{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7091f4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-07T09:18:03.350394Z",
     "iopub.status.busy": "2025-05-07T09:18:03.350125Z",
     "iopub.status.idle": "2025-05-07T09:22:23.028986Z",
     "shell.execute_reply": "2025-05-07T09:22:23.028019Z"
    },
    "papermill": {
     "duration": 259.684144,
     "end_time": "2025-05-07T09:22:23.030410",
     "exception": false,
     "start_time": "2025-05-07T09:18:03.346266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing LJSpeech Transformer with CTC and Decoder Heads...\n",
      "Downloading LJSpeech dataset...\n",
      "Extracting LJSpeech dataset...\n",
      "Dataset extracted to ./data/LJSpeech-1.1\n",
      "Loading metadata...\n",
      "Metadata columns: ['ID', 'Transcription', 'Normalized_Transcription']\n",
      "First few entries of normalized transcription: 0    Printing, in the only sense with which we are ...\n",
      "1                       in being comparatively modern.\n",
      "2    For although the Chinese took impressions from...\n",
      "3    produced the block books, which were the immed...\n",
      "4    the invention of movable metal letters in the ...\n",
      "Name: Normalized_Transcription, dtype: object\n",
      "Warning: Found NaN values in Normalized_Transcription. These will be converted to empty strings.\n",
      "Found 13100 samples\n",
      "\n",
      "Sample metadata:\n",
      "           ID                                      Transcription  \\\n",
      "0  LJ001-0001  Printing, in the only sense with which we are ...   \n",
      "1  LJ001-0002                     in being comparatively modern.   \n",
      "2  LJ001-0003  For although the Chinese took impressions from...   \n",
      "3  LJ001-0004  produced the block books, which were the immed...   \n",
      "4  LJ001-0005  the invention of movable metal letters in the ...   \n",
      "\n",
      "                            Normalized_Transcription  \n",
      "0  Printing, in the only sense with which we are ...  \n",
      "1                     in being comparatively modern.  \n",
      "2  For although the Chinese took impressions from...  \n",
      "3  produced the block books, which were the immed...  \n",
      "4  the invention of movable metal letters in the ...  \n",
      "\n",
      "Preprocessing text and building vocabulary...\n",
      "Vocabulary size: 31\n",
      "Sample characters: [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']...\n",
      "\n",
      "Initializing audio feature extractor...\n",
      "Extracting features from sample file: ./data/LJSpeech-1.1/wavs/LJ001-0001.wav\n",
      "Sample features shape: torch.Size([832, 80])\n",
      "Saved sample mel spectrogram visualization to sample_mel_spectrogram.png\n",
      "\n",
      "Creating dataset...\n",
      "Created dataset with 100 samples\n",
      "\n",
      "Testing a sample from the dataset...\n",
      "Sample ID: LJ001-0001\n",
      "Features shape: torch.Size([832, 80])\n",
      "Feature length: 832\n",
      "Text: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Text indices: tensor([ 1, 20, 22, 13, 18, 24, 13, 18, 11,  4, 13, 18,  4, 24, 12,  9,  4, 19,\n",
      "        18, 16, 29,  4, 23,  9, 18, 23,  9,  4, 27, 13, 24, 12,  4, 27, 12, 13,\n",
      "         7, 12,  4, 27,  9,  4,  5, 22,  9,  4,  5, 24,  4, 20, 22,  9, 23,  9,\n",
      "        18, 24,  4,  7, 19, 18,  7,  9, 22, 18,  9,  8,  4,  8, 13, 10, 10,  9,\n",
      "        22, 23,  4, 10, 22, 19, 17,  4, 17, 19, 23, 24,  4, 13, 10,  4, 18, 19,\n",
      "        24,  4, 10, 22, 19, 17,  4,  5, 16, 16,  4, 24, 12,  9,  4,  5, 22, 24,\n",
      "        23,  4,  5, 18,  8,  4,  7, 22,  5, 10, 24, 23,  4, 22,  9, 20, 22,  9,\n",
      "        23,  9, 18, 24,  9,  8,  4, 13, 18,  4, 24, 12,  9,  4,  9, 28, 12, 13,\n",
      "         6, 13, 24, 13, 19, 18,  2])\n",
      "Text length: 151\n",
      "\n",
      "Creating dataloader...\n",
      "\n",
      "Testing a batch from the dataloader...\n",
      "Batch IDs: ['LJ001-0056', 'LJ001-0083', 'LJ001-0096', 'LJ001-0080']\n",
      "Feature batch shape: torch.Size([4, 833, 80])\n",
      "Feature lengths: tensor([474, 431, 833, 465])\n",
      "Text batch shape: torch.Size([4, 150])\n",
      "Text lengths: tensor([ 81,  75, 150,  92])\n",
      "Texts: ['it was these great venetian printers together with their brethren of rome milan', 'the seventeenth century founts were bad rather negatively than positively', 'have now come into general use and are obviously a great improvement on the ordinary modern style in use in england which is in fact the bodoni type', 'he seems to have taken the letter of the elzevirs of the seventeenth century for his model']\n",
      "\n",
      "Initializing model...\n",
      "Model initialized with 44227646 parameters\n",
      "\n",
      "Testing forward pass...\n",
      "CTC logits shape: torch.Size([4, 833, 31])\n",
      "Decoder logits shape: torch.Size([4, 150, 31])\n",
      "\n",
      "Initializing loss function...\n",
      "\n",
      "Testing loss calculation...\n",
      "Combined loss: 11.60759162902832\n",
      "CTC loss: 14.997252464294434\n",
      "CE loss: 3.6983847618103027\n",
      "\n",
      "Setup complete! The model is ready for training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore all warnings\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    # Data paths\n",
    "    DATA_DIR = \"./data\"\n",
    "    LJ_SPEECH_URL = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
    "    EXTRACTED_DIR = os.path.join(DATA_DIR, \"LJSpeech-1.1\")\n",
    "    WAVS_DIR = os.path.join(EXTRACTED_DIR, \"wavs\")\n",
    "    METADATA_FILE = os.path.join(EXTRACTED_DIR, \"metadata.csv\")\n",
    "    \n",
    "    # Audio preprocessing\n",
    "    SAMPLE_RATE = 22050\n",
    "    N_FFT = 1024\n",
    "    HOP_LENGTH = 256\n",
    "    N_MELS = 80\n",
    "    \n",
    "    # Model hyperparameters\n",
    "    d_model = 512       # Transformer dimension\n",
    "    nhead = 8           # Number of attention heads\n",
    "    num_encoder_layers = 6\n",
    "    dim_feedforward = 2048\n",
    "    dropout = 0.1\n",
    "    max_seq_len = 1000  # Maximum sequence length\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size = 16\n",
    "    learning_rate = 0.0001\n",
    "    max_epochs = 25\n",
    "    \n",
    "    # Vocabulary\n",
    "    vocab_size = 32     # Will be updated after processing text\n",
    "    \n",
    "# Text preprocessing functions\n",
    "def normalize_text(text):\n",
    "    \"\"\"Basic text normalization\"\"\"\n",
    "    # Convert to string in case input is numeric\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def build_vocab(texts):\n",
    "    \"\"\"Build character vocabulary from texts\"\"\"\n",
    "    chars = set()\n",
    "    for text in texts:\n",
    "        for char in text:\n",
    "            chars.add(char)\n",
    "    \n",
    "    # Special tokens\n",
    "    special_tokens = [\"<pad>\", \"<sos>\", \"<eos>\", \"<blank>\"]\n",
    "    \n",
    "    # Create char to index mapping\n",
    "    char_to_idx = {char: idx+len(special_tokens) for idx, char in enumerate(sorted(list(chars)))}\n",
    "    \n",
    "    # Add special tokens\n",
    "    for idx, token in enumerate(special_tokens):\n",
    "        char_to_idx[token] = idx\n",
    "    \n",
    "    # Create index to char mapping\n",
    "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "    \n",
    "    return char_to_idx, idx_to_char\n",
    "\n",
    "class LJSpeechProcessor:\n",
    "    \"\"\"Helper class to download, extract and process LJSpeech dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.char_to_idx = None\n",
    "        self.idx_to_char = None\n",
    "        \n",
    "        # Create data directory if it doesn't exist\n",
    "        os.makedirs(self.config.DATA_DIR, exist_ok=True)\n",
    "        \n",
    "    def download_and_extract(self):\n",
    "        \"\"\"Download and extract LJSpeech dataset\"\"\"\n",
    "        # Check if already extracted\n",
    "        if os.path.exists(self.config.EXTRACTED_DIR):\n",
    "            print(\"Dataset already extracted.\")\n",
    "            return\n",
    "        \n",
    "        # Check if tar file exists\n",
    "        tar_file = os.path.join(self.config.DATA_DIR, \"LJSpeech-1.1.tar.bz2\")\n",
    "        if not os.path.exists(tar_file):\n",
    "            print(\"Downloading LJSpeech dataset...\")\n",
    "            urllib.request.urlretrieve(self.config.LJ_SPEECH_URL, tar_file)\n",
    "            \n",
    "        # Extract tar file\n",
    "        print(\"Extracting LJSpeech dataset...\")\n",
    "        with tarfile.open(tar_file, \"r:bz2\") as tar:\n",
    "            tar.extractall(path=self.config.DATA_DIR)\n",
    "            \n",
    "        print(f\"Dataset extracted to {self.config.EXTRACTED_DIR}\")\n",
    "        \n",
    "    def load_metadata(self):\n",
    "        \"\"\"Load metadata from file\"\"\"\n",
    "        metadata_df = pd.read_csv(self.config.METADATA_FILE, sep=\"|\", header=None)\n",
    "        metadata_df.columns = [\"ID\", \"Transcription\", \"Normalized_Transcription\"]\n",
    "        \n",
    "        # Verify columns and print first few rows\n",
    "        print(\"Metadata columns:\", metadata_df.columns.tolist())\n",
    "        print(\"First few entries of normalized transcription:\", metadata_df[\"Normalized_Transcription\"].head())\n",
    "        \n",
    "        # Check for NaN or float values\n",
    "        if metadata_df[\"Normalized_Transcription\"].isna().any():\n",
    "            print(\"Warning: Found NaN values in Normalized_Transcription. These will be converted to empty strings.\")\n",
    "            metadata_df[\"Normalized_Transcription\"] = metadata_df[\"Normalized_Transcription\"].fillna(\"\")\n",
    "        \n",
    "        # Ensure all text entries are strings\n",
    "        metadata_df[\"Normalized_Transcription\"] = metadata_df[\"Normalized_Transcription\"].astype(str)\n",
    "        \n",
    "        return metadata_df\n",
    "    \n",
    "    def preprocess_text(self, metadata_df):\n",
    "        \"\"\"Preprocess text data and build vocabulary\"\"\"\n",
    "        # Apply more normalization\n",
    "        preprocessed_texts = [normalize_text(text) for text in metadata_df[\"Normalized_Transcription\"]]\n",
    "        \n",
    "        # Build vocabulary\n",
    "        self.char_to_idx, self.idx_to_char = build_vocab(preprocessed_texts)\n",
    "        \n",
    "        # Update vocab size in config\n",
    "        self.config.vocab_size = len(self.char_to_idx)\n",
    "        \n",
    "        print(f\"Vocabulary size: {self.config.vocab_size}\")\n",
    "        print(f\"Sample characters: {list(self.char_to_idx.keys())[:10]}...\")\n",
    "        \n",
    "        return preprocessed_texts\n",
    "    \n",
    "    def text_to_indices(self, text):\n",
    "        \"\"\"Convert text to index sequence\"\"\"\n",
    "        # Add start and end tokens\n",
    "        indices = [self.char_to_idx[\"<sos>\"]]\n",
    "        indices.extend([self.char_to_idx[char] for char in text])\n",
    "        indices.append(self.char_to_idx[\"<eos>\"])\n",
    "        return indices\n",
    "    \n",
    "    def indices_to_text(self, indices):\n",
    "        \"\"\"Convert index sequence to text\"\"\"\n",
    "        text = \"\"\n",
    "        for idx in indices:\n",
    "            if idx == self.char_to_idx[\"<eos>\"]:\n",
    "                break\n",
    "            if idx == self.char_to_idx[\"<sos>\"] or idx == self.char_to_idx[\"<pad>\"] or idx == self.char_to_idx[\"<blank>\"]:\n",
    "                continue\n",
    "            text += self.idx_to_char[idx]\n",
    "        return text\n",
    "    \n",
    "# Audio feature extraction\n",
    "class AudioFeatureExtractor:\n",
    "    \"\"\"Helper class for audio feature extraction\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        # Don't move the transform to device yet - let's do this at extraction time\n",
    "        self.mel_spectrogram_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=config.SAMPLE_RATE,\n",
    "            n_fft=config.N_FFT,\n",
    "            hop_length=config.HOP_LENGTH,\n",
    "            n_mels=config.N_MELS\n",
    "        )\n",
    "        \n",
    "    def extract_features(self, audio_path):\n",
    "        \"\"\"Extract mel spectrogram features from audio file\"\"\"\n",
    "        # Load audio\n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sample_rate != self.config.SAMPLE_RATE:\n",
    "            resampler = torchaudio.transforms.Resample(sample_rate, self.config.SAMPLE_RATE)\n",
    "            waveform = resampler(waveform)\n",
    "        \n",
    "        # Convert to mono if stereo\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Move both waveform and transform to the same device\n",
    "        waveform = waveform.to(device)\n",
    "        mel_spectrogram_transform = self.mel_spectrogram_transform.to(device)\n",
    "            \n",
    "        # Extract mel spectrogram\n",
    "        mel_spectrogram = mel_spectrogram_transform(waveform)\n",
    "        \n",
    "        # Convert to decibel scale\n",
    "        mel_spectrogram = torchaudio.transforms.AmplitudeToDB().to(device)(mel_spectrogram)\n",
    "        \n",
    "        # Transpose to time-major format (T, n_mels)\n",
    "        mel_spectrogram = mel_spectrogram.squeeze(0).transpose(0, 1)\n",
    "        \n",
    "        return mel_spectrogram\n",
    "    \n",
    "    def pad_sequence(self, features, max_len):\n",
    "        \"\"\"Pad or truncate features to a fixed length\"\"\"\n",
    "        if features.size(0) > max_len:\n",
    "            # Truncate\n",
    "            features = features[:max_len, :]\n",
    "        elif features.size(0) < max_len:\n",
    "            # Pad with zeros\n",
    "            padding = torch.zeros(max_len - features.size(0), features.size(1), device=features.device)\n",
    "            features = torch.cat([features, padding], dim=0)\n",
    "        return features\n",
    "    \n",
    "# Dataset class\n",
    "class LJSpeechDataset(Dataset):\n",
    "    \"\"\"LJSpeech dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, metadata_df, processed_texts, config, processor, feature_extractor, is_training=True):\n",
    "        self.metadata_df = metadata_df\n",
    "        self.processed_texts = processed_texts\n",
    "        self.config = config\n",
    "        self.processor = processor\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.is_training = is_training\n",
    "        \n",
    "        # Process IDs\n",
    "        self.file_ids = metadata_df[\"ID\"].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_id = self.file_ids[idx]\n",
    "        text = self.processed_texts[idx]\n",
    "        \n",
    "        # Get audio path\n",
    "        audio_path = os.path.join(self.config.WAVS_DIR, f\"{file_id}.wav\")\n",
    "        \n",
    "        # Extract features\n",
    "        try:\n",
    "            features = self.feature_extractor.extract_features(audio_path)\n",
    "            # Move features to CPU for dataset storage\n",
    "            features = features.cpu()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing audio {file_id}: {e}\")\n",
    "            # Return dummy data in case of error\n",
    "            return {\n",
    "                \"id\": file_id,\n",
    "                \"features\": torch.zeros(100, self.config.N_MELS),\n",
    "                \"feature_lengths\": torch.tensor(100),\n",
    "                \"text_indices\": torch.tensor([0, 0]),\n",
    "                \"text_lengths\": torch.tensor(2),\n",
    "                \"text\": \"\"\n",
    "            }\n",
    "        \n",
    "        # Convert text to indices\n",
    "        text_indices = self.processor.text_to_indices(text)\n",
    "        \n",
    "        # Prepare output\n",
    "        output = {\n",
    "            \"id\": file_id,\n",
    "            \"features\": features,\n",
    "            \"feature_lengths\": torch.tensor(features.size(0)),\n",
    "            \"text_indices\": torch.tensor(text_indices),\n",
    "            \"text_lengths\": torch.tensor(len(text_indices)),\n",
    "            \"text\": text\n",
    "        }\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Collate function for batching\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function for batching\"\"\"\n",
    "    \n",
    "    # Get batch info\n",
    "    ids = [item[\"id\"] for item in batch]\n",
    "    texts = [item[\"text\"] for item in batch]\n",
    "    \n",
    "    # Get feature lengths and text lengths\n",
    "    feature_lengths = torch.stack([item[\"feature_lengths\"] for item in batch])\n",
    "    text_lengths = torch.stack([item[\"text_lengths\"] for item in batch])\n",
    "    \n",
    "    # Get max lengths\n",
    "    max_feature_len = feature_lengths.max().item()\n",
    "    max_text_len = text_lengths.max().item()\n",
    "    \n",
    "    # Prepare batch tensors\n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    # Prepare feature batch\n",
    "    feature_batch = torch.zeros(batch_size, max_feature_len, batch[0][\"features\"].size(1))\n",
    "    \n",
    "    # Prepare text batch\n",
    "    text_batch = torch.full((batch_size, max_text_len), 0)  # Pad with 0 (<pad> token)\n",
    "    \n",
    "    # Fill batches\n",
    "    for i, item in enumerate(batch):\n",
    "        features = item[\"features\"]\n",
    "        text_indices = item[\"text_indices\"]\n",
    "        \n",
    "        # Copy features and text indices\n",
    "        feature_len = features.size(0)\n",
    "        text_len = len(text_indices)\n",
    "        \n",
    "        feature_batch[i, :feature_len, :] = features\n",
    "        text_batch[i, :text_len] = torch.tensor(text_indices)\n",
    "    \n",
    "    return {\n",
    "        \"ids\": ids,\n",
    "        \"feature_batch\": feature_batch,\n",
    "        \"feature_lengths\": feature_lengths,\n",
    "        \"text_batch\": text_batch,\n",
    "        \"text_lengths\": text_lengths,\n",
    "        \"texts\": texts\n",
    "    }\n",
    "\n",
    "# Positional Encoding for Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Positional encoding for transformer\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Dual-Head Transformer Model\n",
    "class DualHeadTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer encoder with two heads:\n",
    "    1. CTC head for sequence labeling\n",
    "    2. Decoder head for autoregressive decoding\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(DualHeadTransformer, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(config.N_MELS, config.d_model)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(config.d_model, config.max_seq_len, config.dropout)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=config.d_model, \n",
    "                                                  nhead=config.nhead,\n",
    "                                                  dim_feedforward=config.dim_feedforward,\n",
    "                                                  dropout=config.dropout)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layers, num_layers=config.num_encoder_layers)\n",
    "        \n",
    "        # CTC Head\n",
    "        self.ctc_head = nn.Linear(config.d_model, config.vocab_size)\n",
    "        \n",
    "        # Decoder embeddings\n",
    "        self.decoder_embedding = nn.Embedding(config.vocab_size, config.d_model)\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_layers = nn.TransformerDecoderLayer(d_model=config.d_model, \n",
    "                                                  nhead=config.nhead,\n",
    "                                                  dim_feedforward=config.dim_feedforward,\n",
    "                                                  dropout=config.dropout)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layers, num_layers=config.num_encoder_layers)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_projection = nn.Linear(config.d_model, config.vocab_size)\n",
    "        \n",
    "    def create_padding_mask(self, lengths, max_len):\n",
    "        \"\"\"Create padding mask from lengths\"\"\"\n",
    "        batch_size = lengths.size(0)\n",
    "        # Create mask on the same device as the lengths tensor\n",
    "        mask = torch.ones(batch_size, max_len, device=lengths.device)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            mask[i, :lengths[i]] = 0\n",
    "        \n",
    "        return mask.bool()\n",
    "        \n",
    "    def forward(self, features, feature_lengths, text=None, text_lengths=None):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \n",
    "        Args:\n",
    "            features: (batch_size, time, n_mels)\n",
    "            feature_lengths: (batch_size)\n",
    "            text: (batch_size, text_len)\n",
    "            text_lengths: (batch_size)\n",
    "            \n",
    "        Returns:\n",
    "            ctc_logits: CTC logits\n",
    "            decoder_logits: Decoder logits (if text is provided)\n",
    "        \"\"\"\n",
    "        batch_size, max_time, _ = features.size()\n",
    "        \n",
    "        # Create padding mask for encoder\n",
    "        encoder_padding_mask = self.create_padding_mask(feature_lengths, max_time)\n",
    "        \n",
    "        # Project and transpose to time-first\n",
    "        x = self.input_projection(features).transpose(0, 1)  # (time, batch, d_model)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoder(x)\n",
    "        \n",
    "        # Encoder\n",
    "        memory = self.encoder(x, src_key_padding_mask=encoder_padding_mask)  # (time, batch, d_model)\n",
    "        \n",
    "        # CTC Head (time-first to batch-first)\n",
    "        ctc_logits = self.ctc_head(memory).transpose(0, 1)  # (batch, time, vocab_size)\n",
    "        \n",
    "        decoder_logits = None\n",
    "        \n",
    "        # Decoder (if training or text is provided)\n",
    "        if text is not None:\n",
    "            # Shift right for teacher forcing\n",
    "            decoder_input = torch.cat([\n",
    "                torch.full((batch_size, 1), 1, device=text.device),  # <sos> token\n",
    "                text[:, :-1]\n",
    "            ], dim=1)\n",
    "            \n",
    "            # Create mask for decoder padding\n",
    "            tgt_padding_mask = self.create_padding_mask(text_lengths, text.size(1))\n",
    "            \n",
    "            # Create causal mask\n",
    "            tgt_mask = torch.triu(\n",
    "                torch.ones(text.size(1), text.size(1), device=text.device) * float('-inf'),\n",
    "                diagonal=1\n",
    "            )\n",
    "            \n",
    "            # Get embeddings\n",
    "            tgt_embeddings = self.decoder_embedding(decoder_input).transpose(0, 1)  # (seq, batch, d_model)\n",
    "            \n",
    "            # Run decoder\n",
    "            decoder_output = self.decoder(\n",
    "                tgt_embeddings, memory,\n",
    "                tgt_mask=tgt_mask,\n",
    "                tgt_key_padding_mask=tgt_padding_mask,\n",
    "                memory_key_padding_mask=encoder_padding_mask\n",
    "            )\n",
    "            \n",
    "            # Output projection\n",
    "            decoder_logits = self.output_projection(decoder_output).transpose(0, 1)  # (batch, seq, vocab_size)\n",
    "            \n",
    "        return ctc_logits, decoder_logits\n",
    "\n",
    "# Loss function\n",
    "class DualHeadLoss(nn.Module):\n",
    "    \"\"\"Loss function for dual-head model\"\"\"\n",
    "    \n",
    "    def __init__(self, blank_idx=3, ctc_weight=0.7):  # blank_idx for <blank> token\n",
    "        super(DualHeadLoss, self).__init__()\n",
    "        self.ctc_loss = nn.CTCLoss(blank=blank_idx, reduction='mean', zero_infinity=True)\n",
    "        self.ce_loss = nn.CrossEntropyLoss(ignore_index=0)  # ignore <pad> token\n",
    "        self.ctc_weight = ctc_weight\n",
    "        \n",
    "    def forward(self, ctc_logits, decoder_logits, targets, input_lengths, target_lengths):\n",
    "        # Strip <sos> and <eos> from targets for CTC\n",
    "        # Ensure targets have at least length 2 to avoid errors\n",
    "        ctc_targets = targets[:, 1:-1]  # Exclude first (<sos>) and last (<eos>) tokens\n",
    "        ctc_target_lengths = torch.clamp(target_lengths - 2, min=1)  # Adjust lengths\n",
    "        \n",
    "        # Handle edge cases where targets become too short\n",
    "        valid_mask = (ctc_target_lengths > 0) & (ctc_targets.size(1) > 0)\n",
    "        if not valid_mask.all():\n",
    "            # Filter out invalid entries (if any)\n",
    "            valid_indices = valid_mask.nonzero(as_tuple=True)[0]\n",
    "            ctc_logits = ctc_logits[valid_indices]\n",
    "            ctc_targets = ctc_targets[valid_indices]\n",
    "            input_lengths = input_lengths[valid_indices]\n",
    "            ctc_target_lengths = ctc_target_lengths[valid_indices]\n",
    "            if ctc_logits.size(0) == 0:\n",
    "                ctc_loss_val = torch.tensor(0.0, device=ctc_logits.device)\n",
    "            else:\n",
    "                ctc_logits_tm = ctc_logits.transpose(0, 1)\n",
    "                ctc_loss_val = self.ctc_loss(\n",
    "                    ctc_logits_tm.log_softmax(2), \n",
    "                    ctc_targets, \n",
    "                    input_lengths, \n",
    "                    ctc_target_lengths\n",
    "                )\n",
    "        else:\n",
    "            ctc_logits_tm = ctc_logits.transpose(0, 1)\n",
    "            ctc_loss_val = self.ctc_loss(\n",
    "                ctc_logits_tm.log_softmax(2), \n",
    "                ctc_targets, \n",
    "                input_lengths, \n",
    "                ctc_target_lengths\n",
    "            )\n",
    "        \n",
    "        # CE loss remains unchanged\n",
    "        batch_size, seq_len, vocab_size = decoder_logits.size()\n",
    "        ce_loss_val = self.ce_loss(\n",
    "            decoder_logits.reshape(-1, vocab_size),\n",
    "            targets.reshape(-1)\n",
    "        )\n",
    "        \n",
    "        # Combined loss\n",
    "        loss = self.ctc_weight * ctc_loss_val + (1 - self.ctc_weight) * ce_loss_val\n",
    "        \n",
    "        return loss, ctc_loss_val, ce_loss_val\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    print(\"Initializing LJSpeech Transformer with CTC and Decoder Heads...\")\n",
    "    \n",
    "    # Configuration\n",
    "    config = Config()\n",
    "    \n",
    "    # Initialize processor\n",
    "    processor = LJSpeechProcessor(config)\n",
    "    \n",
    "    # Download and extract dataset\n",
    "    processor.download_and_extract()\n",
    "    \n",
    "    # Load metadata\n",
    "    print(\"Loading metadata...\")\n",
    "    metadata_df = processor.load_metadata()\n",
    "    print(f\"Found {len(metadata_df)} samples\")\n",
    "    \n",
    "    # Check the first few rows\n",
    "    print(\"\\nSample metadata:\")\n",
    "    print(metadata_df.head())\n",
    "    \n",
    "    # Preprocess text\n",
    "    print(\"\\nPreprocessing text and building vocabulary...\")\n",
    "    processed_texts = processor.preprocess_text(metadata_df)\n",
    "    \n",
    "    # Initialize feature extractor\n",
    "    print(\"\\nInitializing audio feature extractor...\")\n",
    "    feature_extractor = AudioFeatureExtractor(config)\n",
    "    \n",
    "    # Verify feature extraction with a sample file\n",
    "    sample_id = metadata_df[\"ID\"].iloc[0]\n",
    "    sample_path = os.path.join(config.WAVS_DIR, f\"{sample_id}.wav\")\n",
    "    print(f\"Extracting features from sample file: {sample_path}\")\n",
    "    \n",
    "    sample_features = feature_extractor.extract_features(sample_path)\n",
    "    print(f\"Sample features shape: {sample_features.shape}\")\n",
    "    \n",
    "    # Visualize mel spectrogram\n",
    "    # First move sample_features to CPU for visualization\n",
    "    sample_features_cpu = sample_features.cpu()\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(sample_features_cpu.numpy(), aspect='auto', origin='lower')\n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_mel_spectrogram.png')\n",
    "    plt.close()\n",
    "    print(\"Saved sample mel spectrogram visualization to sample_mel_spectrogram.png\")\n",
    "    \n",
    "    # Create dataset\n",
    "    print(\"\\nCreating dataset...\")\n",
    "    # Use a small subset for testing\n",
    "    test_size = min(100, len(metadata_df))\n",
    "    test_metadata_df = metadata_df.iloc[:test_size]\n",
    "    test_processed_texts = processed_texts[:test_size]\n",
    "    \n",
    "    dataset = LJSpeechDataset(\n",
    "        test_metadata_df, \n",
    "        test_processed_texts, \n",
    "        config, \n",
    "        processor, \n",
    "        feature_extractor\n",
    "    )\n",
    "    \n",
    "    print(f\"Created dataset with {len(dataset)} samples\")\n",
    "    \n",
    "    # Test a sample from the dataset\n",
    "    print(\"\\nTesting a sample from the dataset...\")\n",
    "    sample_item = dataset[0]\n",
    "    print(f\"Sample ID: {sample_item['id']}\")\n",
    "    print(f\"Features shape: {sample_item['features'].shape}\")\n",
    "    print(f\"Feature length: {sample_item['feature_lengths']}\")\n",
    "    print(f\"Text: {sample_item['text']}\")\n",
    "    print(f\"Text indices: {sample_item['text_indices']}\")\n",
    "    print(f\"Text length: {sample_item['text_lengths']}\")\n",
    "    \n",
    "    # Create dataloader\n",
    "    print(\"\\nCreating dataloader...\")\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=4, \n",
    "        shuffle=True, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Test a batch from the dataloader\n",
    "    print(\"\\nTesting a batch from the dataloader...\")\n",
    "    sample_batch = next(iter(dataloader))\n",
    "    print(f\"Batch IDs: {sample_batch['ids']}\")\n",
    "    print(f\"Feature batch shape: {sample_batch['feature_batch'].shape}\")\n",
    "    print(f\"Feature lengths: {sample_batch['feature_lengths']}\")\n",
    "    print(f\"Text batch shape: {sample_batch['text_batch'].shape}\")\n",
    "    print(f\"Text lengths: {sample_batch['text_lengths']}\")\n",
    "    print(f\"Texts: {sample_batch['texts']}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"\\nInitializing model...\")\n",
    "    model = DualHeadTransformer(config).to(device)\n",
    "    print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    print(\"\\nTesting forward pass...\")\n",
    "    sample_feature_batch = sample_batch['feature_batch'].to(device)\n",
    "    sample_feature_lengths = sample_batch['feature_lengths'].to(device)\n",
    "    sample_text_batch = sample_batch['text_batch'].to(device)\n",
    "    sample_text_lengths = sample_batch['text_lengths'].to(device)\n",
    "    \n",
    "    ctc_logits, decoder_logits = model(\n",
    "        sample_feature_batch, \n",
    "        sample_feature_lengths, \n",
    "        sample_text_batch, \n",
    "        sample_text_lengths\n",
    "    )\n",
    "    \n",
    "    print(f\"CTC logits shape: {ctc_logits.shape}\")\n",
    "    print(f\"Decoder logits shape: {decoder_logits.shape}\")\n",
    "    \n",
    "    # Initialize loss function\n",
    "    print(\"\\nInitializing loss function...\")\n",
    "    loss_fn = DualHeadLoss().to(device)\n",
    "    \n",
    "    # Test loss calculation\n",
    "    print(\"\\nTesting loss calculation...\")\n",
    "    loss, ctc_loss, ce_loss = loss_fn(\n",
    "        ctc_logits, \n",
    "        decoder_logits, \n",
    "        sample_text_batch, \n",
    "        sample_feature_lengths, \n",
    "        sample_text_lengths\n",
    "    )\n",
    "    \n",
    "    print(f\"Combined loss: {loss.item()}\")\n",
    "    print(f\"CTC loss: {ctc_loss.item()}\")\n",
    "    print(f\"CE loss: {ce_loss.item()}\")\n",
    "    \n",
    "    print(\"\\nSetup complete! The model is ready for training.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816bc70b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T09:22:23.036544Z",
     "iopub.status.busy": "2025-05-07T09:22:23.036284Z",
     "iopub.status.idle": "2025-05-07T14:45:25.434414Z",
     "shell.execute_reply": "2025-05-07T14:45:25.433713Z"
    },
    "papermill": {
     "duration": 19382.402676,
     "end_time": "2025-05-07T14:45:25.435755",
     "exception": false,
     "start_time": "2025-05-07T09:22:23.033079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LJSpeech Transformer with CTC and Decoder Heads...\n",
      "Dataset already extracted.\n",
      "Loading metadata...\n",
      "Metadata columns: ['ID', 'Transcription', 'Normalized_Transcription']\n",
      "First few entries of normalized transcription: 0    Printing, in the only sense with which we are ...\n",
      "1                       in being comparatively modern.\n",
      "2    For although the Chinese took impressions from...\n",
      "3    produced the block books, which were the immed...\n",
      "4    the invention of movable metal letters in the ...\n",
      "Name: Normalized_Transcription, dtype: object\n",
      "Warning: Found NaN values in Normalized_Transcription. These will be converted to empty strings.\n",
      "Found 13100 samples\n",
      "\n",
      "Preprocessing text and building vocabulary...\n",
      "Vocabulary size: 31\n",
      "Sample characters: [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']...\n",
      "\n",
      "Initializing audio feature extractor...\n",
      "\n",
      "Creating dataset...\n",
      "Created train dataset with 11790 samples\n",
      "Created validation dataset with 1179 samples\n",
      "\n",
      "Creating dataloaders...\n",
      "\n",
      "Initializing model...\n",
      "Model initialized with 44227646 parameters\n",
      "\n",
      "Initializing loss function...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/25\n",
      "Epoch 1 | Batch 0/737 | Loss: 9.9515 | CTC: 12.6191 | CE: 3.7269 | Time: 1.42s\n",
      "Epoch 1 | Batch 10/737 | Loss: 4.2814 | CTC: 4.8874 | CE: 2.8676 | Time: 10.21s\n",
      "Epoch 1 | Batch 20/737 | Loss: 4.0537 | CTC: 4.6851 | CE: 2.5804 | Time: 10.40s\n",
      "Epoch 1 | Batch 30/737 | Loss: 4.1168 | CTC: 4.7707 | CE: 2.5911 | Time: 10.25s\n",
      "Epoch 1 | Batch 40/737 | Loss: 3.8783 | CTC: 4.5113 | CE: 2.4014 | Time: 10.43s\n",
      "Epoch 1 | Batch 50/737 | Loss: 4.0151 | CTC: 4.6999 | CE: 2.4173 | Time: 10.13s\n",
      "Epoch 1 | Batch 60/737 | Loss: 3.8855 | CTC: 4.5055 | CE: 2.4390 | Time: 10.31s\n",
      "Epoch 1 | Batch 70/737 | Loss: 4.6802 | CTC: 5.6539 | CE: 2.4083 | Time: 10.27s\n",
      "Epoch 1 | Batch 80/737 | Loss: 4.5292 | CTC: 5.4527 | CE: 2.3743 | Time: 9.99s\n",
      "Epoch 1 | Batch 90/737 | Loss: 3.8050 | CTC: 4.4146 | CE: 2.3825 | Time: 10.40s\n",
      "Epoch 1 | Batch 100/737 | Loss: 4.8461 | CTC: 5.9086 | CE: 2.3670 | Time: 10.41s\n",
      "Epoch 1 | Batch 110/737 | Loss: 4.6076 | CTC: 5.6084 | CE: 2.2723 | Time: 10.69s\n",
      "Epoch 1 | Batch 120/737 | Loss: 3.6742 | CTC: 4.2595 | CE: 2.3087 | Time: 10.28s\n",
      "Epoch 1 | Batch 130/737 | Loss: 4.3544 | CTC: 5.2277 | CE: 2.3168 | Time: 9.97s\n",
      "Epoch 1 | Batch 140/737 | Loss: 3.7003 | CTC: 4.2809 | CE: 2.3455 | Time: 9.90s\n",
      "Epoch 1 | Batch 150/737 | Loss: 3.6847 | CTC: 4.2715 | CE: 2.3154 | Time: 9.87s\n",
      "Epoch 1 | Batch 160/737 | Loss: 3.7179 | CTC: 4.3229 | CE: 2.3061 | Time: 10.04s\n",
      "Epoch 1 | Batch 170/737 | Loss: 3.8949 | CTC: 4.5587 | CE: 2.3461 | Time: 10.22s\n",
      "Epoch 1 | Batch 180/737 | Loss: 3.6996 | CTC: 4.2865 | CE: 2.3300 | Time: 10.18s\n",
      "Epoch 1 | Batch 190/737 | Loss: 3.6427 | CTC: 4.2226 | CE: 2.2896 | Time: 10.11s\n",
      "Epoch 1 | Batch 200/737 | Loss: 3.9258 | CTC: 4.5650 | CE: 2.4345 | Time: 10.17s\n",
      "Epoch 1 | Batch 210/737 | Loss: 3.5147 | CTC: 4.0309 | CE: 2.3104 | Time: 10.25s\n",
      "Epoch 1 | Batch 220/737 | Loss: 3.6810 | CTC: 4.2578 | CE: 2.3350 | Time: 10.26s\n",
      "Epoch 1 | Batch 230/737 | Loss: 4.3369 | CTC: 5.2148 | CE: 2.2885 | Time: 10.28s\n",
      "Epoch 1 | Batch 240/737 | Loss: 3.8138 | CTC: 4.4393 | CE: 2.3543 | Time: 10.37s\n",
      "Epoch 1 | Batch 250/737 | Loss: 3.6391 | CTC: 4.1997 | CE: 2.3310 | Time: 10.21s\n",
      "Epoch 1 | Batch 260/737 | Loss: 3.4894 | CTC: 3.9733 | CE: 2.3602 | Time: 10.42s\n",
      "Epoch 1 | Batch 270/737 | Loss: 3.5776 | CTC: 4.1261 | CE: 2.2977 | Time: 10.19s\n",
      "Epoch 1 | Batch 280/737 | Loss: 4.4965 | CTC: 5.4332 | CE: 2.3109 | Time: 9.85s\n",
      "Epoch 1 | Batch 290/737 | Loss: 4.9312 | CTC: 6.0393 | CE: 2.3456 | Time: 10.44s\n",
      "Epoch 1 | Batch 300/737 | Loss: 3.6704 | CTC: 4.2468 | CE: 2.3252 | Time: 10.05s\n",
      "Epoch 1 | Batch 310/737 | Loss: 3.5021 | CTC: 4.0091 | CE: 2.3192 | Time: 10.33s\n",
      "Epoch 1 | Batch 320/737 | Loss: 3.7044 | CTC: 4.3064 | CE: 2.2996 | Time: 10.07s\n",
      "Epoch 1 | Batch 330/737 | Loss: 3.7118 | CTC: 4.3153 | CE: 2.3035 | Time: 10.13s\n",
      "Epoch 1 | Batch 340/737 | Loss: 3.6156 | CTC: 4.1904 | CE: 2.2744 | Time: 10.01s\n",
      "Epoch 1 | Batch 350/737 | Loss: 3.4353 | CTC: 3.9037 | CE: 2.3424 | Time: 10.25s\n",
      "Epoch 1 | Batch 360/737 | Loss: 3.4319 | CTC: 3.9426 | CE: 2.2403 | Time: 10.32s\n",
      "Epoch 1 | Batch 370/737 | Loss: 3.5554 | CTC: 4.1050 | CE: 2.2728 | Time: 10.39s\n",
      "Epoch 1 | Batch 380/737 | Loss: 3.5247 | CTC: 4.0906 | CE: 2.2040 | Time: 10.07s\n",
      "Epoch 1 | Batch 390/737 | Loss: 3.3950 | CTC: 3.8919 | CE: 2.2355 | Time: 10.23s\n",
      "Epoch 1 | Batch 400/737 | Loss: 3.8579 | CTC: 4.5305 | CE: 2.2886 | Time: 10.26s\n",
      "Epoch 1 | Batch 410/737 | Loss: 3.5528 | CTC: 4.1226 | CE: 2.2231 | Time: 10.05s\n",
      "Epoch 1 | Batch 420/737 | Loss: 3.4561 | CTC: 3.9796 | CE: 2.2344 | Time: 10.14s\n",
      "Epoch 1 | Batch 430/737 | Loss: 3.5613 | CTC: 4.1287 | CE: 2.2374 | Time: 10.16s\n",
      "Epoch 1 | Batch 440/737 | Loss: 3.7444 | CTC: 4.4242 | CE: 2.1580 | Time: 9.91s\n",
      "Epoch 1 | Batch 450/737 | Loss: 4.6643 | CTC: 5.7022 | CE: 2.2426 | Time: 10.18s\n",
      "Epoch 1 | Batch 460/737 | Loss: 3.4585 | CTC: 3.9995 | CE: 2.1961 | Time: 10.08s\n",
      "Epoch 1 | Batch 470/737 | Loss: 3.7259 | CTC: 4.3619 | CE: 2.2420 | Time: 10.22s\n",
      "Epoch 1 | Batch 480/737 | Loss: 3.7969 | CTC: 4.5083 | CE: 2.1367 | Time: 9.90s\n",
      "Epoch 1 | Batch 490/737 | Loss: 3.5915 | CTC: 4.2337 | CE: 2.0930 | Time: 10.32s\n",
      "Epoch 1 | Batch 500/737 | Loss: 3.4431 | CTC: 3.9667 | CE: 2.2214 | Time: 10.30s\n",
      "Epoch 1 | Batch 510/737 | Loss: 3.6551 | CTC: 4.2903 | CE: 2.1729 | Time: 10.15s\n",
      "Epoch 1 | Batch 520/737 | Loss: 3.4619 | CTC: 4.0316 | CE: 2.1328 | Time: 10.14s\n",
      "Epoch 1 | Batch 530/737 | Loss: 3.6785 | CTC: 4.3597 | CE: 2.0891 | Time: 10.38s\n",
      "Epoch 1 | Batch 540/737 | Loss: 3.5074 | CTC: 4.0913 | CE: 2.1449 | Time: 10.06s\n",
      "Epoch 1 | Batch 550/737 | Loss: 3.4289 | CTC: 4.0169 | CE: 2.0568 | Time: 10.15s\n",
      "Epoch 1 | Batch 560/737 | Loss: 3.3631 | CTC: 3.9338 | CE: 2.0316 | Time: 10.30s\n",
      "Epoch 1 | Batch 570/737 | Loss: 4.9078 | CTC: 6.1288 | CE: 2.0589 | Time: 10.22s\n",
      "Epoch 1 | Batch 580/737 | Loss: 4.3929 | CTC: 5.3665 | CE: 2.1213 | Time: 10.34s\n",
      "Epoch 1 | Batch 590/737 | Loss: 3.3692 | CTC: 3.9339 | CE: 2.0517 | Time: 10.21s\n",
      "Epoch 1 | Batch 600/737 | Loss: 3.4295 | CTC: 4.0094 | CE: 2.0763 | Time: 10.15s\n",
      "Epoch 1 | Batch 610/737 | Loss: 3.6269 | CTC: 4.2937 | CE: 2.0713 | Time: 10.08s\n",
      "Epoch 1 | Batch 620/737 | Loss: 3.3580 | CTC: 3.9029 | CE: 2.0866 | Time: 10.24s\n",
      "Epoch 1 | Batch 630/737 | Loss: 3.4873 | CTC: 4.1235 | CE: 2.0029 | Time: 9.98s\n",
      "Epoch 1 | Batch 640/737 | Loss: 3.4973 | CTC: 4.1306 | CE: 2.0198 | Time: 10.34s\n",
      "Epoch 1 | Batch 650/737 | Loss: 3.4395 | CTC: 4.0351 | CE: 2.0499 | Time: 10.31s\n",
      "Epoch 1 | Batch 660/737 | Loss: 3.3214 | CTC: 3.9008 | CE: 1.9695 | Time: 9.91s\n",
      "Epoch 1 | Batch 670/737 | Loss: 3.2744 | CTC: 3.8136 | CE: 2.0162 | Time: 10.19s\n",
      "Epoch 1 | Batch 680/737 | Loss: 3.3109 | CTC: 3.8799 | CE: 1.9831 | Time: 10.10s\n",
      "Epoch 1 | Batch 690/737 | Loss: 3.6234 | CTC: 4.3527 | CE: 1.9215 | Time: 10.19s\n",
      "Epoch 1 | Batch 700/737 | Loss: 3.4540 | CTC: 4.0786 | CE: 1.9966 | Time: 9.81s\n",
      "Epoch 1 | Batch 710/737 | Loss: 3.3851 | CTC: 3.9684 | CE: 2.0240 | Time: 10.39s\n",
      "Epoch 1 | Batch 720/737 | Loss: 3.5436 | CTC: 4.2017 | CE: 2.0081 | Time: 10.01s\n",
      "Epoch 1 | Batch 730/737 | Loss: 3.2140 | CTC: 3.7568 | CE: 1.9473 | Time: 10.33s\n",
      "Train Loss: 7.1672 | CTC: 9.2770 | CE: 2.2442\n",
      "Val Loss: 3.5856 | CTC: 4.2995 | CE: 1.9199\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction:  a a a a a a a a a a a \n",
      "\n",
      "Epoch 2/25\n",
      "Epoch 2 | Batch 0/737 | Loss: 3.2690 | CTC: 3.8253 | CE: 1.9708 | Time: 0.99s\n",
      "Epoch 2 | Batch 10/737 | Loss: 3.3765 | CTC: 3.9551 | CE: 2.0263 | Time: 10.37s\n",
      "Epoch 2 | Batch 20/737 | Loss: 3.2770 | CTC: 3.8285 | CE: 1.9902 | Time: 10.35s\n",
      "Epoch 2 | Batch 30/737 | Loss: 3.3926 | CTC: 4.0143 | CE: 1.9418 | Time: 10.14s\n",
      "Epoch 2 | Batch 40/737 | Loss: 3.2545 | CTC: 3.8017 | CE: 1.9776 | Time: 10.00s\n",
      "Epoch 2 | Batch 50/737 | Loss: 3.5726 | CTC: 4.2303 | CE: 2.0379 | Time: 10.33s\n",
      "Epoch 2 | Batch 60/737 | Loss: 3.3769 | CTC: 4.0136 | CE: 1.8914 | Time: 9.82s\n",
      "Epoch 2 | Batch 70/737 | Loss: 3.3432 | CTC: 3.9293 | CE: 1.9756 | Time: 9.80s\n",
      "Epoch 2 | Batch 80/737 | Loss: 3.3822 | CTC: 3.9749 | CE: 1.9992 | Time: 10.48s\n",
      "Epoch 2 | Batch 90/737 | Loss: 3.3305 | CTC: 3.9171 | CE: 1.9618 | Time: 10.30s\n",
      "Epoch 2 | Batch 100/737 | Loss: 3.2380 | CTC: 3.7716 | CE: 1.9930 | Time: 10.11s\n",
      "Epoch 2 | Batch 110/737 | Loss: 3.4977 | CTC: 4.1716 | CE: 1.9253 | Time: 9.91s\n",
      "Epoch 2 | Batch 120/737 | Loss: 3.2989 | CTC: 3.9082 | CE: 1.8771 | Time: 10.10s\n",
      "Epoch 2 | Batch 130/737 | Loss: 3.4740 | CTC: 4.1096 | CE: 1.9909 | Time: 10.41s\n",
      "Epoch 2 | Batch 140/737 | Loss: 4.3304 | CTC: 5.3808 | CE: 1.8792 | Time: 10.17s\n",
      "Epoch 2 | Batch 150/737 | Loss: 239.8718 | CTC: 341.8458 | CE: 1.9326 | Time: 10.34s\n",
      "Epoch 2 | Batch 160/737 | Loss: 106.1459 | CTC: 150.8150 | CE: 1.9179 | Time: 10.16s\n",
      "Epoch 2 | Batch 170/737 | Loss: 3.3975 | CTC: 4.0482 | CE: 1.8792 | Time: 10.15s\n",
      "Epoch 2 | Batch 180/737 | Loss: 3.2226 | CTC: 3.8121 | CE: 1.8469 | Time: 9.86s\n",
      "Epoch 2 | Batch 190/737 | Loss: 3.3339 | CTC: 3.9603 | CE: 1.8723 | Time: 10.28s\n",
      "Epoch 2 | Batch 200/737 | Loss: 3.1993 | CTC: 3.7780 | CE: 1.8491 | Time: 10.35s\n",
      "Epoch 2 | Batch 210/737 | Loss: 3.2637 | CTC: 3.8701 | CE: 1.8486 | Time: 10.24s\n",
      "Epoch 2 | Batch 220/737 | Loss: 3.2315 | CTC: 3.8011 | CE: 1.9026 | Time: 10.07s\n",
      "Epoch 2 | Batch 230/737 | Loss: 3.2825 | CTC: 3.8813 | CE: 1.8854 | Time: 10.11s\n",
      "Epoch 2 | Batch 240/737 | Loss: 3.3273 | CTC: 3.9187 | CE: 1.9474 | Time: 10.14s\n",
      "Epoch 2 | Batch 250/737 | Loss: 3.3067 | CTC: 3.9196 | CE: 1.8767 | Time: 10.17s\n",
      "Epoch 2 | Batch 260/737 | Loss: 4.2572 | CTC: 5.2886 | CE: 1.8507 | Time: 9.99s\n",
      "Epoch 2 | Batch 270/737 | Loss: 3.3912 | CTC: 4.0546 | CE: 1.8431 | Time: 10.05s\n",
      "Epoch 2 | Batch 280/737 | Loss: 3.2289 | CTC: 3.8320 | CE: 1.8215 | Time: 10.03s\n",
      "Epoch 2 | Batch 290/737 | Loss: 3.2945 | CTC: 3.9118 | CE: 1.8541 | Time: 10.14s\n",
      "Epoch 2 | Batch 300/737 | Loss: 3.0847 | CTC: 3.6317 | CE: 1.8085 | Time: 10.30s\n",
      "Epoch 2 | Batch 310/737 | Loss: 3.1488 | CTC: 3.7091 | CE: 1.8413 | Time: 10.10s\n",
      "Epoch 2 | Batch 320/737 | Loss: 3.1916 | CTC: 3.7996 | CE: 1.7729 | Time: 10.31s\n",
      "Epoch 2 | Batch 330/737 | Loss: 3.2089 | CTC: 3.7920 | CE: 1.8486 | Time: 10.41s\n",
      "Epoch 2 | Batch 340/737 | Loss: 3.1691 | CTC: 3.7534 | CE: 1.8057 | Time: 10.20s\n",
      "Epoch 2 | Batch 350/737 | Loss: 3.2500 | CTC: 3.8439 | CE: 1.8642 | Time: 10.31s\n",
      "Epoch 2 | Batch 360/737 | Loss: 3.2346 | CTC: 3.8500 | CE: 1.7989 | Time: 10.23s\n",
      "Epoch 2 | Batch 370/737 | Loss: 4.4503 | CTC: 5.5696 | CE: 1.8385 | Time: 10.40s\n",
      "Epoch 2 | Batch 380/737 | Loss: 3.9725 | CTC: 4.8536 | CE: 1.9165 | Time: 9.85s\n",
      "Epoch 2 | Batch 390/737 | Loss: 4.1794 | CTC: 5.1617 | CE: 1.8874 | Time: 10.13s\n",
      "Epoch 2 | Batch 400/737 | Loss: 3.0504 | CTC: 3.5784 | CE: 1.8184 | Time: 10.22s\n",
      "Epoch 2 | Batch 410/737 | Loss: 3.2150 | CTC: 3.8323 | CE: 1.7747 | Time: 10.37s\n",
      "Epoch 2 | Batch 420/737 | Loss: 3.2950 | CTC: 3.9043 | CE: 1.8731 | Time: 10.31s\n",
      "Epoch 2 | Batch 430/737 | Loss: 3.6386 | CTC: 4.3988 | CE: 1.8649 | Time: 10.43s\n",
      "Epoch 2 | Batch 440/737 | Loss: 4.2435 | CTC: 5.2465 | CE: 1.9030 | Time: 10.05s\n",
      "Epoch 2 | Batch 450/737 | Loss: 3.3016 | CTC: 3.9381 | CE: 1.8163 | Time: 10.19s\n",
      "Epoch 2 | Batch 460/737 | Loss: 4.0051 | CTC: 4.9426 | CE: 1.8177 | Time: 10.02s\n",
      "Epoch 2 | Batch 470/737 | Loss: 4.1633 | CTC: 5.1466 | CE: 1.8690 | Time: 10.17s\n",
      "Epoch 2 | Batch 480/737 | Loss: 4.1181 | CTC: 5.1271 | CE: 1.7637 | Time: 10.31s\n",
      "Epoch 2 | Batch 490/737 | Loss: 3.2915 | CTC: 3.9485 | CE: 1.7586 | Time: 9.95s\n",
      "Epoch 2 | Batch 500/737 | Loss: 3.3184 | CTC: 3.9868 | CE: 1.7588 | Time: 10.15s\n",
      "Epoch 2 | Batch 510/737 | Loss: 3.3244 | CTC: 3.9674 | CE: 1.8240 | Time: 9.87s\n",
      "Epoch 2 | Batch 520/737 | Loss: 3.2763 | CTC: 3.9101 | CE: 1.7975 | Time: 9.94s\n",
      "Epoch 2 | Batch 530/737 | Loss: 137.1994 | CTC: 195.2236 | CE: 1.8097 | Time: 10.26s\n",
      "Epoch 2 | Batch 540/737 | Loss: 3.2501 | CTC: 3.8610 | CE: 1.8247 | Time: 10.06s\n",
      "Epoch 2 | Batch 550/737 | Loss: 3.3631 | CTC: 4.0413 | CE: 1.7805 | Time: 10.27s\n",
      "Epoch 2 | Batch 560/737 | Loss: 3.1323 | CTC: 3.7090 | CE: 1.7868 | Time: 10.04s\n",
      "Epoch 2 | Batch 570/737 | Loss: 3.2600 | CTC: 3.8675 | CE: 1.8428 | Time: 10.11s\n",
      "Epoch 2 | Batch 580/737 | Loss: 3.3593 | CTC: 4.0675 | CE: 1.7068 | Time: 10.02s\n",
      "Epoch 2 | Batch 590/737 | Loss: 3.2691 | CTC: 3.9070 | CE: 1.7808 | Time: 9.86s\n",
      "Epoch 2 | Batch 600/737 | Loss: 4.2037 | CTC: 5.2656 | CE: 1.7257 | Time: 10.13s\n",
      "Epoch 2 | Batch 610/737 | Loss: 3.1819 | CTC: 3.7997 | CE: 1.7404 | Time: 10.28s\n",
      "Epoch 2 | Batch 620/737 | Loss: 3.3369 | CTC: 3.9828 | CE: 1.8298 | Time: 10.44s\n",
      "Epoch 2 | Batch 630/737 | Loss: 3.2769 | CTC: 3.9296 | CE: 1.7541 | Time: 10.12s\n",
      "Epoch 2 | Batch 640/737 | Loss: 3.3086 | CTC: 3.9920 | CE: 1.7140 | Time: 10.41s\n",
      "Epoch 2 | Batch 650/737 | Loss: 3.1803 | CTC: 3.7765 | CE: 1.7892 | Time: 10.30s\n",
      "Epoch 2 | Batch 660/737 | Loss: 3.2509 | CTC: 3.8913 | CE: 1.7565 | Time: 10.00s\n",
      "Epoch 2 | Batch 670/737 | Loss: 3.1660 | CTC: 3.8020 | CE: 1.6819 | Time: 10.24s\n",
      "Epoch 2 | Batch 680/737 | Loss: 3.3085 | CTC: 3.9635 | CE: 1.7802 | Time: 10.08s\n",
      "Epoch 2 | Batch 690/737 | Loss: 3.2344 | CTC: 3.8348 | CE: 1.8336 | Time: 10.05s\n",
      "Epoch 2 | Batch 700/737 | Loss: 3.2229 | CTC: 3.8396 | CE: 1.7840 | Time: 10.47s\n",
      "Epoch 2 | Batch 710/737 | Loss: 3.1392 | CTC: 3.7513 | CE: 1.7112 | Time: 10.14s\n",
      "Epoch 2 | Batch 720/737 | Loss: 3.1213 | CTC: 3.6981 | CE: 1.7753 | Time: 10.08s\n",
      "Epoch 2 | Batch 730/737 | Loss: 3.1035 | CTC: 3.6906 | CE: 1.7337 | Time: 10.06s\n",
      "Train Loss: 6.7898 | CTC: 8.9100 | CE: 1.8427\n",
      "Val Loss: 3.2359 | CTC: 3.9321 | CE: 1.6114\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction:  a a a a \n",
      "\n",
      "Epoch 3/25\n",
      "Epoch 3 | Batch 0/737 | Loss: 3.1747 | CTC: 3.8037 | CE: 1.7069 | Time: 0.98s\n",
      "Epoch 3 | Batch 10/737 | Loss: 3.2264 | CTC: 3.8708 | CE: 1.7228 | Time: 10.22s\n",
      "Epoch 3 | Batch 20/737 | Loss: 3.3922 | CTC: 4.1104 | CE: 1.7165 | Time: 10.17s\n",
      "Epoch 3 | Batch 30/737 | Loss: 3.1203 | CTC: 3.7334 | CE: 1.6899 | Time: 9.67s\n",
      "Epoch 3 | Batch 40/737 | Loss: 3.0834 | CTC: 3.6550 | CE: 1.7496 | Time: 10.01s\n",
      "Epoch 3 | Batch 50/737 | Loss: 3.3366 | CTC: 4.0411 | CE: 1.6927 | Time: 9.96s\n",
      "Epoch 3 | Batch 60/737 | Loss: 3.0214 | CTC: 3.6052 | CE: 1.6592 | Time: 10.25s\n",
      "Epoch 3 | Batch 70/737 | Loss: 3.1463 | CTC: 3.7535 | CE: 1.7293 | Time: 10.00s\n",
      "Epoch 3 | Batch 80/737 | Loss: 3.3198 | CTC: 3.9981 | CE: 1.7372 | Time: 10.13s\n",
      "Epoch 3 | Batch 90/737 | Loss: 3.0160 | CTC: 3.5654 | CE: 1.7341 | Time: 10.25s\n",
      "Epoch 3 | Batch 100/737 | Loss: 3.1341 | CTC: 3.7575 | CE: 1.6794 | Time: 10.30s\n",
      "Epoch 3 | Batch 110/737 | Loss: 4.0019 | CTC: 4.9490 | CE: 1.7922 | Time: 10.22s\n",
      "Epoch 3 | Batch 120/737 | Loss: 3.0425 | CTC: 3.6270 | CE: 1.6785 | Time: 10.05s\n",
      "Epoch 3 | Batch 130/737 | Loss: 3.1513 | CTC: 3.7745 | CE: 1.6971 | Time: 10.20s\n",
      "Epoch 3 | Batch 140/737 | Loss: 4.2069 | CTC: 5.2653 | CE: 1.7374 | Time: 10.30s\n",
      "Epoch 3 | Batch 150/737 | Loss: 3.0189 | CTC: 3.6007 | CE: 1.6614 | Time: 9.99s\n",
      "Epoch 3 | Batch 160/737 | Loss: 3.0519 | CTC: 3.6404 | CE: 1.6787 | Time: 10.10s\n",
      "Epoch 3 | Batch 170/737 | Loss: 2.9861 | CTC: 3.5592 | CE: 1.6487 | Time: 10.33s\n",
      "Epoch 3 | Batch 180/737 | Loss: 3.3339 | CTC: 4.0539 | CE: 1.6538 | Time: 9.90s\n",
      "Epoch 3 | Batch 190/737 | Loss: 3.2137 | CTC: 3.8743 | CE: 1.6721 | Time: 10.20s\n",
      "Epoch 3 | Batch 200/737 | Loss: 2.9818 | CTC: 3.5288 | CE: 1.7057 | Time: 10.10s\n",
      "Epoch 3 | Batch 210/737 | Loss: 3.8382 | CTC: 4.7274 | CE: 1.7634 | Time: 9.97s\n",
      "Epoch 3 | Batch 220/737 | Loss: 3.0698 | CTC: 3.6545 | CE: 1.7057 | Time: 10.59s\n",
      "Epoch 3 | Batch 230/737 | Loss: 4.2624 | CTC: 5.3819 | CE: 1.6504 | Time: 10.42s\n",
      "Epoch 3 | Batch 240/737 | Loss: 2.9870 | CTC: 3.5166 | CE: 1.7514 | Time: 9.97s\n",
      "Epoch 3 | Batch 250/737 | Loss: 3.0046 | CTC: 3.5836 | CE: 1.6535 | Time: 10.29s\n",
      "Epoch 3 | Batch 260/737 | Loss: 2.9610 | CTC: 3.5152 | CE: 1.6678 | Time: 10.52s\n",
      "Epoch 3 | Batch 270/737 | Loss: 3.1137 | CTC: 3.7239 | CE: 1.6899 | Time: 10.32s\n",
      "Epoch 3 | Batch 280/737 | Loss: 3.1428 | CTC: 3.7929 | CE: 1.6258 | Time: 10.36s\n",
      "Epoch 3 | Batch 290/737 | Loss: 3.1017 | CTC: 3.6668 | CE: 1.7833 | Time: 10.36s\n",
      "Epoch 3 | Batch 300/737 | Loss: 3.2340 | CTC: 3.9032 | CE: 1.6725 | Time: 10.17s\n",
      "Epoch 3 | Batch 310/737 | Loss: 3.1809 | CTC: 3.8044 | CE: 1.7261 | Time: 10.21s\n",
      "Epoch 3 | Batch 320/737 | Loss: 3.0365 | CTC: 3.6252 | CE: 1.6629 | Time: 10.35s\n",
      "Epoch 3 | Batch 330/737 | Loss: 3.0982 | CTC: 3.6937 | CE: 1.7086 | Time: 10.34s\n",
      "Epoch 3 | Batch 340/737 | Loss: 2.6827 | CTC: 3.0866 | CE: 1.7404 | Time: 9.98s\n",
      "Epoch 3 | Batch 350/737 | Loss: 2.6018 | CTC: 2.9387 | CE: 1.8155 | Time: 9.89s\n",
      "Epoch 3 | Batch 360/737 | Loss: 2.5540 | CTC: 2.9152 | CE: 1.7111 | Time: 10.06s\n",
      "Epoch 3 | Batch 370/737 | Loss: 2.5184 | CTC: 2.8751 | CE: 1.6860 | Time: 10.33s\n",
      "Epoch 3 | Batch 380/737 | Loss: 2.5579 | CTC: 2.8902 | CE: 1.7825 | Time: 10.23s\n",
      "Epoch 3 | Batch 390/737 | Loss: 2.5739 | CTC: 2.8910 | CE: 1.8341 | Time: 10.37s\n",
      "Epoch 3 | Batch 400/737 | Loss: 2.5961 | CTC: 2.9358 | CE: 1.8033 | Time: 10.15s\n",
      "Epoch 3 | Batch 410/737 | Loss: 2.5461 | CTC: 2.8878 | CE: 1.7488 | Time: 10.07s\n",
      "Epoch 3 | Batch 420/737 | Loss: 2.5244 | CTC: 2.8586 | CE: 1.7445 | Time: 10.31s\n",
      "Epoch 3 | Batch 430/737 | Loss: 2.5506 | CTC: 2.9123 | CE: 1.7068 | Time: 9.99s\n",
      "Epoch 3 | Batch 440/737 | Loss: 2.5551 | CTC: 2.8954 | CE: 1.7610 | Time: 10.01s\n",
      "Epoch 3 | Batch 450/737 | Loss: 2.5390 | CTC: 2.8847 | CE: 1.7325 | Time: 10.20s\n",
      "Epoch 3 | Batch 460/737 | Loss: 2.5318 | CTC: 2.8898 | CE: 1.6964 | Time: 10.16s\n",
      "Epoch 3 | Batch 470/737 | Loss: 2.5099 | CTC: 2.8505 | CE: 1.7152 | Time: 10.06s\n",
      "Epoch 3 | Batch 480/737 | Loss: 2.4912 | CTC: 2.8270 | CE: 1.7078 | Time: 10.22s\n",
      "Epoch 3 | Batch 490/737 | Loss: 2.4872 | CTC: 2.7859 | CE: 1.7904 | Time: 10.01s\n",
      "Epoch 3 | Batch 500/737 | Loss: 2.4721 | CTC: 2.7438 | CE: 1.8383 | Time: 10.27s\n",
      "Epoch 3 | Batch 510/737 | Loss: 2.3570 | CTC: 2.6282 | CE: 1.7242 | Time: 10.27s\n",
      "Epoch 3 | Batch 520/737 | Loss: 2.3017 | CTC: 2.5712 | CE: 1.6728 | Time: 10.30s\n",
      "Epoch 3 | Batch 530/737 | Loss: 2.2433 | CTC: 2.4577 | CE: 1.7429 | Time: 10.25s\n",
      "Epoch 3 | Batch 540/737 | Loss: 2.2177 | CTC: 2.4421 | CE: 1.6939 | Time: 10.08s\n",
      "Epoch 3 | Batch 550/737 | Loss: 2.1578 | CTC: 2.3610 | CE: 1.6837 | Time: 10.19s\n",
      "Epoch 3 | Batch 560/737 | Loss: 2.1874 | CTC: 2.3799 | CE: 1.7383 | Time: 10.36s\n",
      "Epoch 3 | Batch 570/737 | Loss: 2.1803 | CTC: 2.3763 | CE: 1.7228 | Time: 10.13s\n",
      "Epoch 3 | Batch 580/737 | Loss: 2.0776 | CTC: 2.2932 | CE: 1.5747 | Time: 10.25s\n",
      "Epoch 3 | Batch 590/737 | Loss: 2.0593 | CTC: 2.2583 | CE: 1.5950 | Time: 10.09s\n",
      "Epoch 3 | Batch 600/737 | Loss: 2.0575 | CTC: 2.2243 | CE: 1.6681 | Time: 9.92s\n",
      "Epoch 3 | Batch 610/737 | Loss: 2.1223 | CTC: 2.2939 | CE: 1.7220 | Time: 10.15s\n",
      "Epoch 3 | Batch 620/737 | Loss: 2.0213 | CTC: 2.1979 | CE: 1.6093 | Time: 10.03s\n",
      "Epoch 3 | Batch 630/737 | Loss: 2.0547 | CTC: 2.2342 | CE: 1.6360 | Time: 10.51s\n",
      "Epoch 3 | Batch 640/737 | Loss: 2.0248 | CTC: 2.2067 | CE: 1.6004 | Time: 10.38s\n",
      "Epoch 3 | Batch 650/737 | Loss: 1.9939 | CTC: 2.1795 | CE: 1.5608 | Time: 10.06s\n",
      "Epoch 3 | Batch 660/737 | Loss: 2.0345 | CTC: 2.1789 | CE: 1.6976 | Time: 10.11s\n",
      "Epoch 3 | Batch 670/737 | Loss: 2.0409 | CTC: 2.2140 | CE: 1.6371 | Time: 10.43s\n",
      "Epoch 3 | Batch 680/737 | Loss: 2.0003 | CTC: 2.1566 | CE: 1.6356 | Time: 10.30s\n",
      "Epoch 3 | Batch 690/737 | Loss: 1.9510 | CTC: 2.0866 | CE: 1.6347 | Time: 10.13s\n",
      "Epoch 3 | Batch 700/737 | Loss: 1.9279 | CTC: 2.0884 | CE: 1.5533 | Time: 10.03s\n",
      "Epoch 3 | Batch 710/737 | Loss: 2.0006 | CTC: 2.1746 | CE: 1.5946 | Time: 9.93s\n",
      "Epoch 3 | Batch 720/737 | Loss: 1.9685 | CTC: 2.1177 | CE: 1.6204 | Time: 10.20s\n",
      "Epoch 3 | Batch 730/737 | Loss: 1.9693 | CTC: 2.1243 | CE: 1.6075 | Time: 10.27s\n",
      "Train Loss: 3.6284 | CTC: 4.4571 | CE: 1.6948\n",
      "Val Loss: 1.8604 | CTC: 2.0281 | CE: 1.4692\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: pninhnnoonnronrnrninthn\n",
      "\n",
      "Epoch 4/25\n",
      "Epoch 4 | Batch 0/737 | Loss: 1.9502 | CTC: 2.0999 | CE: 1.6007 | Time: 1.04s\n",
      "Epoch 4 | Batch 10/737 | Loss: 1.9079 | CTC: 2.0454 | CE: 1.5870 | Time: 10.39s\n",
      "Epoch 4 | Batch 20/737 | Loss: 1.9345 | CTC: 2.0519 | CE: 1.6607 | Time: 10.22s\n",
      "Epoch 4 | Batch 30/737 | Loss: 1.8809 | CTC: 2.0316 | CE: 1.5294 | Time: 10.08s\n",
      "Epoch 4 | Batch 40/737 | Loss: 1.8993 | CTC: 2.0435 | CE: 1.5630 | Time: 10.28s\n",
      "Epoch 4 | Batch 50/737 | Loss: 1.8920 | CTC: 2.0217 | CE: 1.5894 | Time: 9.94s\n",
      "Epoch 4 | Batch 60/737 | Loss: 1.9115 | CTC: 2.0467 | CE: 1.5962 | Time: 10.32s\n",
      "Epoch 4 | Batch 70/737 | Loss: 1.9250 | CTC: 2.0698 | CE: 1.5871 | Time: 10.26s\n",
      "Epoch 4 | Batch 80/737 | Loss: 1.8937 | CTC: 2.0059 | CE: 1.6318 | Time: 10.52s\n",
      "Epoch 4 | Batch 90/737 | Loss: 1.8642 | CTC: 2.0001 | CE: 1.5470 | Time: 10.21s\n",
      "Epoch 4 | Batch 100/737 | Loss: 1.8366 | CTC: 1.9455 | CE: 1.5823 | Time: 10.22s\n",
      "Epoch 4 | Batch 110/737 | Loss: 1.8873 | CTC: 2.0649 | CE: 1.4728 | Time: 10.61s\n",
      "Epoch 4 | Batch 120/737 | Loss: 1.8328 | CTC: 1.9446 | CE: 1.5719 | Time: 10.25s\n",
      "Epoch 4 | Batch 130/737 | Loss: 1.9237 | CTC: 2.0633 | CE: 1.5980 | Time: 10.24s\n",
      "Epoch 4 | Batch 140/737 | Loss: 1.8970 | CTC: 2.0378 | CE: 1.5686 | Time: 10.26s\n",
      "Epoch 4 | Batch 150/737 | Loss: 1.8762 | CTC: 2.0016 | CE: 1.5834 | Time: 10.30s\n",
      "Epoch 4 | Batch 160/737 | Loss: 1.9247 | CTC: 2.0717 | CE: 1.5817 | Time: 10.01s\n",
      "Epoch 4 | Batch 170/737 | Loss: 1.8252 | CTC: 1.9439 | CE: 1.5483 | Time: 10.17s\n",
      "Epoch 4 | Batch 180/737 | Loss: 1.8473 | CTC: 1.9912 | CE: 1.5115 | Time: 10.36s\n",
      "Epoch 4 | Batch 190/737 | Loss: 1.8506 | CTC: 1.9671 | CE: 1.5786 | Time: 10.15s\n",
      "Epoch 4 | Batch 200/737 | Loss: 1.8584 | CTC: 1.9623 | CE: 1.6162 | Time: 10.08s\n",
      "Epoch 4 | Batch 210/737 | Loss: 1.7832 | CTC: 1.9236 | CE: 1.4556 | Time: 10.16s\n",
      "Epoch 4 | Batch 220/737 | Loss: 1.9010 | CTC: 2.0405 | CE: 1.5754 | Time: 9.48s\n",
      "Epoch 4 | Batch 230/737 | Loss: 1.8108 | CTC: 1.9231 | CE: 1.5488 | Time: 9.97s\n",
      "Epoch 4 | Batch 240/737 | Loss: 1.8337 | CTC: 1.9471 | CE: 1.5691 | Time: 10.21s\n",
      "Epoch 4 | Batch 250/737 | Loss: 1.8853 | CTC: 2.0323 | CE: 1.5423 | Time: 10.27s\n",
      "Epoch 4 | Batch 260/737 | Loss: 1.8034 | CTC: 1.9185 | CE: 1.5349 | Time: 9.83s\n",
      "Epoch 4 | Batch 270/737 | Loss: 1.8267 | CTC: 1.9670 | CE: 1.4994 | Time: 10.22s\n",
      "Epoch 4 | Batch 280/737 | Loss: 1.8336 | CTC: 1.9527 | CE: 1.5559 | Time: 10.06s\n",
      "Epoch 4 | Batch 290/737 | Loss: 1.7847 | CTC: 1.9184 | CE: 1.4729 | Time: 10.25s\n",
      "Epoch 4 | Batch 300/737 | Loss: 1.8062 | CTC: 1.9262 | CE: 1.5260 | Time: 10.10s\n",
      "Epoch 4 | Batch 310/737 | Loss: 1.7879 | CTC: 1.8969 | CE: 1.5335 | Time: 10.28s\n",
      "Epoch 4 | Batch 320/737 | Loss: 1.7471 | CTC: 1.8641 | CE: 1.4739 | Time: 10.21s\n",
      "Epoch 4 | Batch 330/737 | Loss: 1.8546 | CTC: 1.9361 | CE: 1.6643 | Time: 10.06s\n",
      "Epoch 4 | Batch 340/737 | Loss: 1.7551 | CTC: 1.8866 | CE: 1.4481 | Time: 10.15s\n",
      "Epoch 4 | Batch 350/737 | Loss: 1.8125 | CTC: 1.9423 | CE: 1.5096 | Time: 10.19s\n",
      "Epoch 4 | Batch 360/737 | Loss: 1.7827 | CTC: 1.9040 | CE: 1.4998 | Time: 10.36s\n",
      "Epoch 4 | Batch 370/737 | Loss: 1.8458 | CTC: 1.9400 | CE: 1.6261 | Time: 10.00s\n",
      "Epoch 4 | Batch 380/737 | Loss: 1.7609 | CTC: 1.8850 | CE: 1.4715 | Time: 9.84s\n",
      "Epoch 4 | Batch 390/737 | Loss: 1.7872 | CTC: 1.9121 | CE: 1.4957 | Time: 10.35s\n",
      "Epoch 4 | Batch 400/737 | Loss: 1.7714 | CTC: 1.9057 | CE: 1.4581 | Time: 10.49s\n",
      "Epoch 4 | Batch 410/737 | Loss: 1.7985 | CTC: 1.9178 | CE: 1.5202 | Time: 10.38s\n",
      "Epoch 4 | Batch 420/737 | Loss: 1.7988 | CTC: 1.9043 | CE: 1.5527 | Time: 10.14s\n",
      "Epoch 4 | Batch 430/737 | Loss: 1.7759 | CTC: 1.9027 | CE: 1.4802 | Time: 10.34s\n",
      "Epoch 4 | Batch 440/737 | Loss: 1.8135 | CTC: 1.9329 | CE: 1.5347 | Time: 10.02s\n",
      "Epoch 4 | Batch 450/737 | Loss: 1.7866 | CTC: 1.8732 | CE: 1.5846 | Time: 10.30s\n",
      "Epoch 4 | Batch 460/737 | Loss: 1.7244 | CTC: 1.8507 | CE: 1.4295 | Time: 9.85s\n",
      "Epoch 4 | Batch 470/737 | Loss: 1.7787 | CTC: 1.8821 | CE: 1.5375 | Time: 10.04s\n",
      "Epoch 4 | Batch 480/737 | Loss: 1.8094 | CTC: 1.8985 | CE: 1.6014 | Time: 10.02s\n",
      "Epoch 4 | Batch 490/737 | Loss: 1.7176 | CTC: 1.8267 | CE: 1.4631 | Time: 10.06s\n",
      "Epoch 4 | Batch 500/737 | Loss: 1.7937 | CTC: 1.9501 | CE: 1.4286 | Time: 10.32s\n",
      "Epoch 4 | Batch 510/737 | Loss: 1.7054 | CTC: 1.8148 | CE: 1.4499 | Time: 9.98s\n",
      "Epoch 4 | Batch 520/737 | Loss: 1.7333 | CTC: 1.8417 | CE: 1.4803 | Time: 10.28s\n",
      "Epoch 4 | Batch 530/737 | Loss: 1.7176 | CTC: 1.8367 | CE: 1.4395 | Time: 10.35s\n",
      "Epoch 4 | Batch 540/737 | Loss: 1.7651 | CTC: 1.8882 | CE: 1.4778 | Time: 10.45s\n",
      "Epoch 4 | Batch 550/737 | Loss: 1.6888 | CTC: 1.8101 | CE: 1.4058 | Time: 10.17s\n",
      "Epoch 4 | Batch 560/737 | Loss: 1.7717 | CTC: 1.9000 | CE: 1.4726 | Time: 9.74s\n",
      "Epoch 4 | Batch 570/737 | Loss: 1.7605 | CTC: 1.8564 | CE: 1.5367 | Time: 10.01s\n",
      "Epoch 4 | Batch 580/737 | Loss: 1.7337 | CTC: 1.8464 | CE: 1.4708 | Time: 10.31s\n",
      "Epoch 4 | Batch 590/737 | Loss: 1.7690 | CTC: 1.8615 | CE: 1.5530 | Time: 10.27s\n",
      "Epoch 4 | Batch 600/737 | Loss: 1.7251 | CTC: 1.8360 | CE: 1.4661 | Time: 9.99s\n",
      "Epoch 4 | Batch 610/737 | Loss: 1.7179 | CTC: 1.8372 | CE: 1.4395 | Time: 10.28s\n",
      "Epoch 4 | Batch 620/737 | Loss: 1.8535 | CTC: 1.9652 | CE: 1.5926 | Time: 10.18s\n",
      "Epoch 4 | Batch 630/737 | Loss: 1.6637 | CTC: 1.7955 | CE: 1.3562 | Time: 10.40s\n",
      "Epoch 4 | Batch 640/737 | Loss: 1.7581 | CTC: 1.8803 | CE: 1.4729 | Time: 10.29s\n",
      "Epoch 4 | Batch 650/737 | Loss: 1.7393 | CTC: 1.8529 | CE: 1.4741 | Time: 10.17s\n",
      "Epoch 4 | Batch 660/737 | Loss: 1.7018 | CTC: 1.7732 | CE: 1.5353 | Time: 10.04s\n",
      "Epoch 4 | Batch 670/737 | Loss: 1.7654 | CTC: 1.8570 | CE: 1.5515 | Time: 10.08s\n",
      "Epoch 4 | Batch 680/737 | Loss: 1.6533 | CTC: 1.7685 | CE: 1.3846 | Time: 9.98s\n",
      "Epoch 4 | Batch 690/737 | Loss: 1.7151 | CTC: 1.8337 | CE: 1.4385 | Time: 9.88s\n",
      "Epoch 4 | Batch 700/737 | Loss: 12.7378 | CTC: 17.5784 | CE: 1.4431 | Time: 10.53s\n",
      "Epoch 4 | Batch 710/737 | Loss: 1.7257 | CTC: 1.8437 | CE: 1.4503 | Time: 10.13s\n",
      "Epoch 4 | Batch 720/737 | Loss: 1.6563 | CTC: 1.7763 | CE: 1.3763 | Time: 10.11s\n",
      "Epoch 4 | Batch 730/737 | Loss: 1.7009 | CTC: 1.8194 | CE: 1.4245 | Time: 10.29s\n",
      "Train Loss: 1.9615 | CTC: 2.1526 | CE: 1.5157\n",
      "Val Loss: 1.5880 | CTC: 1.7321 | CE: 1.2518\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prinhnwtwrsntnntrrmdnnrlnrrrrdin thbin\n",
      "\n",
      "Epoch 5/25\n",
      "Epoch 5 | Batch 0/737 | Loss: 1.6565 | CTC: 1.7628 | CE: 1.4084 | Time: 1.07s\n",
      "Epoch 5 | Batch 10/737 | Loss: 1.6816 | CTC: 1.8175 | CE: 1.3645 | Time: 10.44s\n",
      "Epoch 5 | Batch 20/737 | Loss: 1.7153 | CTC: 1.8133 | CE: 1.4868 | Time: 10.23s\n",
      "Epoch 5 | Batch 30/737 | Loss: 1.6565 | CTC: 1.7606 | CE: 1.4136 | Time: 10.31s\n",
      "Epoch 5 | Batch 40/737 | Loss: 1.6752 | CTC: 1.8091 | CE: 1.3626 | Time: 10.10s\n",
      "Epoch 5 | Batch 50/737 | Loss: 1.6857 | CTC: 1.7958 | CE: 1.4289 | Time: 9.84s\n",
      "Epoch 5 | Batch 60/737 | Loss: 1.6617 | CTC: 1.7906 | CE: 1.3610 | Time: 10.17s\n",
      "Epoch 5 | Batch 70/737 | Loss: 1.6401 | CTC: 1.7747 | CE: 1.3262 | Time: 10.18s\n",
      "Epoch 5 | Batch 80/737 | Loss: 1.6615 | CTC: 1.7940 | CE: 1.3524 | Time: 10.26s\n",
      "Epoch 5 | Batch 90/737 | Loss: 1.6787 | CTC: 1.8098 | CE: 1.3731 | Time: 10.62s\n",
      "Epoch 5 | Batch 100/737 | Loss: 1.6011 | CTC: 1.7090 | CE: 1.3493 | Time: 10.25s\n",
      "Epoch 5 | Batch 110/737 | Loss: 1.6121 | CTC: 1.7319 | CE: 1.3327 | Time: 10.25s\n",
      "Epoch 5 | Batch 120/737 | Loss: 1.6270 | CTC: 1.7478 | CE: 1.3452 | Time: 10.23s\n",
      "Epoch 5 | Batch 130/737 | Loss: 1.6499 | CTC: 1.7421 | CE: 1.4347 | Time: 10.29s\n",
      "Epoch 5 | Batch 140/737 | Loss: 1.6845 | CTC: 1.8315 | CE: 1.3414 | Time: 10.20s\n",
      "Epoch 5 | Batch 150/737 | Loss: 6.8036 | CTC: 9.1064 | CE: 1.4304 | Time: 9.77s\n",
      "Epoch 5 | Batch 160/737 | Loss: 1.6335 | CTC: 1.7429 | CE: 1.3782 | Time: 10.08s\n",
      "Epoch 5 | Batch 170/737 | Loss: 1.6242 | CTC: 1.7415 | CE: 1.3505 | Time: 10.24s\n",
      "Epoch 5 | Batch 180/737 | Loss: 1.6623 | CTC: 1.7614 | CE: 1.4309 | Time: 9.96s\n",
      "Epoch 5 | Batch 190/737 | Loss: 1.6457 | CTC: 1.7698 | CE: 1.3562 | Time: 10.33s\n",
      "Epoch 5 | Batch 200/737 | Loss: 1.6410 | CTC: 1.7433 | CE: 1.4023 | Time: 10.44s\n",
      "Epoch 5 | Batch 210/737 | Loss: 1.6156 | CTC: 1.7351 | CE: 1.3368 | Time: 10.19s\n",
      "Epoch 5 | Batch 220/737 | Loss: 1.6194 | CTC: 1.7520 | CE: 1.3099 | Time: 10.15s\n",
      "Epoch 5 | Batch 230/737 | Loss: 1.6282 | CTC: 1.7463 | CE: 1.3525 | Time: 10.16s\n",
      "Epoch 5 | Batch 240/737 | Loss: 1.6055 | CTC: 1.7175 | CE: 1.3440 | Time: 10.32s\n",
      "Epoch 5 | Batch 250/737 | Loss: 1.6233 | CTC: 1.7497 | CE: 1.3285 | Time: 10.15s\n",
      "Epoch 5 | Batch 260/737 | Loss: 1.6373 | CTC: 1.7734 | CE: 1.3197 | Time: 10.21s\n",
      "Epoch 5 | Batch 270/737 | Loss: 1.5727 | CTC: 1.6914 | CE: 1.2958 | Time: 10.19s\n",
      "Epoch 5 | Batch 280/737 | Loss: 1.6599 | CTC: 1.7849 | CE: 1.3682 | Time: 9.96s\n",
      "Epoch 5 | Batch 290/737 | Loss: 1.6534 | CTC: 1.7630 | CE: 1.3976 | Time: 10.37s\n",
      "Epoch 5 | Batch 300/737 | Loss: 1.6051 | CTC: 1.7231 | CE: 1.3296 | Time: 10.14s\n",
      "Epoch 5 | Batch 310/737 | Loss: 1.6274 | CTC: 1.7582 | CE: 1.3222 | Time: 10.21s\n",
      "Epoch 5 | Batch 320/737 | Loss: 1.5806 | CTC: 1.7164 | CE: 1.2637 | Time: 10.16s\n",
      "Epoch 5 | Batch 330/737 | Loss: 8.0686 | CTC: 10.9569 | CE: 1.3291 | Time: 10.20s\n",
      "Epoch 5 | Batch 340/737 | Loss: 1.6500 | CTC: 1.7846 | CE: 1.3359 | Time: 10.18s\n",
      "Epoch 5 | Batch 350/737 | Loss: 1.6303 | CTC: 1.7455 | CE: 1.3614 | Time: 10.00s\n",
      "Epoch 5 | Batch 360/737 | Loss: 1.5562 | CTC: 1.6731 | CE: 1.2835 | Time: 10.24s\n",
      "Epoch 5 | Batch 370/737 | Loss: 1.6063 | CTC: 1.6861 | CE: 1.4203 | Time: 10.07s\n",
      "Epoch 5 | Batch 380/737 | Loss: 1.6691 | CTC: 1.8030 | CE: 1.3567 | Time: 10.02s\n",
      "Epoch 5 | Batch 390/737 | Loss: 1.6386 | CTC: 1.7512 | CE: 1.3758 | Time: 9.88s\n",
      "Epoch 5 | Batch 400/737 | Loss: 1.6572 | CTC: 1.7609 | CE: 1.4153 | Time: 10.11s\n",
      "Epoch 5 | Batch 410/737 | Loss: 1.5582 | CTC: 1.6914 | CE: 1.2473 | Time: 10.52s\n",
      "Epoch 5 | Batch 420/737 | Loss: 1.6005 | CTC: 1.7137 | CE: 1.3364 | Time: 9.84s\n",
      "Epoch 5 | Batch 430/737 | Loss: 1.6039 | CTC: 1.6865 | CE: 1.4110 | Time: 10.11s\n",
      "Epoch 5 | Batch 440/737 | Loss: 1.5920 | CTC: 1.7040 | CE: 1.3306 | Time: 10.25s\n",
      "Epoch 5 | Batch 450/737 | Loss: 1.6467 | CTC: 1.7631 | CE: 1.3753 | Time: 10.29s\n",
      "Epoch 5 | Batch 460/737 | Loss: 1.5692 | CTC: 1.6736 | CE: 1.3256 | Time: 10.20s\n",
      "Epoch 5 | Batch 470/737 | Loss: 1.5834 | CTC: 1.6883 | CE: 1.3389 | Time: 10.22s\n",
      "Epoch 5 | Batch 480/737 | Loss: 1.5871 | CTC: 1.7189 | CE: 1.2794 | Time: 10.02s\n",
      "Epoch 5 | Batch 490/737 | Loss: 1.5499 | CTC: 1.6676 | CE: 1.2754 | Time: 10.16s\n",
      "Epoch 5 | Batch 500/737 | Loss: 1.6386 | CTC: 1.7425 | CE: 1.3961 | Time: 10.18s\n",
      "Epoch 5 | Batch 510/737 | Loss: 1.5896 | CTC: 1.6946 | CE: 1.3446 | Time: 10.20s\n",
      "Epoch 5 | Batch 520/737 | Loss: 1.5706 | CTC: 1.6971 | CE: 1.2755 | Time: 10.24s\n",
      "Epoch 5 | Batch 530/737 | Loss: 1.5435 | CTC: 1.6823 | CE: 1.2197 | Time: 10.17s\n",
      "Epoch 5 | Batch 540/737 | Loss: 1.6164 | CTC: 1.7415 | CE: 1.3246 | Time: 10.17s\n",
      "Epoch 5 | Batch 550/737 | Loss: 1.5208 | CTC: 1.6534 | CE: 1.2115 | Time: 10.26s\n",
      "Epoch 5 | Batch 560/737 | Loss: 1.5684 | CTC: 1.6742 | CE: 1.3217 | Time: 10.13s\n",
      "Epoch 5 | Batch 570/737 | Loss: 1.6360 | CTC: 1.7452 | CE: 1.3811 | Time: 10.20s\n",
      "Epoch 5 | Batch 580/737 | Loss: 1.5325 | CTC: 1.6610 | CE: 1.2328 | Time: 10.58s\n",
      "Epoch 5 | Batch 590/737 | Loss: 1.5670 | CTC: 1.7000 | CE: 1.2569 | Time: 10.15s\n",
      "Epoch 5 | Batch 600/737 | Loss: 1.5452 | CTC: 1.6641 | CE: 1.2677 | Time: 10.32s\n",
      "Epoch 5 | Batch 610/737 | Loss: 1.5234 | CTC: 1.6298 | CE: 1.2752 | Time: 10.15s\n",
      "Epoch 5 | Batch 620/737 | Loss: 1.5696 | CTC: 1.6799 | CE: 1.3123 | Time: 10.47s\n",
      "Epoch 5 | Batch 630/737 | Loss: 1.5136 | CTC: 1.6786 | CE: 1.1286 | Time: 10.06s\n",
      "Epoch 5 | Batch 640/737 | Loss: 12.3812 | CTC: 17.1282 | CE: 1.3050 | Time: 10.10s\n",
      "Epoch 5 | Batch 650/737 | Loss: 1.5783 | CTC: 1.7193 | CE: 1.2493 | Time: 10.12s\n",
      "Epoch 5 | Batch 660/737 | Loss: 1.5443 | CTC: 1.6658 | CE: 1.2608 | Time: 10.31s\n",
      "Epoch 5 | Batch 670/737 | Loss: 1.5477 | CTC: 1.6871 | CE: 1.2223 | Time: 10.11s\n",
      "Epoch 5 | Batch 680/737 | Loss: 1.4925 | CTC: 1.5964 | CE: 1.2502 | Time: 10.24s\n",
      "Epoch 5 | Batch 690/737 | Loss: 1.5533 | CTC: 1.6700 | CE: 1.2811 | Time: 10.13s\n",
      "Epoch 5 | Batch 700/737 | Loss: 1.6121 | CTC: 1.7328 | CE: 1.3304 | Time: 10.20s\n",
      "Epoch 5 | Batch 710/737 | Loss: 1.5073 | CTC: 1.6319 | CE: 1.2166 | Time: 9.95s\n",
      "Epoch 5 | Batch 720/737 | Loss: 1.4506 | CTC: 1.5678 | CE: 1.1769 | Time: 10.11s\n",
      "Epoch 5 | Batch 730/737 | Loss: 1.5053 | CTC: 1.6401 | CE: 1.1908 | Time: 10.11s\n",
      "Train Loss: 1.7795 | CTC: 1.9758 | CE: 1.3217\n",
      "Val Loss: 1.4203 | CTC: 1.5733 | CE: 1.0634\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: printhtnwitpwwrnpssontnsrndifrs rnfroltnrrrprsnd in thebion\n",
      "\n",
      "Epoch 6/25\n",
      "Epoch 6 | Batch 0/737 | Loss: 1.4810 | CTC: 1.5951 | CE: 1.2147 | Time: 0.99s\n",
      "Epoch 6 | Batch 10/737 | Loss: 9.2393 | CTC: 12.6700 | CE: 1.2343 | Time: 10.35s\n",
      "Epoch 6 | Batch 20/737 | Loss: 1.5419 | CTC: 1.6632 | CE: 1.2589 | Time: 10.19s\n",
      "Epoch 6 | Batch 30/737 | Loss: 1.5336 | CTC: 1.6657 | CE: 1.2252 | Time: 10.24s\n",
      "Epoch 6 | Batch 40/737 | Loss: 1.5169 | CTC: 1.6553 | CE: 1.1938 | Time: 10.24s\n",
      "Epoch 6 | Batch 50/737 | Loss: 1.5631 | CTC: 1.6959 | CE: 1.2533 | Time: 10.35s\n",
      "Epoch 6 | Batch 60/737 | Loss: 1.4574 | CTC: 1.5975 | CE: 1.1304 | Time: 10.27s\n",
      "Epoch 6 | Batch 70/737 | Loss: 1.4900 | CTC: 1.6253 | CE: 1.1743 | Time: 10.24s\n",
      "Epoch 6 | Batch 80/737 | Loss: 1.5164 | CTC: 1.6370 | CE: 1.2349 | Time: 10.19s\n",
      "Epoch 6 | Batch 90/737 | Loss: 1.5400 | CTC: 1.6534 | CE: 1.2753 | Time: 10.11s\n",
      "Epoch 6 | Batch 100/737 | Loss: 1.4970 | CTC: 1.6065 | CE: 1.2414 | Time: 10.38s\n",
      "Epoch 6 | Batch 110/737 | Loss: 1.4556 | CTC: 1.5928 | CE: 1.1353 | Time: 10.17s\n",
      "Epoch 6 | Batch 120/737 | Loss: 1.4611 | CTC: 1.5545 | CE: 1.2430 | Time: 9.69s\n",
      "Epoch 6 | Batch 130/737 | Loss: 1.4275 | CTC: 1.5354 | CE: 1.1758 | Time: 10.25s\n",
      "Epoch 6 | Batch 140/737 | Loss: 1.4161 | CTC: 1.5391 | CE: 1.1293 | Time: 10.25s\n",
      "Epoch 6 | Batch 150/737 | Loss: 1.4905 | CTC: 1.6208 | CE: 1.1865 | Time: 10.19s\n",
      "Epoch 6 | Batch 160/737 | Loss: 1.4962 | CTC: 1.6472 | CE: 1.1439 | Time: 10.29s\n",
      "Epoch 6 | Batch 170/737 | Loss: 1.4567 | CTC: 1.6003 | CE: 1.1217 | Time: 10.57s\n",
      "Epoch 6 | Batch 180/737 | Loss: 1.5248 | CTC: 1.6375 | CE: 1.2621 | Time: 10.13s\n",
      "Epoch 6 | Batch 190/737 | Loss: 1.4679 | CTC: 1.5960 | CE: 1.1688 | Time: 10.03s\n",
      "Epoch 6 | Batch 200/737 | Loss: 1.4257 | CTC: 1.5886 | CE: 1.0455 | Time: 10.24s\n",
      "Epoch 6 | Batch 210/737 | Loss: 1.4589 | CTC: 1.6086 | CE: 1.1095 | Time: 10.23s\n",
      "Epoch 6 | Batch 220/737 | Loss: 1.4649 | CTC: 1.6200 | CE: 1.1028 | Time: 10.07s\n",
      "Epoch 6 | Batch 230/737 | Loss: 1.4796 | CTC: 1.5854 | CE: 1.2329 | Time: 10.30s\n",
      "Epoch 6 | Batch 240/737 | Loss: 1.4677 | CTC: 1.5526 | CE: 1.2698 | Time: 10.00s\n",
      "Epoch 6 | Batch 250/737 | Loss: 1.4000 | CTC: 1.5314 | CE: 1.0932 | Time: 10.05s\n",
      "Epoch 6 | Batch 260/737 | Loss: 1.4485 | CTC: 1.5759 | CE: 1.1512 | Time: 10.41s\n",
      "Epoch 6 | Batch 270/737 | Loss: 1.4228 | CTC: 1.5734 | CE: 1.0713 | Time: 9.99s\n",
      "Epoch 6 | Batch 280/737 | Loss: 1.4872 | CTC: 1.6001 | CE: 1.2238 | Time: 10.02s\n",
      "Epoch 6 | Batch 290/737 | Loss: 1.4792 | CTC: 1.6155 | CE: 1.1612 | Time: 10.41s\n",
      "Epoch 6 | Batch 300/737 | Loss: 1.4226 | CTC: 1.5357 | CE: 1.1587 | Time: 10.06s\n",
      "Epoch 6 | Batch 310/737 | Loss: 1.4235 | CTC: 1.5743 | CE: 1.0717 | Time: 10.47s\n",
      "Epoch 6 | Batch 320/737 | Loss: 1.3902 | CTC: 1.4944 | CE: 1.1469 | Time: 10.09s\n",
      "Epoch 6 | Batch 330/737 | Loss: 1.4826 | CTC: 1.6305 | CE: 1.1374 | Time: 10.04s\n",
      "Epoch 6 | Batch 340/737 | Loss: 1.4577 | CTC: 1.5697 | CE: 1.1962 | Time: 10.16s\n",
      "Epoch 6 | Batch 350/737 | Loss: 1.4628 | CTC: 1.5882 | CE: 1.1703 | Time: 10.35s\n",
      "Epoch 6 | Batch 360/737 | Loss: 1.4734 | CTC: 1.5852 | CE: 1.2126 | Time: 10.00s\n",
      "Epoch 6 | Batch 370/737 | Loss: 1.4498 | CTC: 1.5819 | CE: 1.1418 | Time: 10.29s\n",
      "Epoch 6 | Batch 380/737 | Loss: 1.4406 | CTC: 1.5823 | CE: 1.1100 | Time: 10.36s\n",
      "Epoch 6 | Batch 390/737 | Loss: 1.5107 | CTC: 1.6318 | CE: 1.2281 | Time: 10.16s\n",
      "Epoch 6 | Batch 400/737 | Loss: 1.4458 | CTC: 1.5854 | CE: 1.1201 | Time: 10.16s\n",
      "Epoch 6 | Batch 410/737 | Loss: 1.5510 | CTC: 1.7281 | CE: 1.1377 | Time: 10.31s\n",
      "Epoch 6 | Batch 420/737 | Loss: 1.4119 | CTC: 1.5247 | CE: 1.1488 | Time: 10.23s\n",
      "Epoch 6 | Batch 430/737 | Loss: 1.4258 | CTC: 1.5443 | CE: 1.1493 | Time: 10.03s\n",
      "Epoch 6 | Batch 440/737 | Loss: 1.4302 | CTC: 1.5667 | CE: 1.1119 | Time: 10.27s\n",
      "Epoch 6 | Batch 450/737 | Loss: 1.4395 | CTC: 1.5730 | CE: 1.1279 | Time: 10.15s\n",
      "Epoch 6 | Batch 460/737 | Loss: 1.4172 | CTC: 1.5659 | CE: 1.0702 | Time: 10.33s\n",
      "Epoch 6 | Batch 470/737 | Loss: 1.4413 | CTC: 1.5696 | CE: 1.1419 | Time: 10.26s\n",
      "Epoch 6 | Batch 480/737 | Loss: 1.3835 | CTC: 1.5107 | CE: 1.0867 | Time: 10.22s\n",
      "Epoch 6 | Batch 490/737 | Loss: 1.4941 | CTC: 1.6406 | CE: 1.1525 | Time: 10.18s\n",
      "Epoch 6 | Batch 500/737 | Loss: 1.4355 | CTC: 1.5920 | CE: 1.0706 | Time: 10.22s\n",
      "Epoch 6 | Batch 510/737 | Loss: 1.4035 | CTC: 1.5808 | CE: 0.9899 | Time: 10.02s\n",
      "Epoch 6 | Batch 520/737 | Loss: 1.4277 | CTC: 1.5518 | CE: 1.1381 | Time: 10.27s\n",
      "Epoch 6 | Batch 530/737 | Loss: 1.4278 | CTC: 1.5771 | CE: 1.0793 | Time: 10.09s\n",
      "Epoch 6 | Batch 540/737 | Loss: 1.3929 | CTC: 1.5192 | CE: 1.0982 | Time: 10.17s\n",
      "Epoch 6 | Batch 550/737 | Loss: 1.3829 | CTC: 1.5305 | CE: 1.0387 | Time: 10.21s\n",
      "Epoch 6 | Batch 560/737 | Loss: 1.3945 | CTC: 1.5390 | CE: 1.0572 | Time: 10.28s\n",
      "Epoch 6 | Batch 570/737 | Loss: 1.4217 | CTC: 1.5308 | CE: 1.1670 | Time: 9.81s\n",
      "Epoch 6 | Batch 580/737 | Loss: 1.4419 | CTC: 1.5714 | CE: 1.1396 | Time: 10.33s\n",
      "Epoch 6 | Batch 590/737 | Loss: 1.4386 | CTC: 1.5789 | CE: 1.1111 | Time: 10.05s\n",
      "Epoch 6 | Batch 600/737 | Loss: 1.4158 | CTC: 1.5583 | CE: 1.0834 | Time: 10.44s\n",
      "Epoch 6 | Batch 610/737 | Loss: 1.4315 | CTC: 1.5698 | CE: 1.1088 | Time: 10.28s\n",
      "Epoch 6 | Batch 620/737 | Loss: 1.4017 | CTC: 1.5270 | CE: 1.1095 | Time: 10.51s\n",
      "Epoch 6 | Batch 630/737 | Loss: 1.4589 | CTC: 1.6167 | CE: 1.0910 | Time: 10.45s\n",
      "Epoch 6 | Batch 640/737 | Loss: 1.3592 | CTC: 1.4757 | CE: 1.0875 | Time: 10.13s\n",
      "Epoch 6 | Batch 650/737 | Loss: 1.3862 | CTC: 1.5255 | CE: 1.0611 | Time: 9.76s\n",
      "Epoch 6 | Batch 660/737 | Loss: 1.4316 | CTC: 1.5811 | CE: 1.0826 | Time: 10.18s\n",
      "Epoch 6 | Batch 670/737 | Loss: 1.4290 | CTC: 1.5617 | CE: 1.1192 | Time: 9.97s\n",
      "Epoch 6 | Batch 680/737 | Loss: 1.3752 | CTC: 1.5140 | CE: 1.0514 | Time: 9.98s\n",
      "Epoch 6 | Batch 690/737 | Loss: 1.3760 | CTC: 1.5420 | CE: 0.9885 | Time: 10.30s\n",
      "Epoch 6 | Batch 700/737 | Loss: 1.3629 | CTC: 1.5151 | CE: 1.0076 | Time: 10.16s\n",
      "Epoch 6 | Batch 710/737 | Loss: 1.3852 | CTC: 1.5351 | CE: 1.0355 | Time: 10.04s\n",
      "Epoch 6 | Batch 720/737 | Loss: 1.3616 | CTC: 1.5091 | CE: 1.0174 | Time: 10.03s\n",
      "Epoch 6 | Batch 730/737 | Loss: 1.3485 | CTC: 1.4948 | CE: 1.0072 | Time: 9.90s\n",
      "Train Loss: 1.6406 | CTC: 1.8604 | CE: 1.1278\n",
      "Val Loss: 1.2544 | CTC: 1.4181 | CE: 0.8724\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prtinnthnswtpwrapsntnsrntsdifrrs rnotfrolenrrrprsn in thexbin\n",
      "\n",
      "Epoch 7/25\n",
      "Epoch 7 | Batch 0/737 | Loss: 1.3921 | CTC: 1.5362 | CE: 1.0558 | Time: 1.05s\n",
      "Epoch 7 | Batch 10/737 | Loss: 1.3555 | CTC: 1.5076 | CE: 1.0007 | Time: 10.03s\n",
      "Epoch 7 | Batch 20/737 | Loss: 1.3002 | CTC: 1.4515 | CE: 0.9471 | Time: 10.33s\n",
      "Epoch 7 | Batch 30/737 | Loss: 1.3312 | CTC: 1.4964 | CE: 0.9456 | Time: 10.29s\n",
      "Epoch 7 | Batch 40/737 | Loss: 1.3119 | CTC: 1.4318 | CE: 1.0321 | Time: 10.34s\n",
      "Epoch 7 | Batch 50/737 | Loss: 1.4132 | CTC: 1.5551 | CE: 1.0822 | Time: 10.10s\n",
      "Epoch 7 | Batch 60/737 | Loss: 1.3619 | CTC: 1.4851 | CE: 1.0744 | Time: 9.68s\n",
      "Epoch 7 | Batch 70/737 | Loss: 1.3361 | CTC: 1.4734 | CE: 1.0156 | Time: 10.04s\n",
      "Epoch 7 | Batch 80/737 | Loss: 1.3110 | CTC: 1.4467 | CE: 0.9943 | Time: 10.18s\n",
      "Epoch 7 | Batch 90/737 | Loss: 1.2688 | CTC: 1.4019 | CE: 0.9581 | Time: 10.33s\n",
      "Epoch 7 | Batch 100/737 | Loss: 1.2974 | CTC: 1.4476 | CE: 0.9469 | Time: 10.16s\n",
      "Epoch 7 | Batch 110/737 | Loss: 1.3060 | CTC: 1.4587 | CE: 0.9497 | Time: 10.11s\n",
      "Epoch 7 | Batch 120/737 | Loss: 1.2852 | CTC: 1.4218 | CE: 0.9665 | Time: 10.27s\n",
      "Epoch 7 | Batch 130/737 | Loss: 1.2745 | CTC: 1.4198 | CE: 0.9355 | Time: 10.22s\n",
      "Epoch 7 | Batch 140/737 | Loss: 1.2643 | CTC: 1.4065 | CE: 0.9325 | Time: 10.36s\n",
      "Epoch 7 | Batch 150/737 | Loss: 1.3328 | CTC: 1.4586 | CE: 1.0393 | Time: 10.43s\n",
      "Epoch 7 | Batch 160/737 | Loss: 1.3165 | CTC: 1.4631 | CE: 0.9745 | Time: 9.96s\n",
      "Epoch 7 | Batch 170/737 | Loss: 1.3354 | CTC: 1.4790 | CE: 1.0004 | Time: 10.44s\n",
      "Epoch 7 | Batch 180/737 | Loss: 1.2824 | CTC: 1.4288 | CE: 0.9408 | Time: 10.20s\n",
      "Epoch 7 | Batch 190/737 | Loss: 1.3468 | CTC: 1.4780 | CE: 1.0405 | Time: 10.27s\n",
      "Epoch 7 | Batch 200/737 | Loss: 1.3075 | CTC: 1.4427 | CE: 0.9920 | Time: 10.33s\n",
      "Epoch 7 | Batch 210/737 | Loss: 1.2662 | CTC: 1.3669 | CE: 1.0313 | Time: 10.28s\n",
      "Epoch 7 | Batch 220/737 | Loss: 1.2727 | CTC: 1.4124 | CE: 0.9467 | Time: 10.14s\n",
      "Epoch 7 | Batch 230/737 | Loss: 1.3237 | CTC: 1.5157 | CE: 0.8758 | Time: 9.83s\n",
      "Epoch 7 | Batch 240/737 | Loss: 1.2832 | CTC: 1.4555 | CE: 0.8811 | Time: 10.36s\n",
      "Epoch 7 | Batch 250/737 | Loss: 1.3500 | CTC: 1.4890 | CE: 1.0258 | Time: 10.28s\n",
      "Epoch 7 | Batch 260/737 | Loss: 1.3312 | CTC: 1.4869 | CE: 0.9679 | Time: 10.29s\n",
      "Epoch 7 | Batch 270/737 | Loss: 1.2671 | CTC: 1.4029 | CE: 0.9503 | Time: 10.26s\n",
      "Epoch 7 | Batch 280/737 | Loss: 1.3586 | CTC: 1.5203 | CE: 0.9812 | Time: 10.28s\n",
      "Epoch 7 | Batch 290/737 | Loss: 1.2687 | CTC: 1.4386 | CE: 0.8722 | Time: 10.25s\n",
      "Epoch 7 | Batch 300/737 | Loss: 1.2372 | CTC: 1.3940 | CE: 0.8714 | Time: 9.95s\n",
      "Epoch 7 | Batch 310/737 | Loss: 1.3453 | CTC: 1.4872 | CE: 1.0142 | Time: 10.16s\n",
      "Epoch 7 | Batch 320/737 | Loss: 1.3760 | CTC: 1.5311 | CE: 1.0142 | Time: 10.21s\n",
      "Epoch 7 | Batch 330/737 | Loss: 1.2619 | CTC: 1.4215 | CE: 0.8894 | Time: 10.41s\n",
      "Epoch 7 | Batch 340/737 | Loss: 1.2515 | CTC: 1.4049 | CE: 0.8938 | Time: 10.07s\n",
      "Epoch 7 | Batch 350/737 | Loss: 1.2286 | CTC: 1.3727 | CE: 0.8923 | Time: 10.09s\n",
      "Epoch 7 | Batch 360/737 | Loss: 1.2835 | CTC: 1.4179 | CE: 0.9700 | Time: 10.12s\n",
      "Epoch 7 | Batch 370/737 | Loss: 1.3244 | CTC: 1.4448 | CE: 1.0432 | Time: 10.14s\n",
      "Epoch 7 | Batch 380/737 | Loss: 1.3358 | CTC: 1.4722 | CE: 1.0176 | Time: 9.89s\n",
      "Epoch 7 | Batch 390/737 | Loss: 1.3115 | CTC: 1.4530 | CE: 0.9813 | Time: 10.28s\n",
      "Epoch 7 | Batch 400/737 | Loss: 1.3011 | CTC: 1.4276 | CE: 1.0060 | Time: 10.13s\n",
      "Epoch 7 | Batch 410/737 | Loss: 1.2265 | CTC: 1.3886 | CE: 0.8484 | Time: 10.23s\n",
      "Epoch 7 | Batch 420/737 | Loss: 1.2389 | CTC: 1.3854 | CE: 0.8970 | Time: 10.02s\n",
      "Epoch 7 | Batch 430/737 | Loss: 1.2469 | CTC: 1.4052 | CE: 0.8776 | Time: 10.09s\n",
      "Epoch 7 | Batch 440/737 | Loss: 1.3057 | CTC: 1.4618 | CE: 0.9415 | Time: 9.93s\n",
      "Epoch 7 | Batch 450/737 | Loss: 1.2696 | CTC: 1.4091 | CE: 0.9441 | Time: 10.21s\n",
      "Epoch 7 | Batch 460/737 | Loss: 1.2810 | CTC: 1.4395 | CE: 0.9112 | Time: 10.18s\n",
      "Epoch 7 | Batch 470/737 | Loss: 1.3506 | CTC: 1.4866 | CE: 1.0334 | Time: 10.16s\n",
      "Epoch 7 | Batch 480/737 | Loss: 1.2467 | CTC: 1.4081 | CE: 0.8700 | Time: 10.25s\n",
      "Epoch 7 | Batch 490/737 | Loss: 1.2904 | CTC: 1.4282 | CE: 0.9687 | Time: 9.82s\n",
      "Epoch 7 | Batch 500/737 | Loss: 16.4584 | CTC: 23.1027 | CE: 0.9550 | Time: 9.94s\n",
      "Epoch 7 | Batch 510/737 | Loss: 1.2471 | CTC: 1.3678 | CE: 0.9654 | Time: 10.20s\n",
      "Epoch 7 | Batch 520/737 | Loss: 1.2302 | CTC: 1.3909 | CE: 0.8553 | Time: 10.45s\n",
      "Epoch 7 | Batch 530/737 | Loss: 1.2356 | CTC: 1.3796 | CE: 0.8996 | Time: 10.01s\n",
      "Epoch 7 | Batch 540/737 | Loss: 1.3346 | CTC: 1.4731 | CE: 1.0113 | Time: 10.15s\n",
      "Epoch 7 | Batch 550/737 | Loss: 1.2218 | CTC: 1.3786 | CE: 0.8558 | Time: 10.42s\n",
      "Epoch 7 | Batch 560/737 | Loss: 1.2403 | CTC: 1.3808 | CE: 0.9125 | Time: 10.16s\n",
      "Epoch 7 | Batch 570/737 | Loss: 1.3315 | CTC: 1.5193 | CE: 0.8932 | Time: 10.52s\n",
      "Epoch 7 | Batch 580/737 | Loss: 1.3299 | CTC: 1.4600 | CE: 1.0265 | Time: 10.10s\n",
      "Epoch 7 | Batch 590/737 | Loss: 1.2099 | CTC: 1.3815 | CE: 0.8095 | Time: 10.17s\n",
      "Epoch 7 | Batch 600/737 | Loss: 1.2809 | CTC: 1.4381 | CE: 0.9141 | Time: 10.22s\n",
      "Epoch 7 | Batch 610/737 | Loss: 1.1857 | CTC: 1.3179 | CE: 0.8773 | Time: 10.00s\n",
      "Epoch 7 | Batch 620/737 | Loss: 1.2921 | CTC: 1.4190 | CE: 0.9959 | Time: 10.21s\n",
      "Epoch 7 | Batch 630/737 | Loss: 1.2901 | CTC: 1.4447 | CE: 0.9293 | Time: 10.00s\n",
      "Epoch 7 | Batch 640/737 | Loss: 1.2974 | CTC: 1.4465 | CE: 0.9493 | Time: 10.20s\n",
      "Epoch 7 | Batch 650/737 | Loss: 1.3305 | CTC: 1.4579 | CE: 1.0334 | Time: 10.19s\n",
      "Epoch 7 | Batch 660/737 | Loss: 1.2532 | CTC: 1.3996 | CE: 0.9118 | Time: 10.44s\n",
      "Epoch 7 | Batch 670/737 | Loss: 1.2323 | CTC: 1.3960 | CE: 0.8503 | Time: 10.47s\n",
      "Epoch 7 | Batch 680/737 | Loss: 1.2675 | CTC: 1.4374 | CE: 0.8711 | Time: 10.15s\n",
      "Epoch 7 | Batch 690/737 | Loss: 1.2329 | CTC: 1.3728 | CE: 0.9064 | Time: 10.13s\n",
      "Epoch 7 | Batch 700/737 | Loss: 1.2933 | CTC: 1.4547 | CE: 0.9166 | Time: 10.49s\n",
      "Epoch 7 | Batch 710/737 | Loss: 1.2190 | CTC: 1.3841 | CE: 0.8336 | Time: 10.03s\n",
      "Epoch 7 | Batch 720/737 | Loss: 1.2099 | CTC: 1.3515 | CE: 0.8794 | Time: 10.07s\n",
      "Epoch 7 | Batch 730/737 | Loss: 1.2254 | CTC: 1.3755 | CE: 0.8750 | Time: 10.34s\n",
      "Train Loss: 1.4994 | CTC: 1.7334 | CE: 0.9534\n",
      "Val Loss: 1.1082 | CTC: 1.2745 | CE: 0.7203\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prtimnm thancswithpwirenprsntnsrndivfis friotfroalrncprfrrprsent in thexbion\n",
      "\n",
      "Epoch 8/25\n",
      "Epoch 8 | Batch 0/737 | Loss: 1.1596 | CTC: 1.3028 | CE: 0.8254 | Time: 1.08s\n",
      "Epoch 8 | Batch 10/737 | Loss: 1.2036 | CTC: 1.3482 | CE: 0.8661 | Time: 10.21s\n",
      "Epoch 8 | Batch 20/737 | Loss: 1.2035 | CTC: 1.3327 | CE: 0.9022 | Time: 10.07s\n",
      "Epoch 8 | Batch 30/737 | Loss: 1.1305 | CTC: 1.2826 | CE: 0.7754 | Time: 10.20s\n",
      "Epoch 8 | Batch 40/737 | Loss: 1.2421 | CTC: 1.4029 | CE: 0.8671 | Time: 9.96s\n",
      "Epoch 8 | Batch 50/737 | Loss: 1.1993 | CTC: 1.3352 | CE: 0.8820 | Time: 10.24s\n",
      "Epoch 8 | Batch 60/737 | Loss: 1.1799 | CTC: 1.3392 | CE: 0.8084 | Time: 10.51s\n",
      "Epoch 8 | Batch 70/737 | Loss: 1.1606 | CTC: 1.3012 | CE: 0.8324 | Time: 10.27s\n",
      "Epoch 8 | Batch 80/737 | Loss: 1.1720 | CTC: 1.3079 | CE: 0.8550 | Time: 10.05s\n",
      "Epoch 8 | Batch 90/737 | Loss: 1.1672 | CTC: 1.3158 | CE: 0.8205 | Time: 10.21s\n",
      "Epoch 8 | Batch 100/737 | Loss: 1.2288 | CTC: 1.3729 | CE: 0.8926 | Time: 9.92s\n",
      "Epoch 8 | Batch 110/737 | Loss: 1.1623 | CTC: 1.3206 | CE: 0.7927 | Time: 10.44s\n",
      "Epoch 8 | Batch 120/737 | Loss: 1.1909 | CTC: 1.3323 | CE: 0.8609 | Time: 10.30s\n",
      "Epoch 8 | Batch 130/737 | Loss: 1.2122 | CTC: 1.3475 | CE: 0.8964 | Time: 10.20s\n",
      "Epoch 8 | Batch 140/737 | Loss: 1.1731 | CTC: 1.3306 | CE: 0.8055 | Time: 10.07s\n",
      "Epoch 8 | Batch 150/737 | Loss: 1.2358 | CTC: 1.3963 | CE: 0.8613 | Time: 10.14s\n",
      "Epoch 8 | Batch 160/737 | Loss: 1.2024 | CTC: 1.3509 | CE: 0.8559 | Time: 10.24s\n",
      "Epoch 8 | Batch 170/737 | Loss: 1.1325 | CTC: 1.2775 | CE: 0.7940 | Time: 10.30s\n",
      "Epoch 8 | Batch 180/737 | Loss: 1.1913 | CTC: 1.3689 | CE: 0.7771 | Time: 10.16s\n",
      "Epoch 8 | Batch 190/737 | Loss: 1.1425 | CTC: 1.2835 | CE: 0.8135 | Time: 10.22s\n",
      "Epoch 8 | Batch 200/737 | Loss: 1.1780 | CTC: 1.3256 | CE: 0.8337 | Time: 10.39s\n",
      "Epoch 8 | Batch 210/737 | Loss: 1.1734 | CTC: 1.3476 | CE: 0.7670 | Time: 10.12s\n",
      "Epoch 8 | Batch 220/737 | Loss: 1.1894 | CTC: 1.3059 | CE: 0.9177 | Time: 10.28s\n",
      "Epoch 8 | Batch 230/737 | Loss: 1.2217 | CTC: 1.3680 | CE: 0.8801 | Time: 9.95s\n",
      "Epoch 8 | Batch 240/737 | Loss: 1.0922 | CTC: 1.2360 | CE: 0.7565 | Time: 10.35s\n",
      "Epoch 8 | Batch 250/737 | Loss: 1.2282 | CTC: 1.4317 | CE: 0.7534 | Time: 9.88s\n",
      "Epoch 8 | Batch 260/737 | Loss: 1.1849 | CTC: 1.3278 | CE: 0.8517 | Time: 10.23s\n",
      "Epoch 8 | Batch 270/737 | Loss: 1.1337 | CTC: 1.2675 | CE: 0.8214 | Time: 10.05s\n",
      "Epoch 8 | Batch 280/737 | Loss: 1.1993 | CTC: 1.3725 | CE: 0.7950 | Time: 10.26s\n",
      "Epoch 8 | Batch 290/737 | Loss: 1.1589 | CTC: 1.2906 | CE: 0.8516 | Time: 10.07s\n",
      "Epoch 8 | Batch 300/737 | Loss: 1.2019 | CTC: 1.3474 | CE: 0.8624 | Time: 10.14s\n",
      "Epoch 8 | Batch 310/737 | Loss: 1.1088 | CTC: 1.2840 | CE: 0.7000 | Time: 10.07s\n",
      "Epoch 8 | Batch 320/737 | Loss: 1.1725 | CTC: 1.3296 | CE: 0.8061 | Time: 10.47s\n",
      "Epoch 8 | Batch 330/737 | Loss: 8.1665 | CTC: 11.3159 | CE: 0.8178 | Time: 10.27s\n",
      "Epoch 8 | Batch 340/737 | Loss: 1.2189 | CTC: 1.3814 | CE: 0.8398 | Time: 9.96s\n",
      "Epoch 8 | Batch 350/737 | Loss: 1.2315 | CTC: 1.3738 | CE: 0.8996 | Time: 10.32s\n",
      "Epoch 8 | Batch 360/737 | Loss: 1.1610 | CTC: 1.3135 | CE: 0.8052 | Time: 10.07s\n",
      "Epoch 8 | Batch 370/737 | Loss: 1.1286 | CTC: 1.3103 | CE: 0.7046 | Time: 10.16s\n",
      "Epoch 8 | Batch 380/737 | Loss: 1.1251 | CTC: 1.3134 | CE: 0.6858 | Time: 10.45s\n",
      "Epoch 8 | Batch 390/737 | Loss: 1.1180 | CTC: 1.2594 | CE: 0.7880 | Time: 9.98s\n",
      "Epoch 8 | Batch 400/737 | Loss: 1.1317 | CTC: 1.2707 | CE: 0.8074 | Time: 10.18s\n",
      "Epoch 8 | Batch 410/737 | Loss: 1.1546 | CTC: 1.3174 | CE: 0.7747 | Time: 10.24s\n",
      "Epoch 8 | Batch 420/737 | Loss: 1.2011 | CTC: 1.3686 | CE: 0.8104 | Time: 10.22s\n",
      "Epoch 8 | Batch 430/737 | Loss: 1.1304 | CTC: 1.2931 | CE: 0.7506 | Time: 10.37s\n",
      "Epoch 8 | Batch 440/737 | Loss: 1.1887 | CTC: 1.3497 | CE: 0.8130 | Time: 9.94s\n",
      "Epoch 8 | Batch 450/737 | Loss: 1.1173 | CTC: 1.2759 | CE: 0.7472 | Time: 10.46s\n",
      "Epoch 8 | Batch 460/737 | Loss: 1.1724 | CTC: 1.3241 | CE: 0.8185 | Time: 10.07s\n",
      "Epoch 8 | Batch 470/737 | Loss: 1.1368 | CTC: 1.2787 | CE: 0.8055 | Time: 10.18s\n",
      "Epoch 8 | Batch 480/737 | Loss: 1.1454 | CTC: 1.3152 | CE: 0.7492 | Time: 10.24s\n",
      "Epoch 8 | Batch 490/737 | Loss: 1.1053 | CTC: 1.2419 | CE: 0.7866 | Time: 10.26s\n",
      "Epoch 8 | Batch 500/737 | Loss: 1.1045 | CTC: 1.2369 | CE: 0.7955 | Time: 10.36s\n",
      "Epoch 8 | Batch 510/737 | Loss: 1.1970 | CTC: 1.3568 | CE: 0.8240 | Time: 10.40s\n",
      "Epoch 8 | Batch 520/737 | Loss: 1.1304 | CTC: 1.2818 | CE: 0.7771 | Time: 9.98s\n",
      "Epoch 8 | Batch 530/737 | Loss: 1.1679 | CTC: 1.3311 | CE: 0.7870 | Time: 10.11s\n",
      "Epoch 8 | Batch 540/737 | Loss: 1.0731 | CTC: 1.2310 | CE: 0.7048 | Time: 10.21s\n",
      "Epoch 8 | Batch 550/737 | Loss: 1.1627 | CTC: 1.3021 | CE: 0.8373 | Time: 10.06s\n",
      "Epoch 8 | Batch 560/737 | Loss: 1.1326 | CTC: 1.2913 | CE: 0.7624 | Time: 9.86s\n",
      "Epoch 8 | Batch 570/737 | Loss: 1.1291 | CTC: 1.2468 | CE: 0.8545 | Time: 10.07s\n",
      "Epoch 8 | Batch 580/737 | Loss: 1.0938 | CTC: 1.2301 | CE: 0.7758 | Time: 10.35s\n",
      "Epoch 8 | Batch 590/737 | Loss: 1.1239 | CTC: 1.2731 | CE: 0.7760 | Time: 10.16s\n",
      "Epoch 8 | Batch 600/737 | Loss: 1.0691 | CTC: 1.2405 | CE: 0.6689 | Time: 9.81s\n",
      "Epoch 8 | Batch 610/737 | Loss: 1.1698 | CTC: 1.3186 | CE: 0.8224 | Time: 10.22s\n",
      "Epoch 8 | Batch 620/737 | Loss: 1.1617 | CTC: 1.3248 | CE: 0.7813 | Time: 10.13s\n",
      "Epoch 8 | Batch 630/737 | Loss: 1.0921 | CTC: 1.2603 | CE: 0.6998 | Time: 10.36s\n",
      "Epoch 8 | Batch 640/737 | Loss: 1.1566 | CTC: 1.3104 | CE: 0.7978 | Time: 10.10s\n",
      "Epoch 8 | Batch 650/737 | Loss: 1.0583 | CTC: 1.2219 | CE: 0.6764 | Time: 9.88s\n",
      "Epoch 8 | Batch 660/737 | Loss: 1.1919 | CTC: 1.3498 | CE: 0.8235 | Time: 10.38s\n",
      "Epoch 8 | Batch 670/737 | Loss: 1.1291 | CTC: 1.2577 | CE: 0.8290 | Time: 10.21s\n",
      "Epoch 8 | Batch 680/737 | Loss: 1.1445 | CTC: 1.2797 | CE: 0.8288 | Time: 10.32s\n",
      "Epoch 8 | Batch 690/737 | Loss: 1.0610 | CTC: 1.2160 | CE: 0.6993 | Time: 9.99s\n",
      "Epoch 8 | Batch 700/737 | Loss: 1.1107 | CTC: 1.2612 | CE: 0.7595 | Time: 10.41s\n",
      "Epoch 8 | Batch 710/737 | Loss: 1.0475 | CTC: 1.2052 | CE: 0.6797 | Time: 9.99s\n",
      "Epoch 8 | Batch 720/737 | Loss: 1.0889 | CTC: 1.2466 | CE: 0.7207 | Time: 10.20s\n",
      "Epoch 8 | Batch 730/737 | Loss: 1.1424 | CTC: 1.3028 | CE: 0.7683 | Time: 10.09s\n",
      "Train Loss: 1.4048 | CTC: 1.6590 | CE: 0.8117\n",
      "Val Loss: 0.9922 | CTC: 1.1611 | CE: 0.5981\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prntinim theltsancswlithpw aredpreessnt cnsrndivfis frostinotfroltaronrafrrprsentd in the ibion\n",
      "\n",
      "Epoch 9/25\n",
      "Epoch 9 | Batch 0/737 | Loss: 1.0559 | CTC: 1.1988 | CE: 0.7224 | Time: 1.02s\n",
      "Epoch 9 | Batch 10/737 | Loss: 1.0356 | CTC: 1.1794 | CE: 0.7001 | Time: 10.02s\n",
      "Epoch 9 | Batch 20/737 | Loss: 1.0691 | CTC: 1.2167 | CE: 0.7245 | Time: 10.48s\n",
      "Epoch 9 | Batch 30/737 | Loss: 1.0785 | CTC: 1.2188 | CE: 0.7511 | Time: 10.43s\n",
      "Epoch 9 | Batch 40/737 | Loss: 18.7489 | CTC: 26.4849 | CE: 0.6983 | Time: 10.23s\n",
      "Epoch 9 | Batch 50/737 | Loss: 1.0723 | CTC: 1.2517 | CE: 0.6537 | Time: 10.36s\n",
      "Epoch 9 | Batch 60/737 | Loss: 1.0573 | CTC: 1.2023 | CE: 0.7189 | Time: 10.30s\n",
      "Epoch 9 | Batch 70/737 | Loss: 1.1329 | CTC: 1.3074 | CE: 0.7258 | Time: 10.29s\n",
      "Epoch 9 | Batch 80/737 | Loss: 1.0271 | CTC: 1.1606 | CE: 0.7157 | Time: 10.35s\n",
      "Epoch 9 | Batch 90/737 | Loss: 1.1191 | CTC: 1.2952 | CE: 0.7080 | Time: 10.09s\n",
      "Epoch 9 | Batch 100/737 | Loss: 1.0803 | CTC: 1.2377 | CE: 0.7131 | Time: 10.29s\n",
      "Epoch 9 | Batch 110/737 | Loss: 1.0359 | CTC: 1.1947 | CE: 0.6654 | Time: 10.05s\n",
      "Epoch 9 | Batch 120/737 | Loss: 1.0912 | CTC: 1.2461 | CE: 0.7297 | Time: 10.21s\n",
      "Epoch 9 | Batch 130/737 | Loss: 1.0921 | CTC: 1.2445 | CE: 0.7366 | Time: 10.00s\n",
      "Epoch 9 | Batch 140/737 | Loss: 1.0457 | CTC: 1.2028 | CE: 0.6792 | Time: 10.18s\n",
      "Epoch 9 | Batch 150/737 | Loss: 1.1017 | CTC: 1.2530 | CE: 0.7489 | Time: 10.08s\n",
      "Epoch 9 | Batch 160/737 | Loss: 1.0690 | CTC: 1.2176 | CE: 0.7223 | Time: 10.04s\n",
      "Epoch 9 | Batch 170/737 | Loss: 1.0176 | CTC: 1.1763 | CE: 0.6474 | Time: 10.31s\n",
      "Epoch 9 | Batch 180/737 | Loss: 12.1318 | CTC: 17.0289 | CE: 0.7054 | Time: 10.30s\n",
      "Epoch 9 | Batch 190/737 | Loss: 1.0827 | CTC: 1.2447 | CE: 0.7047 | Time: 9.93s\n",
      "Epoch 9 | Batch 200/737 | Loss: 1.0024 | CTC: 1.1577 | CE: 0.6400 | Time: 10.18s\n",
      "Epoch 9 | Batch 210/737 | Loss: 1.0647 | CTC: 1.2045 | CE: 0.7384 | Time: 10.05s\n",
      "Epoch 9 | Batch 220/737 | Loss: 1.0821 | CTC: 1.2460 | CE: 0.6995 | Time: 10.29s\n",
      "Epoch 9 | Batch 230/737 | Loss: 1.0986 | CTC: 1.2406 | CE: 0.7674 | Time: 10.22s\n",
      "Epoch 9 | Batch 240/737 | Loss: 1.0495 | CTC: 1.2168 | CE: 0.6592 | Time: 10.43s\n",
      "Epoch 9 | Batch 250/737 | Loss: 1.1172 | CTC: 1.2794 | CE: 0.7388 | Time: 10.39s\n",
      "Epoch 9 | Batch 260/737 | Loss: 1.0728 | CTC: 1.1901 | CE: 0.7993 | Time: 9.71s\n",
      "Epoch 9 | Batch 270/737 | Loss: 1.0998 | CTC: 1.2321 | CE: 0.7911 | Time: 10.23s\n",
      "Epoch 9 | Batch 280/737 | Loss: 1.1155 | CTC: 1.2589 | CE: 0.7809 | Time: 10.14s\n",
      "Epoch 9 | Batch 290/737 | Loss: 1.0417 | CTC: 1.2067 | CE: 0.6567 | Time: 10.32s\n",
      "Epoch 9 | Batch 300/737 | Loss: 1.0374 | CTC: 1.2128 | CE: 0.6280 | Time: 10.28s\n",
      "Epoch 9 | Batch 310/737 | Loss: 1.0763 | CTC: 1.2272 | CE: 0.7241 | Time: 10.31s\n",
      "Epoch 9 | Batch 320/737 | Loss: 1.0438 | CTC: 1.2087 | CE: 0.6589 | Time: 9.73s\n",
      "Epoch 9 | Batch 330/737 | Loss: 1.0796 | CTC: 1.2504 | CE: 0.6811 | Time: 10.03s\n",
      "Epoch 9 | Batch 340/737 | Loss: 1.1421 | CTC: 1.2984 | CE: 0.7775 | Time: 10.20s\n",
      "Epoch 9 | Batch 350/737 | Loss: 1.0499 | CTC: 1.2035 | CE: 0.6915 | Time: 10.17s\n",
      "Epoch 9 | Batch 360/737 | Loss: 1.0400 | CTC: 1.1890 | CE: 0.6922 | Time: 10.12s\n",
      "Epoch 9 | Batch 370/737 | Loss: 1.0794 | CTC: 1.2203 | CE: 0.7506 | Time: 9.79s\n",
      "Epoch 9 | Batch 380/737 | Loss: 1.0901 | CTC: 1.2254 | CE: 0.7746 | Time: 10.20s\n",
      "Epoch 9 | Batch 390/737 | Loss: 1.1134 | CTC: 1.2619 | CE: 0.7669 | Time: 10.46s\n",
      "Epoch 9 | Batch 400/737 | Loss: 0.9609 | CTC: 1.1084 | CE: 0.6167 | Time: 10.22s\n",
      "Epoch 9 | Batch 410/737 | Loss: 1.0321 | CTC: 1.1961 | CE: 0.6495 | Time: 10.08s\n",
      "Epoch 9 | Batch 420/737 | Loss: 1.0530 | CTC: 1.2072 | CE: 0.6932 | Time: 10.07s\n",
      "Epoch 9 | Batch 430/737 | Loss: 1.1578 | CTC: 1.3058 | CE: 0.8124 | Time: 10.31s\n",
      "Epoch 9 | Batch 440/737 | Loss: 1.0946 | CTC: 1.2684 | CE: 0.6891 | Time: 10.10s\n",
      "Epoch 9 | Batch 450/737 | Loss: 1.1047 | CTC: 1.2767 | CE: 0.7034 | Time: 10.13s\n",
      "Epoch 9 | Batch 460/737 | Loss: 1.0042 | CTC: 1.1553 | CE: 0.6514 | Time: 10.40s\n",
      "Epoch 9 | Batch 470/737 | Loss: 1.0731 | CTC: 1.2202 | CE: 0.7299 | Time: 10.06s\n",
      "Epoch 9 | Batch 480/737 | Loss: 1.0978 | CTC: 1.2382 | CE: 0.7703 | Time: 10.30s\n",
      "Epoch 9 | Batch 490/737 | Loss: 0.9718 | CTC: 1.1224 | CE: 0.6205 | Time: 9.99s\n",
      "Epoch 9 | Batch 500/737 | Loss: 1.0912 | CTC: 1.2510 | CE: 0.7186 | Time: 10.22s\n",
      "Epoch 9 | Batch 510/737 | Loss: 1.0460 | CTC: 1.2084 | CE: 0.6670 | Time: 10.20s\n",
      "Epoch 9 | Batch 520/737 | Loss: 1.0270 | CTC: 1.2101 | CE: 0.5998 | Time: 10.17s\n",
      "Epoch 9 | Batch 530/737 | Loss: 0.9805 | CTC: 1.1335 | CE: 0.6234 | Time: 10.48s\n",
      "Epoch 9 | Batch 540/737 | Loss: 1.0185 | CTC: 1.1740 | CE: 0.6558 | Time: 10.22s\n",
      "Epoch 9 | Batch 550/737 | Loss: 1.0536 | CTC: 1.2146 | CE: 0.6781 | Time: 10.30s\n",
      "Epoch 9 | Batch 560/737 | Loss: 1.0492 | CTC: 1.2292 | CE: 0.6293 | Time: 9.63s\n",
      "Epoch 9 | Batch 570/737 | Loss: 1.0707 | CTC: 1.2356 | CE: 0.6859 | Time: 10.11s\n",
      "Epoch 9 | Batch 580/737 | Loss: 1.0717 | CTC: 1.2314 | CE: 0.6993 | Time: 10.29s\n",
      "Epoch 9 | Batch 590/737 | Loss: 1.0098 | CTC: 1.1869 | CE: 0.5965 | Time: 10.26s\n",
      "Epoch 9 | Batch 600/737 | Loss: 1.0074 | CTC: 1.1754 | CE: 0.6154 | Time: 10.53s\n",
      "Epoch 9 | Batch 610/737 | Loss: 1.0388 | CTC: 1.1790 | CE: 0.7117 | Time: 10.47s\n",
      "Epoch 9 | Batch 620/737 | Loss: 0.9067 | CTC: 1.0158 | CE: 0.6521 | Time: 10.35s\n",
      "Epoch 9 | Batch 630/737 | Loss: 1.1017 | CTC: 1.2692 | CE: 0.7108 | Time: 10.10s\n",
      "Epoch 9 | Batch 640/737 | Loss: 1.1216 | CTC: 1.2942 | CE: 0.7188 | Time: 10.12s\n",
      "Epoch 9 | Batch 650/737 | Loss: 1.0603 | CTC: 1.2286 | CE: 0.6675 | Time: 10.41s\n",
      "Epoch 9 | Batch 660/737 | Loss: 1.0383 | CTC: 1.2057 | CE: 0.6477 | Time: 10.25s\n",
      "Epoch 9 | Batch 670/737 | Loss: 1.0633 | CTC: 1.2357 | CE: 0.6612 | Time: 10.10s\n",
      "Epoch 9 | Batch 680/737 | Loss: 1.0124 | CTC: 1.1677 | CE: 0.6500 | Time: 10.28s\n",
      "Epoch 9 | Batch 690/737 | Loss: 0.9899 | CTC: 1.1724 | CE: 0.5641 | Time: 10.29s\n",
      "Epoch 9 | Batch 700/737 | Loss: 1.0503 | CTC: 1.1905 | CE: 0.7230 | Time: 10.31s\n",
      "Epoch 9 | Batch 710/737 | Loss: 0.9513 | CTC: 1.1156 | CE: 0.5679 | Time: 10.15s\n",
      "Epoch 9 | Batch 720/737 | Loss: 18.1778 | CTC: 25.7267 | CE: 0.5636 | Time: 10.16s\n",
      "Epoch 9 | Batch 730/737 | Loss: 1.0013 | CTC: 1.1591 | CE: 0.6333 | Time: 10.40s\n",
      "Train Loss: 1.3068 | CTC: 1.5683 | CE: 0.6966\n",
      "Val Loss: 0.9305 | CTC: 1.0708 | CE: 0.6030\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prntingim thelsencswlith pwich redpreesnt conrn difis fromstionotfromallarncrarrprsentin theexibion\n",
      "\n",
      "Epoch 10/25\n",
      "Epoch 10 | Batch 0/737 | Loss: 1.0428 | CTC: 1.1866 | CE: 0.7070 | Time: 1.07s\n",
      "Epoch 10 | Batch 10/737 | Loss: 0.9848 | CTC: 1.1183 | CE: 0.6734 | Time: 10.14s\n",
      "Epoch 10 | Batch 20/737 | Loss: 0.9405 | CTC: 1.1050 | CE: 0.5568 | Time: 10.00s\n",
      "Epoch 10 | Batch 30/737 | Loss: 0.9793 | CTC: 1.1451 | CE: 0.5926 | Time: 10.25s\n",
      "Epoch 10 | Batch 40/737 | Loss: 1.0032 | CTC: 1.1817 | CE: 0.5865 | Time: 10.34s\n",
      "Epoch 10 | Batch 50/737 | Loss: 1.0075 | CTC: 1.1744 | CE: 0.6182 | Time: 10.24s\n",
      "Epoch 10 | Batch 60/737 | Loss: 1.0340 | CTC: 1.1777 | CE: 0.6988 | Time: 10.37s\n",
      "Epoch 10 | Batch 70/737 | Loss: 0.9793 | CTC: 1.1358 | CE: 0.6141 | Time: 10.32s\n",
      "Epoch 10 | Batch 80/737 | Loss: 0.9356 | CTC: 1.0650 | CE: 0.6336 | Time: 10.03s\n",
      "Epoch 10 | Batch 90/737 | Loss: 0.9533 | CTC: 1.1129 | CE: 0.5811 | Time: 10.31s\n",
      "Epoch 10 | Batch 100/737 | Loss: 0.8400 | CTC: 0.9869 | CE: 0.4972 | Time: 10.54s\n",
      "Epoch 10 | Batch 110/737 | Loss: 1.0778 | CTC: 1.2370 | CE: 0.7063 | Time: 10.30s\n",
      "Epoch 10 | Batch 120/737 | Loss: 0.9945 | CTC: 1.1410 | CE: 0.6526 | Time: 9.97s\n",
      "Epoch 10 | Batch 130/737 | Loss: 1.0103 | CTC: 1.1545 | CE: 0.6739 | Time: 10.40s\n",
      "Epoch 10 | Batch 140/737 | Loss: 0.9890 | CTC: 1.1440 | CE: 0.6275 | Time: 10.03s\n",
      "Epoch 10 | Batch 150/737 | Loss: 1.0536 | CTC: 1.2282 | CE: 0.6463 | Time: 10.29s\n",
      "Epoch 10 | Batch 160/737 | Loss: 0.9429 | CTC: 1.1122 | CE: 0.5479 | Time: 10.24s\n",
      "Epoch 10 | Batch 170/737 | Loss: 0.9836 | CTC: 1.1427 | CE: 0.6125 | Time: 10.30s\n",
      "Epoch 10 | Batch 180/737 | Loss: 0.9693 | CTC: 1.1407 | CE: 0.5695 | Time: 9.97s\n",
      "Epoch 10 | Batch 190/737 | Loss: 0.8816 | CTC: 1.0379 | CE: 0.5169 | Time: 10.43s\n",
      "Epoch 10 | Batch 200/737 | Loss: 1.0009 | CTC: 1.1695 | CE: 0.6074 | Time: 10.03s\n",
      "Epoch 10 | Batch 210/737 | Loss: 0.9257 | CTC: 1.0929 | CE: 0.5358 | Time: 10.12s\n",
      "Epoch 10 | Batch 220/737 | Loss: 1.0596 | CTC: 1.1965 | CE: 0.7402 | Time: 10.26s\n",
      "Epoch 10 | Batch 230/737 | Loss: 1.0512 | CTC: 1.1658 | CE: 0.7836 | Time: 10.00s\n",
      "Epoch 10 | Batch 240/737 | Loss: 0.9706 | CTC: 1.1118 | CE: 0.6409 | Time: 10.29s\n",
      "Epoch 10 | Batch 250/737 | Loss: 0.9363 | CTC: 1.0923 | CE: 0.5723 | Time: 10.13s\n",
      "Epoch 10 | Batch 260/737 | Loss: 0.9304 | CTC: 1.0853 | CE: 0.5689 | Time: 10.38s\n",
      "Epoch 10 | Batch 270/737 | Loss: 0.9371 | CTC: 1.0848 | CE: 0.5927 | Time: 9.98s\n",
      "Epoch 10 | Batch 280/737 | Loss: 0.9908 | CTC: 1.1233 | CE: 0.6814 | Time: 10.22s\n",
      "Epoch 10 | Batch 290/737 | Loss: 0.9894 | CTC: 1.1217 | CE: 0.6806 | Time: 10.22s\n",
      "Epoch 10 | Batch 300/737 | Loss: 0.9524 | CTC: 1.1151 | CE: 0.5727 | Time: 10.33s\n",
      "Epoch 10 | Batch 310/737 | Loss: 1.0338 | CTC: 1.2067 | CE: 0.6302 | Time: 10.16s\n",
      "Epoch 10 | Batch 320/737 | Loss: 1.0007 | CTC: 1.1570 | CE: 0.6360 | Time: 10.32s\n",
      "Epoch 10 | Batch 330/737 | Loss: 1.0000 | CTC: 1.1402 | CE: 0.6730 | Time: 10.41s\n",
      "Epoch 10 | Batch 340/737 | Loss: 0.9328 | CTC: 1.0861 | CE: 0.5752 | Time: 10.04s\n",
      "Epoch 10 | Batch 350/737 | Loss: 1.0110 | CTC: 1.1897 | CE: 0.5940 | Time: 10.36s\n",
      "Epoch 10 | Batch 360/737 | Loss: 0.9360 | CTC: 1.0901 | CE: 0.5764 | Time: 10.30s\n",
      "Epoch 10 | Batch 370/737 | Loss: 0.9712 | CTC: 1.1204 | CE: 0.6230 | Time: 10.20s\n",
      "Epoch 10 | Batch 380/737 | Loss: 1.0308 | CTC: 1.2118 | CE: 0.6086 | Time: 10.06s\n",
      "Epoch 10 | Batch 390/737 | Loss: 0.9120 | CTC: 1.0733 | CE: 0.5356 | Time: 10.19s\n",
      "Epoch 10 | Batch 400/737 | Loss: 0.9708 | CTC: 1.1067 | CE: 0.6538 | Time: 9.92s\n",
      "Epoch 10 | Batch 410/737 | Loss: 0.9666 | CTC: 1.1454 | CE: 0.5495 | Time: 10.23s\n",
      "Epoch 10 | Batch 420/737 | Loss: 0.9720 | CTC: 1.1296 | CE: 0.6042 | Time: 10.14s\n",
      "Epoch 10 | Batch 430/737 | Loss: 1.0091 | CTC: 1.1651 | CE: 0.6452 | Time: 10.32s\n",
      "Epoch 10 | Batch 440/737 | Loss: 1.0347 | CTC: 1.2099 | CE: 0.6259 | Time: 10.14s\n",
      "Epoch 10 | Batch 450/737 | Loss: 1.0136 | CTC: 1.1805 | CE: 0.6242 | Time: 10.08s\n",
      "Epoch 10 | Batch 460/737 | Loss: 0.9453 | CTC: 1.0911 | CE: 0.6052 | Time: 10.27s\n",
      "Epoch 10 | Batch 470/737 | Loss: 0.9452 | CTC: 1.0968 | CE: 0.5914 | Time: 10.45s\n",
      "Epoch 10 | Batch 480/737 | Loss: 0.9397 | CTC: 1.1033 | CE: 0.5578 | Time: 10.09s\n",
      "Epoch 10 | Batch 490/737 | Loss: 0.8984 | CTC: 1.0461 | CE: 0.5538 | Time: 10.04s\n",
      "Epoch 10 | Batch 500/737 | Loss: 0.9173 | CTC: 1.0619 | CE: 0.5797 | Time: 10.30s\n",
      "Epoch 10 | Batch 510/737 | Loss: 1.0281 | CTC: 1.1613 | CE: 0.7173 | Time: 10.28s\n",
      "Epoch 10 | Batch 520/737 | Loss: 0.8999 | CTC: 1.0747 | CE: 0.4921 | Time: 10.39s\n",
      "Epoch 10 | Batch 530/737 | Loss: 1.0383 | CTC: 1.2176 | CE: 0.6200 | Time: 10.07s\n",
      "Epoch 10 | Batch 540/737 | Loss: 0.9671 | CTC: 1.1560 | CE: 0.5265 | Time: 10.34s\n",
      "Epoch 10 | Batch 550/737 | Loss: 0.9074 | CTC: 1.0506 | CE: 0.5733 | Time: 10.01s\n",
      "Epoch 10 | Batch 560/737 | Loss: 1.0112 | CTC: 1.1542 | CE: 0.6777 | Time: 10.27s\n",
      "Epoch 10 | Batch 570/737 | Loss: 0.9302 | CTC: 1.1100 | CE: 0.5109 | Time: 10.37s\n",
      "Epoch 10 | Batch 580/737 | Loss: 0.9163 | CTC: 1.0535 | CE: 0.5960 | Time: 10.16s\n",
      "Epoch 10 | Batch 590/737 | Loss: 0.9259 | CTC: 1.0670 | CE: 0.5967 | Time: 10.26s\n",
      "Epoch 10 | Batch 600/737 | Loss: 0.9782 | CTC: 1.1358 | CE: 0.6103 | Time: 10.01s\n",
      "Epoch 10 | Batch 610/737 | Loss: 0.9339 | CTC: 1.0925 | CE: 0.5638 | Time: 9.93s\n",
      "Epoch 10 | Batch 620/737 | Loss: 0.8519 | CTC: 1.0078 | CE: 0.4883 | Time: 10.12s\n",
      "Epoch 10 | Batch 630/737 | Loss: 0.8983 | CTC: 1.0487 | CE: 0.5475 | Time: 10.34s\n",
      "Epoch 10 | Batch 640/737 | Loss: 0.9704 | CTC: 1.1117 | CE: 0.6406 | Time: 9.82s\n",
      "Epoch 10 | Batch 650/737 | Loss: 1.0672 | CTC: 1.2537 | CE: 0.6319 | Time: 10.06s\n",
      "Epoch 10 | Batch 660/737 | Loss: 1.0147 | CTC: 1.1835 | CE: 0.6208 | Time: 10.06s\n",
      "Epoch 10 | Batch 670/737 | Loss: 0.9736 | CTC: 1.1205 | CE: 0.6309 | Time: 10.46s\n",
      "Epoch 10 | Batch 680/737 | Loss: 0.9793 | CTC: 1.1473 | CE: 0.5874 | Time: 9.98s\n",
      "Epoch 10 | Batch 690/737 | Loss: 0.9880 | CTC: 1.1525 | CE: 0.6041 | Time: 9.98s\n",
      "Epoch 10 | Batch 700/737 | Loss: 0.9142 | CTC: 1.0750 | CE: 0.5390 | Time: 10.19s\n",
      "Epoch 10 | Batch 710/737 | Loss: 0.9365 | CTC: 1.0658 | CE: 0.6348 | Time: 9.93s\n",
      "Epoch 10 | Batch 720/737 | Loss: 0.9668 | CTC: 1.1245 | CE: 0.5989 | Time: 10.42s\n",
      "Epoch 10 | Batch 730/737 | Loss: 0.8471 | CTC: 0.9993 | CE: 0.4920 | Time: 10.35s\n",
      "Train Loss: 1.2206 | CTC: 1.4829 | CE: 0.6087\n",
      "Val Loss: 0.8440 | CTC: 1.0009 | CE: 0.4778\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prntinin theltsencs withpwhich aredpresnt conern difis frommstinotfrom alt aronncrarrprsent in theexibtion\n",
      "\n",
      "Epoch 11/25\n",
      "Epoch 11 | Batch 0/737 | Loss: 0.9109 | CTC: 1.0310 | CE: 0.6305 | Time: 0.99s\n",
      "Epoch 11 | Batch 10/737 | Loss: 0.9629 | CTC: 1.1133 | CE: 0.6119 | Time: 10.29s\n",
      "Epoch 11 | Batch 20/737 | Loss: 0.9425 | CTC: 1.0981 | CE: 0.5796 | Time: 10.20s\n",
      "Epoch 11 | Batch 30/737 | Loss: 0.8433 | CTC: 1.0176 | CE: 0.4367 | Time: 9.95s\n",
      "Epoch 11 | Batch 40/737 | Loss: 0.8977 | CTC: 1.0705 | CE: 0.4946 | Time: 10.34s\n",
      "Epoch 11 | Batch 50/737 | Loss: 0.9313 | CTC: 1.1038 | CE: 0.5287 | Time: 10.20s\n",
      "Epoch 11 | Batch 60/737 | Loss: 0.9018 | CTC: 1.0703 | CE: 0.5086 | Time: 10.37s\n",
      "Epoch 11 | Batch 70/737 | Loss: 0.8709 | CTC: 1.0301 | CE: 0.4994 | Time: 9.85s\n",
      "Epoch 11 | Batch 80/737 | Loss: 0.8783 | CTC: 1.0455 | CE: 0.4883 | Time: 10.22s\n",
      "Epoch 11 | Batch 90/737 | Loss: 0.8700 | CTC: 1.0081 | CE: 0.5476 | Time: 10.35s\n",
      "Epoch 11 | Batch 100/737 | Loss: 0.9326 | CTC: 1.0971 | CE: 0.5487 | Time: 10.03s\n",
      "Epoch 11 | Batch 110/737 | Loss: 0.8645 | CTC: 1.0092 | CE: 0.5267 | Time: 9.90s\n",
      "Epoch 11 | Batch 120/737 | Loss: 0.9622 | CTC: 1.1178 | CE: 0.5990 | Time: 10.36s\n",
      "Epoch 11 | Batch 130/737 | Loss: 0.9250 | CTC: 1.0735 | CE: 0.5785 | Time: 10.09s\n",
      "Epoch 11 | Batch 140/737 | Loss: 0.8986 | CTC: 1.0527 | CE: 0.5390 | Time: 10.47s\n",
      "Epoch 11 | Batch 150/737 | Loss: 0.9479 | CTC: 1.1233 | CE: 0.5385 | Time: 10.44s\n",
      "Epoch 11 | Batch 160/737 | Loss: 0.8923 | CTC: 1.0716 | CE: 0.4738 | Time: 10.36s\n",
      "Epoch 11 | Batch 170/737 | Loss: 0.8839 | CTC: 1.0012 | CE: 0.6101 | Time: 10.19s\n",
      "Epoch 11 | Batch 180/737 | Loss: 0.9088 | CTC: 1.0696 | CE: 0.5335 | Time: 10.07s\n",
      "Epoch 11 | Batch 190/737 | Loss: 0.9027 | CTC: 1.0520 | CE: 0.5543 | Time: 10.10s\n",
      "Epoch 11 | Batch 200/737 | Loss: 0.8404 | CTC: 0.9954 | CE: 0.4785 | Time: 10.16s\n",
      "Epoch 11 | Batch 210/737 | Loss: 0.9168 | CTC: 1.0692 | CE: 0.5610 | Time: 10.28s\n",
      "Epoch 11 | Batch 220/737 | Loss: 0.8891 | CTC: 1.0548 | CE: 0.5024 | Time: 9.89s\n",
      "Epoch 11 | Batch 230/737 | Loss: 0.8588 | CTC: 1.0264 | CE: 0.4679 | Time: 10.17s\n",
      "Epoch 11 | Batch 240/737 | Loss: 0.8495 | CTC: 0.9958 | CE: 0.5082 | Time: 10.42s\n",
      "Epoch 11 | Batch 250/737 | Loss: 0.8130 | CTC: 0.9670 | CE: 0.4538 | Time: 9.96s\n",
      "Epoch 11 | Batch 260/737 | Loss: 0.8488 | CTC: 1.0062 | CE: 0.4816 | Time: 9.92s\n",
      "Epoch 11 | Batch 270/737 | Loss: 0.9385 | CTC: 1.0866 | CE: 0.5928 | Time: 10.18s\n",
      "Epoch 11 | Batch 280/737 | Loss: 0.8729 | CTC: 1.0315 | CE: 0.5027 | Time: 10.30s\n",
      "Epoch 11 | Batch 290/737 | Loss: 0.9469 | CTC: 1.1180 | CE: 0.5478 | Time: 10.25s\n",
      "Epoch 11 | Batch 300/737 | Loss: 0.8326 | CTC: 0.9732 | CE: 0.5044 | Time: 9.97s\n",
      "Epoch 11 | Batch 310/737 | Loss: 0.8459 | CTC: 0.9979 | CE: 0.4913 | Time: 10.15s\n",
      "Epoch 11 | Batch 320/737 | Loss: 0.8949 | CTC: 1.0541 | CE: 0.5235 | Time: 9.93s\n",
      "Epoch 11 | Batch 330/737 | Loss: 0.9307 | CTC: 1.0724 | CE: 0.6001 | Time: 10.22s\n",
      "Epoch 11 | Batch 340/737 | Loss: 14.2300 | CTC: 20.0947 | CE: 0.5458 | Time: 10.15s\n",
      "Epoch 11 | Batch 350/737 | Loss: 0.8934 | CTC: 1.0559 | CE: 0.5142 | Time: 10.19s\n",
      "Epoch 11 | Batch 360/737 | Loss: 0.9283 | CTC: 1.0999 | CE: 0.5279 | Time: 10.07s\n",
      "Epoch 11 | Batch 370/737 | Loss: 0.8866 | CTC: 1.0249 | CE: 0.5641 | Time: 10.45s\n",
      "Epoch 11 | Batch 380/737 | Loss: 0.8795 | CTC: 1.0468 | CE: 0.4893 | Time: 10.22s\n",
      "Epoch 11 | Batch 390/737 | Loss: 0.8724 | CTC: 1.0386 | CE: 0.4844 | Time: 10.39s\n",
      "Epoch 11 | Batch 400/737 | Loss: 0.9642 | CTC: 1.1277 | CE: 0.5827 | Time: 10.29s\n",
      "Epoch 11 | Batch 410/737 | Loss: 0.8905 | CTC: 0.9895 | CE: 0.6596 | Time: 10.21s\n",
      "Epoch 11 | Batch 420/737 | Loss: 0.8677 | CTC: 1.0142 | CE: 0.5258 | Time: 9.97s\n",
      "Epoch 11 | Batch 430/737 | Loss: 0.8724 | CTC: 1.0289 | CE: 0.5070 | Time: 10.37s\n",
      "Epoch 11 | Batch 440/737 | Loss: 0.8497 | CTC: 1.0055 | CE: 0.4861 | Time: 10.44s\n",
      "Epoch 11 | Batch 450/737 | Loss: 0.8626 | CTC: 1.0073 | CE: 0.5250 | Time: 10.28s\n",
      "Epoch 11 | Batch 460/737 | Loss: 1.0090 | CTC: 1.1590 | CE: 0.6590 | Time: 10.43s\n",
      "Epoch 11 | Batch 470/737 | Loss: 0.9174 | CTC: 1.0877 | CE: 0.5200 | Time: 10.18s\n",
      "Epoch 11 | Batch 480/737 | Loss: 0.8511 | CTC: 1.0101 | CE: 0.4801 | Time: 10.33s\n",
      "Epoch 11 | Batch 490/737 | Loss: 0.8283 | CTC: 0.9818 | CE: 0.4703 | Time: 10.23s\n",
      "Epoch 11 | Batch 500/737 | Loss: 0.8642 | CTC: 1.0119 | CE: 0.5197 | Time: 10.04s\n",
      "Epoch 11 | Batch 510/737 | Loss: 0.8572 | CTC: 1.0224 | CE: 0.4717 | Time: 9.99s\n",
      "Epoch 11 | Batch 520/737 | Loss: 0.8903 | CTC: 1.0339 | CE: 0.5552 | Time: 10.39s\n",
      "Epoch 11 | Batch 530/737 | Loss: 0.8998 | CTC: 1.0533 | CE: 0.5417 | Time: 10.26s\n",
      "Epoch 11 | Batch 540/737 | Loss: 0.8813 | CTC: 1.0108 | CE: 0.5792 | Time: 10.26s\n",
      "Epoch 11 | Batch 550/737 | Loss: 0.8582 | CTC: 1.0297 | CE: 0.4580 | Time: 9.84s\n",
      "Epoch 11 | Batch 560/737 | Loss: 0.8151 | CTC: 0.9371 | CE: 0.5304 | Time: 10.44s\n",
      "Epoch 11 | Batch 570/737 | Loss: 0.7917 | CTC: 0.9385 | CE: 0.4493 | Time: 10.08s\n",
      "Epoch 11 | Batch 580/737 | Loss: 0.8232 | CTC: 0.9904 | CE: 0.4331 | Time: 10.24s\n",
      "Epoch 11 | Batch 590/737 | Loss: 0.9217 | CTC: 1.0611 | CE: 0.5964 | Time: 10.28s\n",
      "Epoch 11 | Batch 600/737 | Loss: 0.7912 | CTC: 0.9424 | CE: 0.4384 | Time: 10.20s\n",
      "Epoch 11 | Batch 610/737 | Loss: 0.8183 | CTC: 0.9769 | CE: 0.4482 | Time: 10.35s\n",
      "Epoch 11 | Batch 620/737 | Loss: 0.8752 | CTC: 1.0209 | CE: 0.5351 | Time: 10.24s\n",
      "Epoch 11 | Batch 630/737 | Loss: 0.8307 | CTC: 1.0174 | CE: 0.3950 | Time: 10.21s\n",
      "Epoch 11 | Batch 640/737 | Loss: 0.8982 | CTC: 1.0690 | CE: 0.4996 | Time: 10.11s\n",
      "Epoch 11 | Batch 650/737 | Loss: 0.8723 | CTC: 1.0412 | CE: 0.4781 | Time: 10.03s\n",
      "Epoch 11 | Batch 660/737 | Loss: 0.8694 | CTC: 0.9725 | CE: 0.6290 | Time: 10.19s\n",
      "Epoch 11 | Batch 670/737 | Loss: 0.8955 | CTC: 1.0700 | CE: 0.4885 | Time: 10.17s\n",
      "Epoch 11 | Batch 680/737 | Loss: 0.8772 | CTC: 1.0456 | CE: 0.4844 | Time: 9.99s\n",
      "Epoch 11 | Batch 690/737 | Loss: 0.9088 | CTC: 1.0675 | CE: 0.5386 | Time: 10.30s\n",
      "Epoch 11 | Batch 700/737 | Loss: 0.8296 | CTC: 0.9958 | CE: 0.4418 | Time: 10.35s\n",
      "Epoch 11 | Batch 710/737 | Loss: 0.9585 | CTC: 1.1047 | CE: 0.6173 | Time: 10.34s\n",
      "Epoch 11 | Batch 720/737 | Loss: 0.8267 | CTC: 0.9653 | CE: 0.5034 | Time: 10.47s\n",
      "Epoch 11 | Batch 730/737 | Loss: 0.8517 | CTC: 0.9843 | CE: 0.5425 | Time: 10.16s\n",
      "Train Loss: 1.1564 | CTC: 1.4253 | CE: 0.5288\n",
      "Val Loss: 0.7716 | CTC: 0.9275 | CE: 0.4079\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prntinin the ltsencs withp wich wratpresnt conrnd diffors frommstionotfrom altarnncpraftrrprisentd in theexibition\n",
      "\n",
      "Epoch 12/25\n",
      "Epoch 12 | Batch 0/737 | Loss: 0.7985 | CTC: 0.9691 | CE: 0.4002 | Time: 0.95s\n",
      "Epoch 12 | Batch 10/737 | Loss: 0.8549 | CTC: 1.0194 | CE: 0.4711 | Time: 10.30s\n",
      "Epoch 12 | Batch 20/737 | Loss: 0.7983 | CTC: 0.9398 | CE: 0.4680 | Time: 10.21s\n",
      "Epoch 12 | Batch 30/737 | Loss: 0.8897 | CTC: 1.0241 | CE: 0.5759 | Time: 10.33s\n",
      "Epoch 12 | Batch 40/737 | Loss: 0.8430 | CTC: 0.9971 | CE: 0.4835 | Time: 10.21s\n",
      "Epoch 12 | Batch 50/737 | Loss: 0.8277 | CTC: 0.9872 | CE: 0.4555 | Time: 9.97s\n",
      "Epoch 12 | Batch 60/737 | Loss: 0.8176 | CTC: 0.9889 | CE: 0.4179 | Time: 10.19s\n",
      "Epoch 12 | Batch 70/737 | Loss: 0.8278 | CTC: 0.9826 | CE: 0.4666 | Time: 10.08s\n",
      "Epoch 12 | Batch 80/737 | Loss: 0.8506 | CTC: 0.9958 | CE: 0.5116 | Time: 10.01s\n",
      "Epoch 12 | Batch 90/737 | Loss: 0.8656 | CTC: 0.9949 | CE: 0.5640 | Time: 10.13s\n",
      "Epoch 12 | Batch 100/737 | Loss: 0.8838 | CTC: 1.0527 | CE: 0.4895 | Time: 9.98s\n",
      "Epoch 12 | Batch 110/737 | Loss: 0.8473 | CTC: 1.0075 | CE: 0.4735 | Time: 10.08s\n",
      "Epoch 12 | Batch 120/737 | Loss: 0.8665 | CTC: 1.0391 | CE: 0.4637 | Time: 10.23s\n",
      "Epoch 12 | Batch 130/737 | Loss: 0.8408 | CTC: 0.9777 | CE: 0.5213 | Time: 10.00s\n",
      "Epoch 12 | Batch 140/737 | Loss: 0.7971 | CTC: 0.9605 | CE: 0.4158 | Time: 10.36s\n",
      "Epoch 12 | Batch 150/737 | Loss: 0.8356 | CTC: 0.9869 | CE: 0.4826 | Time: 10.31s\n",
      "Epoch 12 | Batch 160/737 | Loss: 0.8309 | CTC: 1.0017 | CE: 0.4326 | Time: 10.18s\n",
      "Epoch 12 | Batch 170/737 | Loss: 0.8431 | CTC: 0.9718 | CE: 0.5430 | Time: 10.19s\n",
      "Epoch 12 | Batch 180/737 | Loss: 0.8457 | CTC: 0.9906 | CE: 0.5078 | Time: 10.33s\n",
      "Epoch 12 | Batch 190/737 | Loss: 0.8253 | CTC: 0.9882 | CE: 0.4452 | Time: 9.84s\n",
      "Epoch 12 | Batch 200/737 | Loss: 0.8371 | CTC: 0.9934 | CE: 0.4725 | Time: 10.12s\n",
      "Epoch 12 | Batch 210/737 | Loss: 0.8354 | CTC: 1.0067 | CE: 0.4356 | Time: 10.25s\n",
      "Epoch 12 | Batch 220/737 | Loss: 0.8660 | CTC: 1.0210 | CE: 0.5043 | Time: 10.30s\n",
      "Epoch 12 | Batch 230/737 | Loss: 0.8029 | CTC: 0.9673 | CE: 0.4192 | Time: 10.12s\n",
      "Epoch 12 | Batch 240/737 | Loss: 0.8497 | CTC: 0.9721 | CE: 0.5641 | Time: 10.33s\n",
      "Epoch 12 | Batch 250/737 | Loss: 0.8440 | CTC: 1.0065 | CE: 0.4649 | Time: 10.16s\n",
      "Epoch 12 | Batch 260/737 | Loss: 0.8388 | CTC: 1.0001 | CE: 0.4623 | Time: 9.98s\n",
      "Epoch 12 | Batch 270/737 | Loss: 0.8417 | CTC: 0.9968 | CE: 0.4799 | Time: 10.02s\n",
      "Epoch 12 | Batch 280/737 | Loss: 0.8190 | CTC: 0.9853 | CE: 0.4308 | Time: 9.97s\n",
      "Epoch 12 | Batch 290/737 | Loss: 0.7804 | CTC: 0.9550 | CE: 0.3730 | Time: 10.02s\n",
      "Epoch 12 | Batch 300/737 | Loss: 0.8303 | CTC: 0.9739 | CE: 0.4951 | Time: 9.93s\n",
      "Epoch 12 | Batch 310/737 | Loss: 0.8746 | CTC: 1.0397 | CE: 0.4894 | Time: 10.47s\n",
      "Epoch 12 | Batch 320/737 | Loss: 0.7657 | CTC: 0.9265 | CE: 0.3905 | Time: 10.12s\n",
      "Epoch 12 | Batch 330/737 | Loss: 0.8090 | CTC: 0.9497 | CE: 0.4806 | Time: 10.26s\n",
      "Epoch 12 | Batch 340/737 | Loss: 0.8564 | CTC: 1.0144 | CE: 0.4877 | Time: 10.37s\n",
      "Epoch 12 | Batch 350/737 | Loss: 0.8851 | CTC: 1.0664 | CE: 0.4620 | Time: 10.27s\n",
      "Epoch 12 | Batch 360/737 | Loss: 0.8960 | CTC: 1.0578 | CE: 0.5183 | Time: 9.95s\n",
      "Epoch 12 | Batch 370/737 | Loss: 0.7877 | CTC: 0.9543 | CE: 0.3989 | Time: 10.38s\n",
      "Epoch 12 | Batch 380/737 | Loss: 0.8469 | CTC: 1.0099 | CE: 0.4666 | Time: 10.01s\n",
      "Epoch 12 | Batch 390/737 | Loss: 0.8200 | CTC: 0.9902 | CE: 0.4229 | Time: 10.27s\n",
      "Epoch 12 | Batch 400/737 | Loss: 0.8253 | CTC: 0.9911 | CE: 0.4385 | Time: 10.23s\n",
      "Epoch 12 | Batch 410/737 | Loss: 0.8720 | CTC: 1.0168 | CE: 0.5341 | Time: 10.35s\n",
      "Epoch 12 | Batch 420/737 | Loss: 0.8160 | CTC: 0.9650 | CE: 0.4682 | Time: 10.18s\n",
      "Epoch 12 | Batch 430/737 | Loss: 0.8197 | CTC: 0.9788 | CE: 0.4484 | Time: 10.36s\n",
      "Epoch 12 | Batch 440/737 | Loss: 0.9038 | CTC: 1.0343 | CE: 0.5992 | Time: 10.24s\n",
      "Epoch 12 | Batch 450/737 | Loss: 0.7530 | CTC: 0.9163 | CE: 0.3718 | Time: 10.46s\n",
      "Epoch 12 | Batch 460/737 | Loss: 0.8822 | CTC: 1.0620 | CE: 0.4629 | Time: 10.53s\n",
      "Epoch 12 | Batch 470/737 | Loss: 0.7725 | CTC: 0.9292 | CE: 0.4070 | Time: 10.11s\n",
      "Epoch 12 | Batch 480/737 | Loss: 0.7825 | CTC: 0.9558 | CE: 0.3782 | Time: 10.11s\n",
      "Epoch 12 | Batch 490/737 | Loss: 0.8033 | CTC: 0.9362 | CE: 0.4932 | Time: 10.22s\n",
      "Epoch 12 | Batch 500/737 | Loss: 0.9219 | CTC: 1.0934 | CE: 0.5219 | Time: 10.06s\n",
      "Epoch 12 | Batch 510/737 | Loss: 0.8246 | CTC: 0.9927 | CE: 0.4326 | Time: 10.29s\n",
      "Epoch 12 | Batch 520/737 | Loss: 0.8157 | CTC: 0.9895 | CE: 0.4102 | Time: 10.32s\n",
      "Epoch 12 | Batch 530/737 | Loss: 0.8326 | CTC: 0.9822 | CE: 0.4834 | Time: 10.02s\n",
      "Epoch 12 | Batch 540/737 | Loss: 0.8372 | CTC: 1.0085 | CE: 0.4376 | Time: 10.34s\n",
      "Epoch 12 | Batch 550/737 | Loss: 0.8202 | CTC: 0.9796 | CE: 0.4485 | Time: 10.40s\n",
      "Epoch 12 | Batch 560/737 | Loss: 0.7419 | CTC: 0.8927 | CE: 0.3900 | Time: 9.89s\n",
      "Epoch 12 | Batch 570/737 | Loss: 0.8769 | CTC: 1.0306 | CE: 0.5183 | Time: 10.16s\n",
      "Epoch 12 | Batch 580/737 | Loss: 0.8817 | CTC: 1.0436 | CE: 0.5039 | Time: 9.88s\n",
      "Epoch 12 | Batch 590/737 | Loss: 0.8690 | CTC: 1.0035 | CE: 0.5550 | Time: 10.08s\n",
      "Epoch 12 | Batch 600/737 | Loss: 0.7913 | CTC: 0.9470 | CE: 0.4282 | Time: 10.34s\n",
      "Epoch 12 | Batch 610/737 | Loss: 0.8752 | CTC: 1.0192 | CE: 0.5391 | Time: 10.13s\n",
      "Epoch 12 | Batch 620/737 | Loss: 0.6947 | CTC: 0.8232 | CE: 0.3950 | Time: 10.31s\n",
      "Epoch 12 | Batch 630/737 | Loss: 0.8240 | CTC: 0.9812 | CE: 0.4573 | Time: 10.31s\n",
      "Epoch 12 | Batch 640/737 | Loss: 0.8909 | CTC: 1.0458 | CE: 0.5294 | Time: 10.21s\n",
      "Epoch 12 | Batch 650/737 | Loss: 0.8249 | CTC: 0.9624 | CE: 0.5039 | Time: 9.82s\n",
      "Epoch 12 | Batch 660/737 | Loss: 0.8217 | CTC: 0.9764 | CE: 0.4606 | Time: 10.27s\n",
      "Epoch 12 | Batch 670/737 | Loss: 0.8109 | CTC: 0.9856 | CE: 0.4031 | Time: 10.18s\n",
      "Epoch 12 | Batch 680/737 | Loss: 0.7878 | CTC: 0.9471 | CE: 0.4163 | Time: 10.16s\n",
      "Epoch 12 | Batch 690/737 | Loss: 0.8019 | CTC: 0.9475 | CE: 0.4623 | Time: 10.39s\n",
      "Epoch 12 | Batch 700/737 | Loss: 0.8201 | CTC: 0.9842 | CE: 0.4371 | Time: 9.99s\n",
      "Epoch 12 | Batch 710/737 | Loss: 0.7910 | CTC: 0.9530 | CE: 0.4129 | Time: 9.99s\n",
      "Epoch 12 | Batch 720/737 | Loss: 0.8571 | CTC: 1.0118 | CE: 0.4959 | Time: 10.18s\n",
      "Epoch 12 | Batch 730/737 | Loss: 0.7847 | CTC: 0.9444 | CE: 0.4121 | Time: 10.38s\n",
      "Train Loss: 1.0836 | CTC: 1.3507 | CE: 0.4605\n",
      "Val Loss: 0.7220 | CTC: 0.8751 | CE: 0.3649\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prntingin the lsencwitp wich aretpresnt conerndt diiffirs frommstifnotfrom alth arttncraftrrprsent in the exibition\n",
      "\n",
      "Epoch 13/25\n",
      "Epoch 13 | Batch 0/737 | Loss: 0.7724 | CTC: 0.9177 | CE: 0.4333 | Time: 1.03s\n",
      "Epoch 13 | Batch 10/737 | Loss: 0.7734 | CTC: 0.9261 | CE: 0.4170 | Time: 10.42s\n",
      "Epoch 13 | Batch 20/737 | Loss: 0.6685 | CTC: 0.8110 | CE: 0.3359 | Time: 9.81s\n",
      "Epoch 13 | Batch 30/737 | Loss: 0.7567 | CTC: 0.8999 | CE: 0.4227 | Time: 10.03s\n",
      "Epoch 13 | Batch 40/737 | Loss: 0.7702 | CTC: 0.9175 | CE: 0.4266 | Time: 10.21s\n",
      "Epoch 13 | Batch 50/737 | Loss: 0.7336 | CTC: 0.8687 | CE: 0.4185 | Time: 10.12s\n",
      "Epoch 13 | Batch 60/737 | Loss: 0.7786 | CTC: 0.9348 | CE: 0.4142 | Time: 10.20s\n",
      "Epoch 13 | Batch 70/737 | Loss: 0.8335 | CTC: 0.9856 | CE: 0.4788 | Time: 10.05s\n",
      "Epoch 13 | Batch 80/737 | Loss: 0.7730 | CTC: 0.9345 | CE: 0.3963 | Time: 10.38s\n",
      "Epoch 13 | Batch 90/737 | Loss: 0.8018 | CTC: 0.9047 | CE: 0.5618 | Time: 10.30s\n",
      "Epoch 13 | Batch 100/737 | Loss: 0.7550 | CTC: 0.9021 | CE: 0.4117 | Time: 10.37s\n",
      "Epoch 13 | Batch 110/737 | Loss: 0.7876 | CTC: 0.9462 | CE: 0.4175 | Time: 10.09s\n",
      "Epoch 13 | Batch 120/737 | Loss: 0.7959 | CTC: 0.9480 | CE: 0.4408 | Time: 10.25s\n",
      "Epoch 13 | Batch 130/737 | Loss: 0.7476 | CTC: 0.8862 | CE: 0.4241 | Time: 10.21s\n",
      "Epoch 13 | Batch 140/737 | Loss: 0.7326 | CTC: 0.8730 | CE: 0.4051 | Time: 10.01s\n",
      "Epoch 13 | Batch 150/737 | Loss: 0.7891 | CTC: 0.9539 | CE: 0.4045 | Time: 10.24s\n",
      "Epoch 13 | Batch 160/737 | Loss: 0.8037 | CTC: 0.9752 | CE: 0.4037 | Time: 10.10s\n",
      "Epoch 13 | Batch 170/737 | Loss: 13.0540 | CTC: 18.4769 | CE: 0.4005 | Time: 10.10s\n",
      "Epoch 13 | Batch 180/737 | Loss: 0.7890 | CTC: 0.9380 | CE: 0.4416 | Time: 10.32s\n",
      "Epoch 13 | Batch 190/737 | Loss: 0.7231 | CTC: 0.8750 | CE: 0.3687 | Time: 9.78s\n",
      "Epoch 13 | Batch 200/737 | Loss: 0.8259 | CTC: 0.9760 | CE: 0.4756 | Time: 10.12s\n",
      "Epoch 13 | Batch 210/737 | Loss: 0.7255 | CTC: 0.8785 | CE: 0.3685 | Time: 10.06s\n",
      "Epoch 13 | Batch 220/737 | Loss: 0.7704 | CTC: 0.9335 | CE: 0.3897 | Time: 10.24s\n",
      "Epoch 13 | Batch 230/737 | Loss: 0.7521 | CTC: 0.8935 | CE: 0.4222 | Time: 9.99s\n",
      "Epoch 13 | Batch 240/737 | Loss: 0.7473 | CTC: 0.9127 | CE: 0.3615 | Time: 10.40s\n",
      "Epoch 13 | Batch 250/737 | Loss: 0.7746 | CTC: 0.9224 | CE: 0.4296 | Time: 10.08s\n",
      "Epoch 13 | Batch 260/737 | Loss: 0.8108 | CTC: 0.9600 | CE: 0.4624 | Time: 10.45s\n",
      "Epoch 13 | Batch 270/737 | Loss: 0.7213 | CTC: 0.8521 | CE: 0.4161 | Time: 10.01s\n",
      "Epoch 13 | Batch 280/737 | Loss: 21.8503 | CTC: 31.0125 | CE: 0.4719 | Time: 10.48s\n",
      "Epoch 13 | Batch 290/737 | Loss: 0.7615 | CTC: 0.9122 | CE: 0.4099 | Time: 10.12s\n",
      "Epoch 13 | Batch 300/737 | Loss: 0.7026 | CTC: 0.8465 | CE: 0.3666 | Time: 10.21s\n",
      "Epoch 13 | Batch 310/737 | Loss: 13.2012 | CTC: 18.6175 | CE: 0.5632 | Time: 10.40s\n",
      "Epoch 13 | Batch 320/737 | Loss: 0.6905 | CTC: 0.8382 | CE: 0.3460 | Time: 10.37s\n",
      "Epoch 13 | Batch 330/737 | Loss: 0.6993 | CTC: 0.8398 | CE: 0.3715 | Time: 10.16s\n",
      "Epoch 13 | Batch 340/737 | Loss: 0.7541 | CTC: 0.9187 | CE: 0.3700 | Time: 10.16s\n",
      "Epoch 13 | Batch 350/737 | Loss: 0.7764 | CTC: 0.9536 | CE: 0.3630 | Time: 9.88s\n",
      "Epoch 13 | Batch 360/737 | Loss: 0.7685 | CTC: 0.9073 | CE: 0.4445 | Time: 10.22s\n",
      "Epoch 13 | Batch 370/737 | Loss: 0.7241 | CTC: 0.8819 | CE: 0.3560 | Time: 10.19s\n",
      "Epoch 13 | Batch 380/737 | Loss: 0.6542 | CTC: 0.7867 | CE: 0.3451 | Time: 10.02s\n",
      "Epoch 13 | Batch 390/737 | Loss: 0.7246 | CTC: 0.8722 | CE: 0.3802 | Time: 9.90s\n",
      "Epoch 13 | Batch 400/737 | Loss: 0.7402 | CTC: 0.8912 | CE: 0.3877 | Time: 10.16s\n",
      "Epoch 13 | Batch 410/737 | Loss: 0.7689 | CTC: 0.9249 | CE: 0.4049 | Time: 10.26s\n",
      "Epoch 13 | Batch 420/737 | Loss: 0.7321 | CTC: 0.8916 | CE: 0.3600 | Time: 10.15s\n",
      "Epoch 13 | Batch 430/737 | Loss: 0.7396 | CTC: 0.8779 | CE: 0.4167 | Time: 10.25s\n",
      "Epoch 13 | Batch 440/737 | Loss: 0.7728 | CTC: 0.9296 | CE: 0.4070 | Time: 10.38s\n",
      "Epoch 13 | Batch 450/737 | Loss: 0.7657 | CTC: 0.9165 | CE: 0.4139 | Time: 10.31s\n",
      "Epoch 13 | Batch 460/737 | Loss: 0.8281 | CTC: 0.9822 | CE: 0.4688 | Time: 10.51s\n",
      "Epoch 13 | Batch 470/737 | Loss: 0.7940 | CTC: 0.9505 | CE: 0.4287 | Time: 10.20s\n",
      "Epoch 13 | Batch 480/737 | Loss: 0.6598 | CTC: 0.7835 | CE: 0.3710 | Time: 9.72s\n",
      "Epoch 13 | Batch 490/737 | Loss: 0.7664 | CTC: 0.9077 | CE: 0.4368 | Time: 10.15s\n",
      "Epoch 13 | Batch 500/737 | Loss: 0.8383 | CTC: 1.0104 | CE: 0.4367 | Time: 10.43s\n",
      "Epoch 13 | Batch 510/737 | Loss: 0.7575 | CTC: 0.9161 | CE: 0.3876 | Time: 10.06s\n",
      "Epoch 13 | Batch 520/737 | Loss: 0.7752 | CTC: 0.9199 | CE: 0.4375 | Time: 10.18s\n",
      "Epoch 13 | Batch 530/737 | Loss: 0.8171 | CTC: 0.9821 | CE: 0.4321 | Time: 10.18s\n",
      "Epoch 13 | Batch 540/737 | Loss: 0.7398 | CTC: 0.9042 | CE: 0.3563 | Time: 10.39s\n",
      "Epoch 13 | Batch 550/737 | Loss: 0.7852 | CTC: 0.9551 | CE: 0.3887 | Time: 9.82s\n",
      "Epoch 13 | Batch 560/737 | Loss: 0.7432 | CTC: 0.8919 | CE: 0.3961 | Time: 10.26s\n",
      "Epoch 13 | Batch 570/737 | Loss: 0.8194 | CTC: 0.9831 | CE: 0.4376 | Time: 10.39s\n",
      "Epoch 13 | Batch 580/737 | Loss: 0.7501 | CTC: 0.9112 | CE: 0.3743 | Time: 10.39s\n",
      "Epoch 13 | Batch 590/737 | Loss: 0.7264 | CTC: 0.8835 | CE: 0.3598 | Time: 10.42s\n",
      "Epoch 13 | Batch 600/737 | Loss: 0.7608 | CTC: 0.9133 | CE: 0.4051 | Time: 10.23s\n",
      "Epoch 13 | Batch 610/737 | Loss: 0.7159 | CTC: 0.8479 | CE: 0.4077 | Time: 9.88s\n",
      "Epoch 13 | Batch 620/737 | Loss: 0.7531 | CTC: 0.9328 | CE: 0.3336 | Time: 10.28s\n",
      "Epoch 13 | Batch 630/737 | Loss: 0.7924 | CTC: 0.9647 | CE: 0.3903 | Time: 10.49s\n",
      "Epoch 13 | Batch 640/737 | Loss: 0.7396 | CTC: 0.8975 | CE: 0.3709 | Time: 10.26s\n",
      "Epoch 13 | Batch 650/737 | Loss: 0.7631 | CTC: 0.9179 | CE: 0.4020 | Time: 10.20s\n",
      "Epoch 13 | Batch 660/737 | Loss: 0.7039 | CTC: 0.8621 | CE: 0.3350 | Time: 10.22s\n",
      "Epoch 13 | Batch 670/737 | Loss: 0.8086 | CTC: 0.9783 | CE: 0.4125 | Time: 10.31s\n",
      "Epoch 13 | Batch 680/737 | Loss: 0.8076 | CTC: 0.9589 | CE: 0.4545 | Time: 10.12s\n",
      "Epoch 13 | Batch 690/737 | Loss: 0.7097 | CTC: 0.8607 | CE: 0.3574 | Time: 10.12s\n",
      "Epoch 13 | Batch 700/737 | Loss: 0.7941 | CTC: 0.9477 | CE: 0.4357 | Time: 10.34s\n",
      "Epoch 13 | Batch 710/737 | Loss: 0.7838 | CTC: 0.9397 | CE: 0.4200 | Time: 10.15s\n",
      "Epoch 13 | Batch 720/737 | Loss: 0.7248 | CTC: 0.8645 | CE: 0.3988 | Time: 10.00s\n",
      "Epoch 13 | Batch 730/737 | Loss: 0.8225 | CTC: 0.9750 | CE: 0.4667 | Time: 10.35s\n",
      "Train Loss: 1.0307 | CTC: 1.2993 | CE: 0.4038\n",
      "Val Loss: 0.6765 | CTC: 0.8257 | CE: 0.3282\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnnting  in the olsens withp wich waratpresnt conernd diffirs frrmmstinotfrom alt artsoncrafrrprisented in the exibitien\n",
      "\n",
      "Epoch 14/25\n",
      "Epoch 14 | Batch 0/737 | Loss: 0.6858 | CTC: 0.8312 | CE: 0.3464 | Time: 1.03s\n",
      "Epoch 14 | Batch 10/737 | Loss: 0.6726 | CTC: 0.8183 | CE: 0.3325 | Time: 10.34s\n",
      "Epoch 14 | Batch 20/737 | Loss: 0.7009 | CTC: 0.8462 | CE: 0.3618 | Time: 10.49s\n",
      "Epoch 14 | Batch 30/737 | Loss: 0.6834 | CTC: 0.8367 | CE: 0.3255 | Time: 10.13s\n",
      "Epoch 14 | Batch 40/737 | Loss: 0.7519 | CTC: 0.9295 | CE: 0.3376 | Time: 10.12s\n",
      "Epoch 14 | Batch 50/737 | Loss: 0.6717 | CTC: 0.8113 | CE: 0.3459 | Time: 10.48s\n",
      "Epoch 14 | Batch 60/737 | Loss: 0.7143 | CTC: 0.8713 | CE: 0.3480 | Time: 10.27s\n",
      "Epoch 14 | Batch 70/737 | Loss: 0.6798 | CTC: 0.8159 | CE: 0.3621 | Time: 10.19s\n",
      "Epoch 14 | Batch 80/737 | Loss: 0.6165 | CTC: 0.7625 | CE: 0.2757 | Time: 10.07s\n",
      "Epoch 14 | Batch 90/737 | Loss: 0.6893 | CTC: 0.8444 | CE: 0.3273 | Time: 10.15s\n",
      "Epoch 14 | Batch 100/737 | Loss: 0.7521 | CTC: 0.9044 | CE: 0.3967 | Time: 10.37s\n",
      "Epoch 14 | Batch 110/737 | Loss: 0.6826 | CTC: 0.8595 | CE: 0.2699 | Time: 9.87s\n",
      "Epoch 14 | Batch 120/737 | Loss: 0.7001 | CTC: 0.8613 | CE: 0.3241 | Time: 10.21s\n",
      "Epoch 14 | Batch 130/737 | Loss: 0.7186 | CTC: 0.8500 | CE: 0.4119 | Time: 10.08s\n",
      "Epoch 14 | Batch 140/737 | Loss: 0.7489 | CTC: 0.9062 | CE: 0.3818 | Time: 10.15s\n",
      "Epoch 14 | Batch 150/737 | Loss: 0.6930 | CTC: 0.8479 | CE: 0.3317 | Time: 10.47s\n",
      "Epoch 14 | Batch 160/737 | Loss: 0.7625 | CTC: 0.9144 | CE: 0.4081 | Time: 10.30s\n",
      "Epoch 14 | Batch 170/737 | Loss: 0.7257 | CTC: 0.8733 | CE: 0.3815 | Time: 10.37s\n",
      "Epoch 14 | Batch 180/737 | Loss: 0.7359 | CTC: 0.8816 | CE: 0.3960 | Time: 10.37s\n",
      "Epoch 14 | Batch 190/737 | Loss: 0.6957 | CTC: 0.8462 | CE: 0.3444 | Time: 10.17s\n",
      "Epoch 14 | Batch 200/737 | Loss: 0.7179 | CTC: 0.8690 | CE: 0.3654 | Time: 9.91s\n",
      "Epoch 14 | Batch 210/737 | Loss: 0.7008 | CTC: 0.8526 | CE: 0.3467 | Time: 10.04s\n",
      "Epoch 14 | Batch 220/737 | Loss: 0.7639 | CTC: 0.9412 | CE: 0.3504 | Time: 10.39s\n",
      "Epoch 14 | Batch 230/737 | Loss: 0.6640 | CTC: 0.8249 | CE: 0.2886 | Time: 10.02s\n",
      "Epoch 14 | Batch 240/737 | Loss: 0.6966 | CTC: 0.8645 | CE: 0.3049 | Time: 9.98s\n",
      "Epoch 14 | Batch 250/737 | Loss: 0.7164 | CTC: 0.8838 | CE: 0.3259 | Time: 10.12s\n",
      "Epoch 14 | Batch 260/737 | Loss: 0.7165 | CTC: 0.8794 | CE: 0.3365 | Time: 10.11s\n",
      "Epoch 14 | Batch 270/737 | Loss: 0.6157 | CTC: 0.7476 | CE: 0.3081 | Time: 10.36s\n",
      "Epoch 14 | Batch 280/737 | Loss: 0.7967 | CTC: 0.9574 | CE: 0.4218 | Time: 10.30s\n",
      "Epoch 14 | Batch 290/737 | Loss: 0.7207 | CTC: 0.8881 | CE: 0.3301 | Time: 10.39s\n",
      "Epoch 14 | Batch 300/737 | Loss: 0.6267 | CTC: 0.7593 | CE: 0.3172 | Time: 10.30s\n",
      "Epoch 14 | Batch 310/737 | Loss: 0.7639 | CTC: 0.9015 | CE: 0.4430 | Time: 10.23s\n",
      "Epoch 14 | Batch 320/737 | Loss: 0.6843 | CTC: 0.8420 | CE: 0.3165 | Time: 9.98s\n",
      "Epoch 14 | Batch 330/737 | Loss: 0.7062 | CTC: 0.8484 | CE: 0.3744 | Time: 10.45s\n",
      "Epoch 14 | Batch 340/737 | Loss: 0.7201 | CTC: 0.8770 | CE: 0.3540 | Time: 10.01s\n",
      "Epoch 14 | Batch 350/737 | Loss: 0.7156 | CTC: 0.8713 | CE: 0.3525 | Time: 10.38s\n",
      "Epoch 14 | Batch 360/737 | Loss: 0.7051 | CTC: 0.8363 | CE: 0.3988 | Time: 10.01s\n",
      "Epoch 14 | Batch 370/737 | Loss: 0.7323 | CTC: 0.8954 | CE: 0.3520 | Time: 10.18s\n",
      "Epoch 14 | Batch 380/737 | Loss: 0.7178 | CTC: 0.8799 | CE: 0.3395 | Time: 10.07s\n",
      "Epoch 14 | Batch 390/737 | Loss: 0.6091 | CTC: 0.7385 | CE: 0.3073 | Time: 10.05s\n",
      "Epoch 14 | Batch 400/737 | Loss: 0.7810 | CTC: 0.9348 | CE: 0.4221 | Time: 9.97s\n",
      "Epoch 14 | Batch 410/737 | Loss: 0.7576 | CTC: 0.9062 | CE: 0.4110 | Time: 10.24s\n",
      "Epoch 14 | Batch 420/737 | Loss: 0.6858 | CTC: 0.8377 | CE: 0.3315 | Time: 10.19s\n",
      "Epoch 14 | Batch 430/737 | Loss: 0.6558 | CTC: 0.7993 | CE: 0.3209 | Time: 10.26s\n",
      "Epoch 14 | Batch 440/737 | Loss: 0.6218 | CTC: 0.7522 | CE: 0.3174 | Time: 10.20s\n",
      "Epoch 14 | Batch 450/737 | Loss: 0.6928 | CTC: 0.8609 | CE: 0.3004 | Time: 10.30s\n",
      "Epoch 14 | Batch 460/737 | Loss: 0.7219 | CTC: 0.8818 | CE: 0.3490 | Time: 10.27s\n",
      "Epoch 14 | Batch 470/737 | Loss: 0.7152 | CTC: 0.8834 | CE: 0.3228 | Time: 10.48s\n",
      "Epoch 14 | Batch 480/737 | Loss: 0.7496 | CTC: 0.9103 | CE: 0.3746 | Time: 10.42s\n",
      "Epoch 14 | Batch 490/737 | Loss: 0.8026 | CTC: 0.9894 | CE: 0.3667 | Time: 9.99s\n",
      "Epoch 14 | Batch 500/737 | Loss: 0.6913 | CTC: 0.8486 | CE: 0.3243 | Time: 10.07s\n",
      "Epoch 14 | Batch 510/737 | Loss: 0.7429 | CTC: 0.9041 | CE: 0.3668 | Time: 10.16s\n",
      "Epoch 14 | Batch 520/737 | Loss: 0.7000 | CTC: 0.8613 | CE: 0.3235 | Time: 10.14s\n",
      "Epoch 14 | Batch 530/737 | Loss: 0.6222 | CTC: 0.7533 | CE: 0.3162 | Time: 10.16s\n",
      "Epoch 14 | Batch 540/737 | Loss: 0.6717 | CTC: 0.8257 | CE: 0.3121 | Time: 9.90s\n",
      "Epoch 14 | Batch 550/737 | Loss: 0.7770 | CTC: 0.9390 | CE: 0.3989 | Time: 10.16s\n",
      "Epoch 14 | Batch 560/737 | Loss: 0.6931 | CTC: 0.8558 | CE: 0.3137 | Time: 10.51s\n",
      "Epoch 14 | Batch 570/737 | Loss: 0.7902 | CTC: 0.9478 | CE: 0.4223 | Time: 10.35s\n",
      "Epoch 14 | Batch 580/737 | Loss: 0.7591 | CTC: 0.9458 | CE: 0.3236 | Time: 10.08s\n",
      "Epoch 14 | Batch 590/737 | Loss: 0.7656 | CTC: 0.9162 | CE: 0.4144 | Time: 10.07s\n",
      "Epoch 14 | Batch 600/737 | Loss: 0.7463 | CTC: 0.9045 | CE: 0.3770 | Time: 10.02s\n",
      "Epoch 14 | Batch 610/737 | Loss: 0.6336 | CTC: 0.7834 | CE: 0.2839 | Time: 10.12s\n",
      "Epoch 14 | Batch 620/737 | Loss: 0.7746 | CTC: 0.9196 | CE: 0.4364 | Time: 10.30s\n",
      "Epoch 14 | Batch 630/737 | Loss: 0.6603 | CTC: 0.8003 | CE: 0.3334 | Time: 10.14s\n",
      "Epoch 14 | Batch 640/737 | Loss: 0.6400 | CTC: 0.7740 | CE: 0.3272 | Time: 10.26s\n",
      "Epoch 14 | Batch 650/737 | Loss: 0.7000 | CTC: 0.8686 | CE: 0.3065 | Time: 10.17s\n",
      "Epoch 14 | Batch 660/737 | Loss: 0.7206 | CTC: 0.9007 | CE: 0.3006 | Time: 9.87s\n",
      "Epoch 14 | Batch 670/737 | Loss: 0.7025 | CTC: 0.8470 | CE: 0.3654 | Time: 9.82s\n",
      "Epoch 14 | Batch 680/737 | Loss: 0.6523 | CTC: 0.7891 | CE: 0.3331 | Time: 10.06s\n",
      "Epoch 14 | Batch 690/737 | Loss: 0.7030 | CTC: 0.8696 | CE: 0.3142 | Time: 10.29s\n",
      "Epoch 14 | Batch 700/737 | Loss: 0.6685 | CTC: 0.8092 | CE: 0.3403 | Time: 10.37s\n",
      "Epoch 14 | Batch 710/737 | Loss: 0.7692 | CTC: 0.9042 | CE: 0.4545 | Time: 10.23s\n",
      "Epoch 14 | Batch 720/737 | Loss: 0.6259 | CTC: 0.7702 | CE: 0.2892 | Time: 10.28s\n",
      "Epoch 14 | Batch 730/737 | Loss: 0.6713 | CTC: 0.8182 | CE: 0.3284 | Time: 10.06s\n",
      "Train Loss: 0.9673 | CTC: 1.2322 | CE: 0.3492\n",
      "Val Loss: 0.6349 | CTC: 0.7787 | CE: 0.2993\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnting  in the onlysence withp wich w arat presind conrnd diffors frommosetifnotfrom alt artsoncraftrrprisenti in the exibition\n",
      "\n",
      "Epoch 15/25\n",
      "Epoch 15 | Batch 0/737 | Loss: 0.6706 | CTC: 0.8141 | CE: 0.3360 | Time: 1.03s\n",
      "Epoch 15 | Batch 10/737 | Loss: 0.6168 | CTC: 0.7345 | CE: 0.3422 | Time: 10.14s\n",
      "Epoch 15 | Batch 20/737 | Loss: 0.5977 | CTC: 0.7420 | CE: 0.2610 | Time: 10.20s\n",
      "Epoch 15 | Batch 30/737 | Loss: 0.6323 | CTC: 0.7739 | CE: 0.3017 | Time: 10.33s\n",
      "Epoch 15 | Batch 40/737 | Loss: 0.6312 | CTC: 0.7843 | CE: 0.2740 | Time: 10.18s\n",
      "Epoch 15 | Batch 50/737 | Loss: 0.5867 | CTC: 0.7338 | CE: 0.2435 | Time: 10.03s\n",
      "Epoch 15 | Batch 60/737 | Loss: 0.7093 | CTC: 0.8601 | CE: 0.3573 | Time: 10.43s\n",
      "Epoch 15 | Batch 70/737 | Loss: 0.6338 | CTC: 0.7870 | CE: 0.2762 | Time: 10.19s\n",
      "Epoch 15 | Batch 80/737 | Loss: 0.6573 | CTC: 0.8100 | CE: 0.3009 | Time: 10.28s\n",
      "Epoch 15 | Batch 90/737 | Loss: 0.6054 | CTC: 0.7431 | CE: 0.2838 | Time: 9.94s\n",
      "Epoch 15 | Batch 100/737 | Loss: 0.6813 | CTC: 0.8251 | CE: 0.3457 | Time: 9.89s\n",
      "Epoch 15 | Batch 110/737 | Loss: 0.6985 | CTC: 0.8417 | CE: 0.3641 | Time: 10.03s\n",
      "Epoch 15 | Batch 120/737 | Loss: 0.5741 | CTC: 0.7107 | CE: 0.2554 | Time: 10.18s\n",
      "Epoch 15 | Batch 130/737 | Loss: 0.6437 | CTC: 0.8043 | CE: 0.2691 | Time: 10.01s\n",
      "Epoch 15 | Batch 140/737 | Loss: 0.6241 | CTC: 0.7859 | CE: 0.2467 | Time: 10.31s\n",
      "Epoch 15 | Batch 150/737 | Loss: 0.5991 | CTC: 0.7321 | CE: 0.2889 | Time: 10.02s\n",
      "Epoch 15 | Batch 160/737 | Loss: 0.7315 | CTC: 0.8909 | CE: 0.3597 | Time: 10.32s\n",
      "Epoch 15 | Batch 170/737 | Loss: 0.6294 | CTC: 0.7759 | CE: 0.2878 | Time: 10.18s\n",
      "Epoch 15 | Batch 180/737 | Loss: 0.6846 | CTC: 0.8311 | CE: 0.3428 | Time: 10.46s\n",
      "Epoch 15 | Batch 190/737 | Loss: 0.6898 | CTC: 0.8452 | CE: 0.3274 | Time: 9.84s\n",
      "Epoch 15 | Batch 200/737 | Loss: 0.7181 | CTC: 0.8735 | CE: 0.3555 | Time: 10.22s\n",
      "Epoch 15 | Batch 210/737 | Loss: 0.6731 | CTC: 0.8238 | CE: 0.3215 | Time: 10.13s\n",
      "Epoch 15 | Batch 220/737 | Loss: 0.6282 | CTC: 0.7622 | CE: 0.3156 | Time: 10.37s\n",
      "Epoch 15 | Batch 230/737 | Loss: 0.7131 | CTC: 0.8783 | CE: 0.3276 | Time: 10.30s\n",
      "Epoch 15 | Batch 240/737 | Loss: 0.6562 | CTC: 0.8103 | CE: 0.2966 | Time: 10.43s\n",
      "Epoch 15 | Batch 250/737 | Loss: 0.6728 | CTC: 0.8427 | CE: 0.2766 | Time: 10.14s\n",
      "Epoch 15 | Batch 260/737 | Loss: 0.6828 | CTC: 0.8370 | CE: 0.3229 | Time: 10.26s\n",
      "Epoch 15 | Batch 270/737 | Loss: 0.5659 | CTC: 0.6834 | CE: 0.2916 | Time: 10.32s\n",
      "Epoch 15 | Batch 280/737 | Loss: 0.6725 | CTC: 0.8023 | CE: 0.3695 | Time: 10.25s\n",
      "Epoch 15 | Batch 290/737 | Loss: 0.7375 | CTC: 0.9122 | CE: 0.3300 | Time: 10.03s\n",
      "Epoch 15 | Batch 300/737 | Loss: 0.6600 | CTC: 0.8118 | CE: 0.3057 | Time: 10.26s\n",
      "Epoch 15 | Batch 310/737 | Loss: 0.6860 | CTC: 0.8306 | CE: 0.3485 | Time: 10.23s\n",
      "Epoch 15 | Batch 320/737 | Loss: 0.7180 | CTC: 0.8499 | CE: 0.4101 | Time: 10.22s\n",
      "Epoch 15 | Batch 330/737 | Loss: 0.6545 | CTC: 0.8037 | CE: 0.3064 | Time: 10.29s\n",
      "Epoch 15 | Batch 340/737 | Loss: 0.6763 | CTC: 0.8304 | CE: 0.3167 | Time: 10.25s\n",
      "Epoch 15 | Batch 350/737 | Loss: 0.6381 | CTC: 0.7910 | CE: 0.2814 | Time: 10.18s\n",
      "Epoch 15 | Batch 360/737 | Loss: 0.6615 | CTC: 0.8245 | CE: 0.2811 | Time: 10.05s\n",
      "Epoch 15 | Batch 370/737 | Loss: 0.6354 | CTC: 0.7694 | CE: 0.3227 | Time: 10.12s\n",
      "Epoch 15 | Batch 380/737 | Loss: 10.9991 | CTC: 15.5863 | CE: 0.2955 | Time: 10.03s\n",
      "Epoch 15 | Batch 390/737 | Loss: 0.6048 | CTC: 0.7443 | CE: 0.2793 | Time: 10.13s\n",
      "Epoch 15 | Batch 400/737 | Loss: 0.6169 | CTC: 0.7658 | CE: 0.2696 | Time: 10.44s\n",
      "Epoch 15 | Batch 410/737 | Loss: 0.6867 | CTC: 0.8250 | CE: 0.3638 | Time: 10.19s\n",
      "Epoch 15 | Batch 420/737 | Loss: 0.6214 | CTC: 0.7699 | CE: 0.2747 | Time: 10.23s\n",
      "Epoch 15 | Batch 430/737 | Loss: 0.6497 | CTC: 0.8109 | CE: 0.2738 | Time: 10.05s\n",
      "Epoch 15 | Batch 440/737 | Loss: 0.6214 | CTC: 0.7748 | CE: 0.2635 | Time: 10.21s\n",
      "Epoch 15 | Batch 450/737 | Loss: 0.7043 | CTC: 0.8668 | CE: 0.3253 | Time: 10.21s\n",
      "Epoch 15 | Batch 460/737 | Loss: 0.6997 | CTC: 0.8575 | CE: 0.3314 | Time: 10.45s\n",
      "Epoch 15 | Batch 470/737 | Loss: 0.7006 | CTC: 0.8510 | CE: 0.3496 | Time: 10.28s\n",
      "Epoch 15 | Batch 480/737 | Loss: 0.6988 | CTC: 0.8706 | CE: 0.2977 | Time: 10.31s\n",
      "Epoch 15 | Batch 490/737 | Loss: 0.6863 | CTC: 0.8442 | CE: 0.3179 | Time: 10.23s\n",
      "Epoch 15 | Batch 500/737 | Loss: 0.6413 | CTC: 0.7720 | CE: 0.3365 | Time: 10.14s\n",
      "Epoch 15 | Batch 510/737 | Loss: 0.6696 | CTC: 0.8233 | CE: 0.3110 | Time: 10.18s\n",
      "Epoch 15 | Batch 520/737 | Loss: 0.6656 | CTC: 0.8083 | CE: 0.3326 | Time: 10.36s\n",
      "Epoch 15 | Batch 530/737 | Loss: 0.6426 | CTC: 0.7698 | CE: 0.3456 | Time: 10.38s\n",
      "Epoch 15 | Batch 540/737 | Loss: 0.6491 | CTC: 0.7929 | CE: 0.3136 | Time: 10.28s\n",
      "Epoch 15 | Batch 550/737 | Loss: 0.6782 | CTC: 0.8126 | CE: 0.3646 | Time: 10.01s\n",
      "Epoch 15 | Batch 560/737 | Loss: 0.6634 | CTC: 0.8167 | CE: 0.3056 | Time: 10.13s\n",
      "Epoch 15 | Batch 570/737 | Loss: 0.6646 | CTC: 0.8253 | CE: 0.2899 | Time: 10.47s\n",
      "Epoch 15 | Batch 580/737 | Loss: 0.6917 | CTC: 0.8501 | CE: 0.3222 | Time: 10.17s\n",
      "Epoch 15 | Batch 590/737 | Loss: 0.6844 | CTC: 0.8493 | CE: 0.2997 | Time: 10.15s\n",
      "Epoch 15 | Batch 600/737 | Loss: 0.6842 | CTC: 0.8529 | CE: 0.2904 | Time: 10.18s\n",
      "Epoch 15 | Batch 610/737 | Loss: 0.6917 | CTC: 0.8219 | CE: 0.3876 | Time: 10.43s\n",
      "Epoch 15 | Batch 620/737 | Loss: 0.5719 | CTC: 0.7054 | CE: 0.2604 | Time: 10.03s\n",
      "Epoch 15 | Batch 630/737 | Loss: 0.6814 | CTC: 0.8282 | CE: 0.3390 | Time: 10.35s\n",
      "Epoch 15 | Batch 640/737 | Loss: 0.6738 | CTC: 0.8182 | CE: 0.3369 | Time: 10.16s\n",
      "Epoch 15 | Batch 650/737 | Loss: 0.6897 | CTC: 0.8342 | CE: 0.3526 | Time: 10.19s\n",
      "Epoch 15 | Batch 660/737 | Loss: 0.6901 | CTC: 0.8505 | CE: 0.3161 | Time: 10.18s\n",
      "Epoch 15 | Batch 670/737 | Loss: 0.7489 | CTC: 0.9044 | CE: 0.3862 | Time: 10.12s\n",
      "Epoch 15 | Batch 680/737 | Loss: 0.6553 | CTC: 0.7978 | CE: 0.3228 | Time: 10.31s\n",
      "Epoch 15 | Batch 690/737 | Loss: 0.6195 | CTC: 0.7603 | CE: 0.2909 | Time: 10.00s\n",
      "Epoch 15 | Batch 700/737 | Loss: 0.6769 | CTC: 0.8210 | CE: 0.3406 | Time: 10.25s\n",
      "Epoch 15 | Batch 710/737 | Loss: 0.6626 | CTC: 0.8058 | CE: 0.3287 | Time: 10.18s\n",
      "Epoch 15 | Batch 720/737 | Loss: 0.5836 | CTC: 0.7166 | CE: 0.2732 | Time: 9.83s\n",
      "Epoch 15 | Batch 730/737 | Loss: 0.6124 | CTC: 0.7634 | CE: 0.2600 | Time: 10.32s\n",
      "Train Loss: 0.9165 | CTC: 1.1793 | CE: 0.3034\n",
      "Val Loss: 0.5994 | CTC: 0.7443 | CE: 0.2613\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prntain in the lysens withpwich warat presndt conerndt divfors frommostinotfrom alte artsoncpraftrrprisenti in the exibitioen\n",
      "\n",
      "Epoch 16/25\n",
      "Epoch 16 | Batch 0/737 | Loss: 0.6175 | CTC: 0.7631 | CE: 0.2777 | Time: 0.99s\n",
      "Epoch 16 | Batch 10/737 | Loss: 0.6247 | CTC: 0.7773 | CE: 0.2685 | Time: 10.36s\n",
      "Epoch 16 | Batch 20/737 | Loss: 0.6313 | CTC: 0.7763 | CE: 0.2930 | Time: 10.43s\n",
      "Epoch 16 | Batch 30/737 | Loss: 0.6404 | CTC: 0.7943 | CE: 0.2815 | Time: 10.35s\n",
      "Epoch 16 | Batch 40/737 | Loss: 0.6761 | CTC: 0.8415 | CE: 0.2899 | Time: 10.00s\n",
      "Epoch 16 | Batch 50/737 | Loss: 0.5474 | CTC: 0.6825 | CE: 0.2323 | Time: 10.12s\n",
      "Epoch 16 | Batch 60/737 | Loss: 0.5920 | CTC: 0.7348 | CE: 0.2591 | Time: 10.05s\n",
      "Epoch 16 | Batch 70/737 | Loss: 0.6095 | CTC: 0.7603 | CE: 0.2576 | Time: 10.64s\n",
      "Epoch 16 | Batch 80/737 | Loss: 0.6356 | CTC: 0.7855 | CE: 0.2858 | Time: 10.44s\n",
      "Epoch 16 | Batch 90/737 | Loss: 0.6831 | CTC: 0.8379 | CE: 0.3218 | Time: 10.37s\n",
      "Epoch 16 | Batch 100/737 | Loss: 0.6084 | CTC: 0.7526 | CE: 0.2720 | Time: 10.24s\n",
      "Epoch 16 | Batch 110/737 | Loss: 0.6002 | CTC: 0.7466 | CE: 0.2587 | Time: 9.99s\n",
      "Epoch 16 | Batch 120/737 | Loss: 0.5805 | CTC: 0.7194 | CE: 0.2563 | Time: 10.05s\n",
      "Epoch 16 | Batch 130/737 | Loss: 0.6238 | CTC: 0.7577 | CE: 0.3114 | Time: 9.87s\n",
      "Epoch 16 | Batch 140/737 | Loss: 0.6234 | CTC: 0.7718 | CE: 0.2773 | Time: 9.83s\n",
      "Epoch 16 | Batch 150/737 | Loss: 0.6174 | CTC: 0.7711 | CE: 0.2588 | Time: 10.26s\n",
      "Epoch 16 | Batch 160/737 | Loss: 0.6097 | CTC: 0.7661 | CE: 0.2446 | Time: 10.18s\n",
      "Epoch 16 | Batch 170/737 | Loss: 0.6241 | CTC: 0.7680 | CE: 0.2885 | Time: 10.38s\n",
      "Epoch 16 | Batch 180/737 | Loss: 0.6153 | CTC: 0.7607 | CE: 0.2759 | Time: 10.22s\n",
      "Epoch 16 | Batch 190/737 | Loss: 0.6292 | CTC: 0.7794 | CE: 0.2786 | Time: 10.31s\n",
      "Epoch 16 | Batch 200/737 | Loss: 0.5579 | CTC: 0.6919 | CE: 0.2450 | Time: 9.98s\n",
      "Epoch 16 | Batch 210/737 | Loss: 0.6458 | CTC: 0.8132 | CE: 0.2553 | Time: 10.03s\n",
      "Epoch 16 | Batch 220/737 | Loss: 0.6335 | CTC: 0.7853 | CE: 0.2792 | Time: 10.06s\n",
      "Epoch 16 | Batch 230/737 | Loss: 0.6102 | CTC: 0.7642 | CE: 0.2509 | Time: 10.31s\n",
      "Epoch 16 | Batch 240/737 | Loss: 0.5810 | CTC: 0.7043 | CE: 0.2934 | Time: 10.28s\n",
      "Epoch 16 | Batch 250/737 | Loss: 0.6625 | CTC: 0.8347 | CE: 0.2607 | Time: 10.47s\n",
      "Epoch 16 | Batch 260/737 | Loss: 0.5785 | CTC: 0.7148 | CE: 0.2605 | Time: 10.11s\n",
      "Epoch 16 | Batch 270/737 | Loss: 0.5356 | CTC: 0.6621 | CE: 0.2406 | Time: 10.20s\n",
      "Epoch 16 | Batch 280/737 | Loss: 0.6154 | CTC: 0.7706 | CE: 0.2532 | Time: 10.06s\n",
      "Epoch 16 | Batch 290/737 | Loss: 0.6649 | CTC: 0.7896 | CE: 0.3740 | Time: 10.03s\n",
      "Epoch 16 | Batch 300/737 | Loss: 0.5954 | CTC: 0.7428 | CE: 0.2514 | Time: 10.39s\n",
      "Epoch 16 | Batch 310/737 | Loss: 0.6126 | CTC: 0.7594 | CE: 0.2698 | Time: 9.92s\n",
      "Epoch 16 | Batch 320/737 | Loss: 0.5687 | CTC: 0.7054 | CE: 0.2498 | Time: 10.21s\n",
      "Epoch 16 | Batch 330/737 | Loss: 0.6085 | CTC: 0.7667 | CE: 0.2394 | Time: 10.25s\n",
      "Epoch 16 | Batch 340/737 | Loss: 0.5709 | CTC: 0.7058 | CE: 0.2562 | Time: 10.38s\n",
      "Epoch 16 | Batch 350/737 | Loss: 0.6805 | CTC: 0.8358 | CE: 0.3181 | Time: 10.32s\n",
      "Epoch 16 | Batch 360/737 | Loss: 0.6261 | CTC: 0.7718 | CE: 0.2863 | Time: 10.33s\n",
      "Epoch 16 | Batch 370/737 | Loss: 0.5864 | CTC: 0.7128 | CE: 0.2915 | Time: 10.47s\n",
      "Epoch 16 | Batch 380/737 | Loss: 0.5960 | CTC: 0.7329 | CE: 0.2767 | Time: 10.00s\n",
      "Epoch 16 | Batch 390/737 | Loss: 0.5836 | CTC: 0.7299 | CE: 0.2424 | Time: 10.38s\n",
      "Epoch 16 | Batch 400/737 | Loss: 0.5670 | CTC: 0.6989 | CE: 0.2593 | Time: 10.22s\n",
      "Epoch 16 | Batch 410/737 | Loss: 0.5598 | CTC: 0.6902 | CE: 0.2556 | Time: 10.02s\n",
      "Epoch 16 | Batch 420/737 | Loss: 0.5638 | CTC: 0.6939 | CE: 0.2604 | Time: 10.28s\n",
      "Epoch 16 | Batch 430/737 | Loss: 0.6070 | CTC: 0.7496 | CE: 0.2744 | Time: 10.21s\n",
      "Epoch 16 | Batch 440/737 | Loss: 0.5446 | CTC: 0.6955 | CE: 0.1925 | Time: 9.63s\n",
      "Epoch 16 | Batch 450/737 | Loss: 0.5626 | CTC: 0.7185 | CE: 0.1989 | Time: 10.06s\n",
      "Epoch 16 | Batch 460/737 | Loss: 0.5898 | CTC: 0.7393 | CE: 0.2411 | Time: 10.21s\n",
      "Epoch 16 | Batch 470/737 | Loss: 0.6207 | CTC: 0.7653 | CE: 0.2833 | Time: 10.11s\n",
      "Epoch 16 | Batch 480/737 | Loss: 0.5607 | CTC: 0.7044 | CE: 0.2252 | Time: 10.13s\n",
      "Epoch 16 | Batch 490/737 | Loss: 0.6142 | CTC: 0.7574 | CE: 0.2800 | Time: 10.26s\n",
      "Epoch 16 | Batch 500/737 | Loss: 0.5853 | CTC: 0.7250 | CE: 0.2592 | Time: 10.06s\n",
      "Epoch 16 | Batch 510/737 | Loss: 0.6212 | CTC: 0.7642 | CE: 0.2877 | Time: 10.39s\n",
      "Epoch 16 | Batch 520/737 | Loss: 0.6344 | CTC: 0.7921 | CE: 0.2664 | Time: 10.16s\n",
      "Epoch 16 | Batch 530/737 | Loss: 0.5179 | CTC: 0.6358 | CE: 0.2428 | Time: 10.10s\n",
      "Epoch 16 | Batch 540/737 | Loss: 0.5923 | CTC: 0.7309 | CE: 0.2688 | Time: 10.07s\n",
      "Epoch 16 | Batch 550/737 | Loss: 0.5617 | CTC: 0.6935 | CE: 0.2543 | Time: 10.37s\n",
      "Epoch 16 | Batch 560/737 | Loss: 0.6008 | CTC: 0.7378 | CE: 0.2810 | Time: 10.14s\n",
      "Epoch 16 | Batch 570/737 | Loss: 0.5974 | CTC: 0.7514 | CE: 0.2382 | Time: 9.97s\n",
      "Epoch 16 | Batch 580/737 | Loss: 0.6151 | CTC: 0.7750 | CE: 0.2420 | Time: 10.22s\n",
      "Epoch 16 | Batch 590/737 | Loss: 0.5608 | CTC: 0.6893 | CE: 0.2608 | Time: 10.31s\n",
      "Epoch 16 | Batch 600/737 | Loss: 0.6372 | CTC: 0.7879 | CE: 0.2854 | Time: 10.39s\n",
      "Epoch 16 | Batch 610/737 | Loss: 0.5931 | CTC: 0.7279 | CE: 0.2786 | Time: 10.09s\n",
      "Epoch 16 | Batch 620/737 | Loss: 24.2181 | CTC: 34.4723 | CE: 0.2917 | Time: 10.48s\n",
      "Epoch 16 | Batch 630/737 | Loss: 0.6158 | CTC: 0.7627 | CE: 0.2731 | Time: 10.08s\n",
      "Epoch 16 | Batch 640/737 | Loss: 0.6184 | CTC: 0.7668 | CE: 0.2722 | Time: 10.21s\n",
      "Epoch 16 | Batch 650/737 | Loss: 0.5818 | CTC: 0.7300 | CE: 0.2361 | Time: 10.26s\n",
      "Epoch 16 | Batch 660/737 | Loss: 0.5601 | CTC: 0.6842 | CE: 0.2707 | Time: 10.39s\n",
      "Epoch 16 | Batch 670/737 | Loss: 0.6154 | CTC: 0.7563 | CE: 0.2867 | Time: 10.14s\n",
      "Epoch 16 | Batch 680/737 | Loss: 0.5876 | CTC: 0.7118 | CE: 0.2978 | Time: 10.11s\n",
      "Epoch 16 | Batch 690/737 | Loss: 0.5409 | CTC: 0.6752 | CE: 0.2276 | Time: 10.23s\n",
      "Epoch 16 | Batch 700/737 | Loss: 0.5899 | CTC: 0.7317 | CE: 0.2589 | Time: 10.15s\n",
      "Epoch 16 | Batch 710/737 | Loss: 0.6547 | CTC: 0.7975 | CE: 0.3216 | Time: 10.33s\n",
      "Epoch 16 | Batch 720/737 | Loss: 0.6386 | CTC: 0.7753 | CE: 0.3198 | Time: 10.30s\n",
      "Epoch 16 | Batch 730/737 | Loss: 0.6091 | CTC: 0.7580 | CE: 0.2617 | Time: 10.21s\n",
      "Train Loss: 0.8794 | CTC: 1.1417 | CE: 0.2673\n",
      "Val Loss: 0.5721 | CTC: 0.7114 | CE: 0.2472\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnntaig in the nlysencwith which wrtpressnd concrnd divfors frommostinotfrom althe artsoncraftreprisenti in the exibition\n",
      "\n",
      "Epoch 17/25\n",
      "Epoch 17 | Batch 0/737 | Loss: 0.5513 | CTC: 0.6890 | CE: 0.2299 | Time: 1.05s\n",
      "Epoch 17 | Batch 10/737 | Loss: 0.5496 | CTC: 0.6861 | CE: 0.2311 | Time: 10.38s\n",
      "Epoch 17 | Batch 20/737 | Loss: 0.5902 | CTC: 0.7292 | CE: 0.2661 | Time: 9.78s\n",
      "Epoch 17 | Batch 30/737 | Loss: 0.5318 | CTC: 0.6808 | CE: 0.1840 | Time: 10.06s\n",
      "Epoch 17 | Batch 40/737 | Loss: 0.5080 | CTC: 0.6505 | CE: 0.1756 | Time: 10.06s\n",
      "Epoch 17 | Batch 50/737 | Loss: 0.5329 | CTC: 0.6825 | CE: 0.1839 | Time: 10.17s\n",
      "Epoch 17 | Batch 60/737 | Loss: 0.6111 | CTC: 0.7606 | CE: 0.2624 | Time: 10.70s\n",
      "Epoch 17 | Batch 70/737 | Loss: 0.5354 | CTC: 0.6758 | CE: 0.2079 | Time: 10.31s\n",
      "Epoch 17 | Batch 80/737 | Loss: 0.5044 | CTC: 0.6298 | CE: 0.2116 | Time: 10.09s\n",
      "Epoch 17 | Batch 90/737 | Loss: 0.6079 | CTC: 0.7686 | CE: 0.2327 | Time: 10.40s\n",
      "Epoch 17 | Batch 100/737 | Loss: 0.5424 | CTC: 0.6853 | CE: 0.2091 | Time: 9.97s\n",
      "Epoch 17 | Batch 110/737 | Loss: 0.5667 | CTC: 0.7136 | CE: 0.2239 | Time: 10.09s\n",
      "Epoch 17 | Batch 120/737 | Loss: 0.5148 | CTC: 0.6493 | CE: 0.2011 | Time: 10.19s\n",
      "Epoch 17 | Batch 130/737 | Loss: 0.5825 | CTC: 0.7256 | CE: 0.2486 | Time: 10.26s\n",
      "Epoch 17 | Batch 140/737 | Loss: 0.5950 | CTC: 0.7476 | CE: 0.2387 | Time: 10.48s\n",
      "Epoch 17 | Batch 150/737 | Loss: 0.5551 | CTC: 0.6979 | CE: 0.2219 | Time: 10.24s\n",
      "Epoch 17 | Batch 160/737 | Loss: 0.5923 | CTC: 0.7311 | CE: 0.2684 | Time: 9.95s\n",
      "Epoch 17 | Batch 170/737 | Loss: 0.5930 | CTC: 0.7361 | CE: 0.2591 | Time: 10.06s\n",
      "Epoch 17 | Batch 180/737 | Loss: 0.6165 | CTC: 0.7884 | CE: 0.2152 | Time: 10.24s\n",
      "Epoch 17 | Batch 190/737 | Loss: 0.5146 | CTC: 0.6437 | CE: 0.2133 | Time: 9.82s\n",
      "Epoch 17 | Batch 200/737 | Loss: 0.6296 | CTC: 0.7796 | CE: 0.2797 | Time: 10.29s\n",
      "Epoch 17 | Batch 210/737 | Loss: 0.6640 | CTC: 0.7828 | CE: 0.3870 | Time: 10.31s\n",
      "Epoch 17 | Batch 220/737 | Loss: 0.5624 | CTC: 0.7064 | CE: 0.2265 | Time: 10.31s\n",
      "Epoch 17 | Batch 230/737 | Loss: 0.5979 | CTC: 0.7361 | CE: 0.2754 | Time: 10.11s\n",
      "Epoch 17 | Batch 240/737 | Loss: 0.5223 | CTC: 0.6529 | CE: 0.2177 | Time: 10.41s\n",
      "Epoch 17 | Batch 250/737 | Loss: 0.6295 | CTC: 0.7737 | CE: 0.2929 | Time: 10.15s\n",
      "Epoch 17 | Batch 260/737 | Loss: 0.5609 | CTC: 0.7118 | CE: 0.2087 | Time: 10.24s\n",
      "Epoch 17 | Batch 270/737 | Loss: 0.5903 | CTC: 0.7538 | CE: 0.2087 | Time: 10.24s\n",
      "Epoch 17 | Batch 280/737 | Loss: 0.6032 | CTC: 0.7369 | CE: 0.2913 | Time: 10.49s\n",
      "Epoch 17 | Batch 290/737 | Loss: 0.4926 | CTC: 0.6158 | CE: 0.2051 | Time: 10.24s\n",
      "Epoch 17 | Batch 300/737 | Loss: 0.6536 | CTC: 0.7993 | CE: 0.3136 | Time: 10.23s\n",
      "Epoch 17 | Batch 310/737 | Loss: 0.5344 | CTC: 0.6714 | CE: 0.2147 | Time: 10.15s\n",
      "Epoch 17 | Batch 320/737 | Loss: 0.6097 | CTC: 0.7577 | CE: 0.2646 | Time: 10.28s\n",
      "Epoch 17 | Batch 330/737 | Loss: 0.5705 | CTC: 0.7134 | CE: 0.2370 | Time: 10.20s\n",
      "Epoch 17 | Batch 340/737 | Loss: 0.5891 | CTC: 0.7434 | CE: 0.2292 | Time: 10.29s\n",
      "Epoch 17 | Batch 350/737 | Loss: 0.5418 | CTC: 0.6837 | CE: 0.2106 | Time: 10.25s\n",
      "Epoch 17 | Batch 360/737 | Loss: 0.5343 | CTC: 0.6826 | CE: 0.1881 | Time: 10.36s\n",
      "Epoch 17 | Batch 370/737 | Loss: 0.5863 | CTC: 0.7186 | CE: 0.2777 | Time: 10.06s\n",
      "Epoch 17 | Batch 380/737 | Loss: 0.5649 | CTC: 0.6986 | CE: 0.2531 | Time: 10.38s\n",
      "Epoch 17 | Batch 390/737 | Loss: 0.6213 | CTC: 0.7740 | CE: 0.2650 | Time: 10.04s\n",
      "Epoch 17 | Batch 400/737 | Loss: 0.5943 | CTC: 0.7405 | CE: 0.2533 | Time: 10.14s\n",
      "Epoch 17 | Batch 410/737 | Loss: 0.6057 | CTC: 0.7591 | CE: 0.2478 | Time: 10.15s\n",
      "Epoch 17 | Batch 420/737 | Loss: 0.5671 | CTC: 0.7046 | CE: 0.2462 | Time: 10.36s\n",
      "Epoch 17 | Batch 430/737 | Loss: 0.6222 | CTC: 0.7939 | CE: 0.2217 | Time: 10.19s\n",
      "Epoch 17 | Batch 440/737 | Loss: 0.6138 | CTC: 0.7676 | CE: 0.2550 | Time: 10.15s\n",
      "Epoch 17 | Batch 450/737 | Loss: 0.5780 | CTC: 0.7253 | CE: 0.2343 | Time: 10.14s\n",
      "Epoch 17 | Batch 460/737 | Loss: 0.5346 | CTC: 0.6736 | CE: 0.2103 | Time: 10.29s\n",
      "Epoch 17 | Batch 470/737 | Loss: 0.5474 | CTC: 0.6857 | CE: 0.2246 | Time: 10.24s\n",
      "Epoch 17 | Batch 480/737 | Loss: 0.5911 | CTC: 0.7311 | CE: 0.2643 | Time: 10.01s\n",
      "Epoch 17 | Batch 490/737 | Loss: 0.5432 | CTC: 0.6883 | CE: 0.2046 | Time: 10.14s\n",
      "Epoch 17 | Batch 500/737 | Loss: 0.5181 | CTC: 0.6512 | CE: 0.2077 | Time: 10.06s\n",
      "Epoch 17 | Batch 510/737 | Loss: 0.5390 | CTC: 0.6763 | CE: 0.2187 | Time: 10.16s\n",
      "Epoch 17 | Batch 520/737 | Loss: 0.6092 | CTC: 0.7534 | CE: 0.2729 | Time: 10.09s\n",
      "Epoch 17 | Batch 530/737 | Loss: 0.5680 | CTC: 0.7008 | CE: 0.2581 | Time: 10.47s\n",
      "Epoch 17 | Batch 540/737 | Loss: 0.5698 | CTC: 0.7080 | CE: 0.2475 | Time: 10.28s\n",
      "Epoch 17 | Batch 550/737 | Loss: 0.5458 | CTC: 0.7008 | CE: 0.1840 | Time: 10.22s\n",
      "Epoch 17 | Batch 560/737 | Loss: 0.5938 | CTC: 0.7351 | CE: 0.2643 | Time: 10.27s\n",
      "Epoch 17 | Batch 570/737 | Loss: 0.5351 | CTC: 0.6782 | CE: 0.2014 | Time: 10.19s\n",
      "Epoch 17 | Batch 580/737 | Loss: 0.5619 | CTC: 0.7140 | CE: 0.2069 | Time: 10.35s\n",
      "Epoch 17 | Batch 590/737 | Loss: 0.6052 | CTC: 0.7616 | CE: 0.2404 | Time: 10.10s\n",
      "Epoch 17 | Batch 600/737 | Loss: 0.6052 | CTC: 0.7548 | CE: 0.2563 | Time: 10.16s\n",
      "Epoch 17 | Batch 610/737 | Loss: 0.5785 | CTC: 0.7046 | CE: 0.2842 | Time: 10.20s\n",
      "Epoch 17 | Batch 620/737 | Loss: 0.5648 | CTC: 0.7095 | CE: 0.2271 | Time: 9.97s\n",
      "Epoch 17 | Batch 630/737 | Loss: 0.5870 | CTC: 0.7304 | CE: 0.2525 | Time: 10.46s\n",
      "Epoch 17 | Batch 640/737 | Loss: 0.5145 | CTC: 0.6382 | CE: 0.2259 | Time: 10.20s\n",
      "Epoch 17 | Batch 650/737 | Loss: 0.5107 | CTC: 0.6445 | CE: 0.1984 | Time: 9.91s\n",
      "Epoch 17 | Batch 660/737 | Loss: 0.6249 | CTC: 0.7644 | CE: 0.2994 | Time: 10.24s\n",
      "Epoch 17 | Batch 670/737 | Loss: 0.5900 | CTC: 0.7477 | CE: 0.2220 | Time: 10.08s\n",
      "Epoch 17 | Batch 680/737 | Loss: 0.5790 | CTC: 0.7155 | CE: 0.2605 | Time: 9.99s\n",
      "Epoch 17 | Batch 690/737 | Loss: 0.6537 | CTC: 0.8174 | CE: 0.2718 | Time: 10.05s\n",
      "Epoch 17 | Batch 700/737 | Loss: 0.5519 | CTC: 0.6984 | CE: 0.2102 | Time: 9.97s\n",
      "Epoch 17 | Batch 710/737 | Loss: 0.6076 | CTC: 0.7677 | CE: 0.2338 | Time: 10.29s\n",
      "Epoch 17 | Batch 720/737 | Loss: 0.6150 | CTC: 0.7654 | CE: 0.2641 | Time: 10.43s\n",
      "Epoch 17 | Batch 730/737 | Loss: 0.5594 | CTC: 0.6988 | CE: 0.2342 | Time: 10.09s\n",
      "Train Loss: 0.8484 | CTC: 1.1112 | CE: 0.2354\n",
      "Val Loss: 0.5411 | CTC: 0.6756 | CE: 0.2274\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnting in the nlysens with wich we aret present conerned diffors frommostifinotfrom alte artsoncpraftreprisenti in the exibition\n",
      "\n",
      "Epoch 18/25\n",
      "Epoch 18 | Batch 0/737 | Loss: 0.5313 | CTC: 0.6829 | CE: 0.1776 | Time: 1.07s\n",
      "Epoch 18 | Batch 10/737 | Loss: 0.5681 | CTC: 0.7129 | CE: 0.2304 | Time: 10.40s\n",
      "Epoch 18 | Batch 20/737 | Loss: 0.5005 | CTC: 0.6309 | CE: 0.1964 | Time: 10.05s\n",
      "Epoch 18 | Batch 30/737 | Loss: 0.4827 | CTC: 0.5876 | CE: 0.2381 | Time: 10.09s\n",
      "Epoch 18 | Batch 40/737 | Loss: 0.5421 | CTC: 0.6786 | CE: 0.2235 | Time: 10.28s\n",
      "Epoch 18 | Batch 50/737 | Loss: 0.5294 | CTC: 0.6666 | CE: 0.2091 | Time: 10.22s\n",
      "Epoch 18 | Batch 60/737 | Loss: 0.5554 | CTC: 0.6931 | CE: 0.2341 | Time: 10.06s\n",
      "Epoch 18 | Batch 70/737 | Loss: 0.5600 | CTC: 0.7062 | CE: 0.2187 | Time: 10.25s\n",
      "Epoch 18 | Batch 80/737 | Loss: 0.5043 | CTC: 0.6469 | CE: 0.1716 | Time: 10.01s\n",
      "Epoch 18 | Batch 90/737 | Loss: 0.5122 | CTC: 0.6583 | CE: 0.1716 | Time: 10.15s\n",
      "Epoch 18 | Batch 100/737 | Loss: 0.5259 | CTC: 0.6659 | CE: 0.1994 | Time: 10.00s\n",
      "Epoch 18 | Batch 110/737 | Loss: 0.5324 | CTC: 0.6825 | CE: 0.1822 | Time: 10.53s\n",
      "Epoch 18 | Batch 120/737 | Loss: 0.5328 | CTC: 0.6763 | CE: 0.1981 | Time: 10.17s\n",
      "Epoch 18 | Batch 130/737 | Loss: 0.5473 | CTC: 0.6949 | CE: 0.2028 | Time: 10.07s\n",
      "Epoch 18 | Batch 140/737 | Loss: 0.5600 | CTC: 0.6970 | CE: 0.2405 | Time: 10.12s\n",
      "Epoch 18 | Batch 150/737 | Loss: 0.5218 | CTC: 0.6600 | CE: 0.1993 | Time: 10.40s\n",
      "Epoch 18 | Batch 160/737 | Loss: 0.5958 | CTC: 0.7526 | CE: 0.2300 | Time: 10.56s\n",
      "Epoch 18 | Batch 170/737 | Loss: 0.5550 | CTC: 0.7041 | CE: 0.2069 | Time: 10.43s\n",
      "Epoch 18 | Batch 180/737 | Loss: 0.5620 | CTC: 0.7079 | CE: 0.2215 | Time: 10.27s\n",
      "Epoch 18 | Batch 190/737 | Loss: 0.4718 | CTC: 0.6014 | CE: 0.1696 | Time: 10.35s\n",
      "Epoch 18 | Batch 200/737 | Loss: 0.5151 | CTC: 0.6586 | CE: 0.1805 | Time: 10.08s\n",
      "Epoch 18 | Batch 210/737 | Loss: 0.5473 | CTC: 0.6794 | CE: 0.2391 | Time: 10.33s\n",
      "Epoch 18 | Batch 220/737 | Loss: 0.5211 | CTC: 0.6605 | CE: 0.1959 | Time: 10.06s\n",
      "Epoch 18 | Batch 230/737 | Loss: 0.5747 | CTC: 0.7305 | CE: 0.2111 | Time: 10.21s\n",
      "Epoch 18 | Batch 240/737 | Loss: 0.5570 | CTC: 0.7047 | CE: 0.2122 | Time: 10.30s\n",
      "Epoch 18 | Batch 250/737 | Loss: 0.5401 | CTC: 0.6753 | CE: 0.2246 | Time: 10.41s\n",
      "Epoch 18 | Batch 260/737 | Loss: 0.5591 | CTC: 0.7090 | CE: 0.2091 | Time: 10.29s\n",
      "Epoch 18 | Batch 270/737 | Loss: 0.5472 | CTC: 0.6955 | CE: 0.2012 | Time: 9.91s\n",
      "Epoch 18 | Batch 280/737 | Loss: 0.5305 | CTC: 0.6734 | CE: 0.1971 | Time: 10.19s\n",
      "Epoch 18 | Batch 290/737 | Loss: 0.5166 | CTC: 0.6624 | CE: 0.1763 | Time: 10.15s\n",
      "Epoch 18 | Batch 300/737 | Loss: 0.5407 | CTC: 0.6840 | CE: 0.2063 | Time: 10.16s\n",
      "Epoch 18 | Batch 310/737 | Loss: 0.5207 | CTC: 0.6578 | CE: 0.2008 | Time: 10.44s\n",
      "Epoch 18 | Batch 320/737 | Loss: 0.5320 | CTC: 0.6731 | CE: 0.2027 | Time: 10.15s\n",
      "Epoch 18 | Batch 330/737 | Loss: 0.5091 | CTC: 0.6385 | CE: 0.2072 | Time: 10.18s\n",
      "Epoch 18 | Batch 340/737 | Loss: 0.4549 | CTC: 0.5868 | CE: 0.1472 | Time: 10.43s\n",
      "Epoch 18 | Batch 350/737 | Loss: 0.5582 | CTC: 0.6950 | CE: 0.2390 | Time: 10.37s\n",
      "Epoch 18 | Batch 360/737 | Loss: 0.5992 | CTC: 0.7539 | CE: 0.2383 | Time: 10.06s\n",
      "Epoch 18 | Batch 370/737 | Loss: 0.5873 | CTC: 0.7262 | CE: 0.2631 | Time: 10.28s\n",
      "Epoch 18 | Batch 380/737 | Loss: 0.5943 | CTC: 0.7393 | CE: 0.2561 | Time: 10.21s\n",
      "Epoch 18 | Batch 390/737 | Loss: 0.4805 | CTC: 0.5876 | CE: 0.2306 | Time: 10.23s\n",
      "Epoch 18 | Batch 400/737 | Loss: 0.5638 | CTC: 0.7151 | CE: 0.2106 | Time: 10.22s\n",
      "Epoch 18 | Batch 410/737 | Loss: 0.5239 | CTC: 0.6505 | CE: 0.2284 | Time: 10.60s\n",
      "Epoch 18 | Batch 420/737 | Loss: 0.5622 | CTC: 0.7127 | CE: 0.2110 | Time: 10.28s\n",
      "Epoch 18 | Batch 430/737 | Loss: 0.5406 | CTC: 0.6667 | CE: 0.2461 | Time: 10.24s\n",
      "Epoch 18 | Batch 440/737 | Loss: 0.5212 | CTC: 0.6692 | CE: 0.1759 | Time: 9.81s\n",
      "Epoch 18 | Batch 450/737 | Loss: 0.5588 | CTC: 0.7043 | CE: 0.2193 | Time: 10.25s\n",
      "Epoch 18 | Batch 460/737 | Loss: 0.5109 | CTC: 0.6562 | CE: 0.1718 | Time: 9.98s\n",
      "Epoch 18 | Batch 470/737 | Loss: 0.5440 | CTC: 0.6939 | CE: 0.1940 | Time: 10.18s\n",
      "Epoch 18 | Batch 480/737 | Loss: 0.4600 | CTC: 0.5768 | CE: 0.1876 | Time: 9.80s\n",
      "Epoch 18 | Batch 490/737 | Loss: 0.6048 | CTC: 0.7547 | CE: 0.2548 | Time: 9.90s\n",
      "Epoch 18 | Batch 500/737 | Loss: 0.5064 | CTC: 0.6434 | CE: 0.1867 | Time: 10.05s\n",
      "Epoch 18 | Batch 510/737 | Loss: 0.4873 | CTC: 0.6040 | CE: 0.2151 | Time: 10.24s\n",
      "Epoch 18 | Batch 520/737 | Loss: 0.6111 | CTC: 0.7608 | CE: 0.2616 | Time: 10.24s\n",
      "Epoch 18 | Batch 530/737 | Loss: 0.4853 | CTC: 0.5944 | CE: 0.2307 | Time: 10.19s\n",
      "Epoch 18 | Batch 540/737 | Loss: 0.5368 | CTC: 0.6778 | CE: 0.2080 | Time: 10.11s\n",
      "Epoch 18 | Batch 550/737 | Loss: 0.5497 | CTC: 0.6970 | CE: 0.2061 | Time: 9.99s\n",
      "Epoch 18 | Batch 560/737 | Loss: 0.5478 | CTC: 0.6884 | CE: 0.2197 | Time: 10.32s\n",
      "Epoch 18 | Batch 570/737 | Loss: 0.5100 | CTC: 0.6493 | CE: 0.1850 | Time: 10.14s\n",
      "Epoch 18 | Batch 580/737 | Loss: 0.5540 | CTC: 0.7045 | CE: 0.2028 | Time: 10.34s\n",
      "Epoch 18 | Batch 590/737 | Loss: 0.5627 | CTC: 0.7129 | CE: 0.2123 | Time: 10.24s\n",
      "Epoch 18 | Batch 600/737 | Loss: 0.6521 | CTC: 0.7917 | CE: 0.3264 | Time: 10.25s\n",
      "Epoch 18 | Batch 610/737 | Loss: 0.5976 | CTC: 0.7530 | CE: 0.2349 | Time: 10.09s\n",
      "Epoch 18 | Batch 620/737 | Loss: 13.7059 | CTC: 19.4842 | CE: 0.2233 | Time: 10.14s\n",
      "Epoch 18 | Batch 630/737 | Loss: 0.5206 | CTC: 0.6567 | CE: 0.2031 | Time: 10.21s\n",
      "Epoch 18 | Batch 640/737 | Loss: 0.5329 | CTC: 0.6728 | CE: 0.2066 | Time: 10.13s\n",
      "Epoch 18 | Batch 650/737 | Loss: 0.4077 | CTC: 0.5117 | CE: 0.1651 | Time: 10.12s\n",
      "Epoch 18 | Batch 660/737 | Loss: 0.6104 | CTC: 0.7494 | CE: 0.2861 | Time: 10.21s\n",
      "Epoch 18 | Batch 670/737 | Loss: 0.5269 | CTC: 0.6518 | CE: 0.2354 | Time: 10.06s\n",
      "Epoch 18 | Batch 680/737 | Loss: 0.5135 | CTC: 0.6522 | CE: 0.1900 | Time: 10.12s\n",
      "Epoch 18 | Batch 690/737 | Loss: 0.5185 | CTC: 0.6628 | CE: 0.1819 | Time: 10.20s\n",
      "Epoch 18 | Batch 700/737 | Loss: 0.4845 | CTC: 0.6239 | CE: 0.1593 | Time: 10.12s\n",
      "Epoch 18 | Batch 710/737 | Loss: 0.5486 | CTC: 0.6784 | CE: 0.2455 | Time: 10.18s\n",
      "Epoch 18 | Batch 720/737 | Loss: 0.4750 | CTC: 0.6045 | CE: 0.1729 | Time: 10.03s\n",
      "Epoch 18 | Batch 730/737 | Loss: 0.4829 | CTC: 0.6125 | CE: 0.1804 | Time: 9.82s\n",
      "Train Loss: 0.8080 | CTC: 1.0637 | CE: 0.2113\n",
      "Val Loss: 0.5141 | CTC: 0.6411 | CE: 0.2177\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnting in the nlysencs withwhich waredt prescn conernd diffors frommostifnotfrom al the artsincraftreprisentid in the exibition\n",
      "\n",
      "Epoch 19/25\n",
      "Epoch 19 | Batch 0/737 | Loss: 0.5559 | CTC: 0.7053 | CE: 0.2073 | Time: 0.96s\n",
      "Epoch 19 | Batch 10/737 | Loss: 0.5021 | CTC: 0.6412 | CE: 0.1776 | Time: 10.39s\n",
      "Epoch 19 | Batch 20/737 | Loss: 0.4903 | CTC: 0.6195 | CE: 0.1890 | Time: 10.46s\n",
      "Epoch 19 | Batch 30/737 | Loss: 0.4438 | CTC: 0.5694 | CE: 0.1507 | Time: 10.29s\n",
      "Epoch 19 | Batch 40/737 | Loss: 0.5342 | CTC: 0.6647 | CE: 0.2297 | Time: 10.14s\n",
      "Epoch 19 | Batch 50/737 | Loss: 0.5285 | CTC: 0.6749 | CE: 0.1867 | Time: 10.23s\n",
      "Epoch 19 | Batch 60/737 | Loss: 0.5153 | CTC: 0.6551 | CE: 0.1892 | Time: 10.28s\n",
      "Epoch 19 | Batch 70/737 | Loss: 0.5420 | CTC: 0.6829 | CE: 0.2132 | Time: 10.29s\n",
      "Epoch 19 | Batch 80/737 | Loss: 0.4554 | CTC: 0.5831 | CE: 0.1576 | Time: 10.26s\n",
      "Epoch 19 | Batch 90/737 | Loss: 0.4953 | CTC: 0.6162 | CE: 0.2133 | Time: 9.75s\n",
      "Epoch 19 | Batch 100/737 | Loss: 0.5411 | CTC: 0.6837 | CE: 0.2082 | Time: 10.18s\n",
      "Epoch 19 | Batch 110/737 | Loss: 0.5316 | CTC: 0.6677 | CE: 0.2141 | Time: 10.09s\n",
      "Epoch 19 | Batch 120/737 | Loss: 0.5902 | CTC: 0.7326 | CE: 0.2580 | Time: 10.32s\n",
      "Epoch 19 | Batch 130/737 | Loss: 0.4841 | CTC: 0.6144 | CE: 0.1800 | Time: 10.47s\n",
      "Epoch 19 | Batch 140/737 | Loss: 0.4755 | CTC: 0.6131 | CE: 0.1546 | Time: 10.18s\n",
      "Epoch 19 | Batch 150/737 | Loss: 0.4729 | CTC: 0.5967 | CE: 0.1840 | Time: 9.91s\n",
      "Epoch 19 | Batch 160/737 | Loss: 0.5059 | CTC: 0.6300 | CE: 0.2162 | Time: 10.46s\n",
      "Epoch 19 | Batch 170/737 | Loss: 0.5256 | CTC: 0.6644 | CE: 0.2018 | Time: 10.09s\n",
      "Epoch 19 | Batch 180/737 | Loss: 0.5122 | CTC: 0.6570 | CE: 0.1743 | Time: 10.26s\n",
      "Epoch 19 | Batch 190/737 | Loss: 0.5242 | CTC: 0.6625 | CE: 0.2013 | Time: 9.93s\n",
      "Epoch 19 | Batch 200/737 | Loss: 0.5163 | CTC: 0.6468 | CE: 0.2118 | Time: 10.15s\n",
      "Epoch 19 | Batch 210/737 | Loss: 0.5644 | CTC: 0.7102 | CE: 0.2243 | Time: 10.25s\n",
      "Epoch 19 | Batch 220/737 | Loss: 0.4423 | CTC: 0.5559 | CE: 0.1771 | Time: 10.34s\n",
      "Epoch 19 | Batch 230/737 | Loss: 0.4605 | CTC: 0.5818 | CE: 0.1775 | Time: 10.14s\n",
      "Epoch 19 | Batch 240/737 | Loss: 0.5156 | CTC: 0.6401 | CE: 0.2250 | Time: 10.17s\n",
      "Epoch 19 | Batch 250/737 | Loss: 0.4961 | CTC: 0.6305 | CE: 0.1825 | Time: 10.00s\n",
      "Epoch 19 | Batch 260/737 | Loss: 0.4802 | CTC: 0.6152 | CE: 0.1653 | Time: 10.20s\n",
      "Epoch 19 | Batch 270/737 | Loss: 0.5064 | CTC: 0.6561 | CE: 0.1570 | Time: 10.11s\n",
      "Epoch 19 | Batch 280/737 | Loss: 0.4919 | CTC: 0.6161 | CE: 0.2020 | Time: 10.14s\n",
      "Epoch 19 | Batch 290/737 | Loss: 0.5033 | CTC: 0.6293 | CE: 0.2092 | Time: 10.13s\n",
      "Epoch 19 | Batch 300/737 | Loss: 0.4826 | CTC: 0.6098 | CE: 0.1858 | Time: 10.20s\n",
      "Epoch 19 | Batch 310/737 | Loss: 0.4813 | CTC: 0.6025 | CE: 0.1986 | Time: 10.33s\n",
      "Epoch 19 | Batch 320/737 | Loss: 0.5540 | CTC: 0.7027 | CE: 0.2071 | Time: 10.25s\n",
      "Epoch 19 | Batch 330/737 | Loss: 0.5136 | CTC: 0.6622 | CE: 0.1668 | Time: 10.07s\n",
      "Epoch 19 | Batch 340/737 | Loss: 0.5181 | CTC: 0.6454 | CE: 0.2211 | Time: 10.31s\n",
      "Epoch 19 | Batch 350/737 | Loss: 0.6038 | CTC: 0.7574 | CE: 0.2455 | Time: 10.47s\n",
      "Epoch 19 | Batch 360/737 | Loss: 0.5322 | CTC: 0.6610 | CE: 0.2316 | Time: 10.10s\n",
      "Epoch 19 | Batch 370/737 | Loss: 0.5340 | CTC: 0.6666 | CE: 0.2245 | Time: 9.95s\n",
      "Epoch 19 | Batch 380/737 | Loss: 0.5259 | CTC: 0.6761 | CE: 0.1755 | Time: 10.21s\n",
      "Epoch 19 | Batch 390/737 | Loss: 0.5034 | CTC: 0.6518 | CE: 0.1570 | Time: 9.97s\n",
      "Epoch 19 | Batch 400/737 | Loss: 0.4935 | CTC: 0.6315 | CE: 0.1716 | Time: 10.11s\n",
      "Epoch 19 | Batch 410/737 | Loss: 0.4536 | CTC: 0.5840 | CE: 0.1495 | Time: 10.01s\n",
      "Epoch 19 | Batch 420/737 | Loss: 0.4598 | CTC: 0.5846 | CE: 0.1686 | Time: 10.10s\n",
      "Epoch 19 | Batch 430/737 | Loss: 0.4479 | CTC: 0.5746 | CE: 0.1524 | Time: 10.10s\n",
      "Epoch 19 | Batch 440/737 | Loss: 0.5736 | CTC: 0.7244 | CE: 0.2220 | Time: 10.18s\n",
      "Epoch 19 | Batch 450/737 | Loss: 0.4581 | CTC: 0.5895 | CE: 0.1514 | Time: 10.28s\n",
      "Epoch 19 | Batch 460/737 | Loss: 0.5270 | CTC: 0.6600 | CE: 0.2166 | Time: 10.38s\n",
      "Epoch 19 | Batch 470/737 | Loss: 0.4988 | CTC: 0.6464 | CE: 0.1545 | Time: 10.28s\n",
      "Epoch 19 | Batch 480/737 | Loss: 0.4956 | CTC: 0.6297 | CE: 0.1827 | Time: 10.46s\n",
      "Epoch 19 | Batch 490/737 | Loss: 0.5236 | CTC: 0.6613 | CE: 0.2024 | Time: 10.48s\n",
      "Epoch 19 | Batch 500/737 | Loss: 0.4959 | CTC: 0.6091 | CE: 0.2320 | Time: 10.10s\n",
      "Epoch 19 | Batch 510/737 | Loss: 7.1377 | CTC: 10.1002 | CE: 0.2252 | Time: 10.22s\n",
      "Epoch 19 | Batch 520/737 | Loss: 0.4870 | CTC: 0.6208 | CE: 0.1748 | Time: 10.17s\n",
      "Epoch 19 | Batch 530/737 | Loss: 0.4726 | CTC: 0.5985 | CE: 0.1788 | Time: 10.29s\n",
      "Epoch 19 | Batch 540/737 | Loss: 0.4525 | CTC: 0.5820 | CE: 0.1502 | Time: 10.22s\n",
      "Epoch 19 | Batch 550/737 | Loss: 0.5660 | CTC: 0.7071 | CE: 0.2367 | Time: 10.19s\n",
      "Epoch 19 | Batch 560/737 | Loss: 0.4594 | CTC: 0.5868 | CE: 0.1620 | Time: 10.43s\n",
      "Epoch 19 | Batch 570/737 | Loss: 0.5273 | CTC: 0.6523 | CE: 0.2354 | Time: 9.84s\n",
      "Epoch 19 | Batch 580/737 | Loss: 0.4981 | CTC: 0.6335 | CE: 0.1820 | Time: 10.34s\n",
      "Epoch 19 | Batch 590/737 | Loss: 0.4392 | CTC: 0.5524 | CE: 0.1751 | Time: 10.22s\n",
      "Epoch 19 | Batch 600/737 | Loss: 0.5030 | CTC: 0.6385 | CE: 0.1870 | Time: 10.35s\n",
      "Epoch 19 | Batch 610/737 | Loss: 0.4902 | CTC: 0.6228 | CE: 0.1807 | Time: 9.94s\n",
      "Epoch 19 | Batch 620/737 | Loss: 0.5164 | CTC: 0.6626 | CE: 0.1753 | Time: 10.36s\n",
      "Epoch 19 | Batch 630/737 | Loss: 0.4381 | CTC: 0.5589 | CE: 0.1562 | Time: 10.06s\n",
      "Epoch 19 | Batch 640/737 | Loss: 0.4737 | CTC: 0.6106 | CE: 0.1541 | Time: 10.08s\n",
      "Epoch 19 | Batch 650/737 | Loss: 0.5121 | CTC: 0.6570 | CE: 0.1742 | Time: 10.19s\n",
      "Epoch 19 | Batch 660/737 | Loss: 0.5315 | CTC: 0.6761 | CE: 0.1940 | Time: 10.31s\n",
      "Epoch 19 | Batch 670/737 | Loss: 0.5170 | CTC: 0.6644 | CE: 0.1732 | Time: 10.13s\n",
      "Epoch 19 | Batch 680/737 | Loss: 0.4833 | CTC: 0.6106 | CE: 0.1861 | Time: 10.42s\n",
      "Epoch 19 | Batch 690/737 | Loss: 0.4878 | CTC: 0.6204 | CE: 0.1783 | Time: 10.08s\n",
      "Epoch 19 | Batch 700/737 | Loss: 0.5096 | CTC: 0.6441 | CE: 0.1958 | Time: 10.11s\n",
      "Epoch 19 | Batch 710/737 | Loss: 0.4110 | CTC: 0.5320 | CE: 0.1285 | Time: 10.18s\n",
      "Epoch 19 | Batch 720/737 | Loss: 0.5152 | CTC: 0.6391 | CE: 0.2260 | Time: 10.39s\n",
      "Epoch 19 | Batch 730/737 | Loss: 0.5140 | CTC: 0.6421 | CE: 0.2148 | Time: 10.25s\n",
      "Train Loss: 0.7554 | CTC: 0.9982 | CE: 0.1889\n",
      "Val Loss: 0.5064 | CTC: 0.6289 | CE: 0.2203\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnnting in the onlycens with wich w aratpresen conernd diffors frommostienotfrom al the artsoncraftrrprisente in the exibition\n",
      "\n",
      "Epoch 20/25\n",
      "Epoch 20 | Batch 0/737 | Loss: 0.5122 | CTC: 0.6408 | CE: 0.2123 | Time: 1.04s\n",
      "Epoch 20 | Batch 10/737 | Loss: 0.4575 | CTC: 0.5880 | CE: 0.1530 | Time: 10.30s\n",
      "Epoch 20 | Batch 20/737 | Loss: 0.4370 | CTC: 0.5589 | CE: 0.1526 | Time: 10.33s\n",
      "Epoch 20 | Batch 30/737 | Loss: 0.4809 | CTC: 0.6133 | CE: 0.1721 | Time: 10.30s\n",
      "Epoch 20 | Batch 40/737 | Loss: 0.4630 | CTC: 0.5969 | CE: 0.1505 | Time: 10.12s\n",
      "Epoch 20 | Batch 50/737 | Loss: 0.4259 | CTC: 0.5409 | CE: 0.1575 | Time: 10.33s\n",
      "Epoch 20 | Batch 60/737 | Loss: 0.4884 | CTC: 0.6188 | CE: 0.1841 | Time: 10.16s\n",
      "Epoch 20 | Batch 70/737 | Loss: 0.4360 | CTC: 0.5561 | CE: 0.1558 | Time: 10.07s\n",
      "Epoch 20 | Batch 80/737 | Loss: 0.4530 | CTC: 0.5677 | CE: 0.1854 | Time: 10.03s\n",
      "Epoch 20 | Batch 90/737 | Loss: 0.5044 | CTC: 0.6351 | CE: 0.1993 | Time: 9.82s\n",
      "Epoch 20 | Batch 100/737 | Loss: 0.3778 | CTC: 0.4851 | CE: 0.1273 | Time: 10.22s\n",
      "Epoch 20 | Batch 110/737 | Loss: 0.4472 | CTC: 0.5662 | CE: 0.1697 | Time: 10.19s\n",
      "Epoch 20 | Batch 120/737 | Loss: 0.4877 | CTC: 0.6181 | CE: 0.1834 | Time: 10.19s\n",
      "Epoch 20 | Batch 130/737 | Loss: 0.5041 | CTC: 0.6432 | CE: 0.1798 | Time: 10.24s\n",
      "Epoch 20 | Batch 140/737 | Loss: 0.5012 | CTC: 0.6358 | CE: 0.1874 | Time: 10.04s\n",
      "Epoch 20 | Batch 150/737 | Loss: 0.4873 | CTC: 0.6253 | CE: 0.1655 | Time: 10.35s\n",
      "Epoch 20 | Batch 160/737 | Loss: 0.4839 | CTC: 0.6290 | CE: 0.1454 | Time: 10.36s\n",
      "Epoch 20 | Batch 170/737 | Loss: 0.4217 | CTC: 0.5471 | CE: 0.1289 | Time: 10.24s\n",
      "Epoch 20 | Batch 180/737 | Loss: 0.4582 | CTC: 0.5841 | CE: 0.1646 | Time: 10.22s\n",
      "Epoch 20 | Batch 190/737 | Loss: 0.5095 | CTC: 0.6585 | CE: 0.1618 | Time: 10.16s\n",
      "Epoch 20 | Batch 200/737 | Loss: 0.4780 | CTC: 0.6103 | CE: 0.1693 | Time: 10.35s\n",
      "Epoch 20 | Batch 210/737 | Loss: 9.0837 | CTC: 12.8846 | CE: 0.2147 | Time: 9.92s\n",
      "Epoch 20 | Batch 220/737 | Loss: 0.5048 | CTC: 0.6310 | CE: 0.2103 | Time: 9.91s\n",
      "Epoch 20 | Batch 230/737 | Loss: 0.5135 | CTC: 0.6488 | CE: 0.1979 | Time: 10.27s\n",
      "Epoch 20 | Batch 240/737 | Loss: 0.4178 | CTC: 0.5323 | CE: 0.1505 | Time: 9.77s\n",
      "Epoch 20 | Batch 250/737 | Loss: 0.5020 | CTC: 0.6443 | CE: 0.1700 | Time: 9.87s\n",
      "Epoch 20 | Batch 260/737 | Loss: 0.4976 | CTC: 0.6325 | CE: 0.1828 | Time: 10.31s\n",
      "Epoch 20 | Batch 270/737 | Loss: 0.4415 | CTC: 0.5654 | CE: 0.1523 | Time: 10.26s\n",
      "Epoch 20 | Batch 280/737 | Loss: 0.4780 | CTC: 0.6102 | CE: 0.1696 | Time: 10.48s\n",
      "Epoch 20 | Batch 290/737 | Loss: 0.4988 | CTC: 0.6425 | CE: 0.1636 | Time: 10.26s\n",
      "Epoch 20 | Batch 300/737 | Loss: 0.4391 | CTC: 0.5769 | CE: 0.1176 | Time: 10.05s\n",
      "Epoch 20 | Batch 310/737 | Loss: 0.4647 | CTC: 0.5980 | CE: 0.1538 | Time: 10.12s\n",
      "Epoch 20 | Batch 320/737 | Loss: 0.4960 | CTC: 0.6434 | CE: 0.1521 | Time: 10.18s\n",
      "Epoch 20 | Batch 330/737 | Loss: 0.5259 | CTC: 0.6609 | CE: 0.2108 | Time: 10.37s\n",
      "Epoch 20 | Batch 340/737 | Loss: 0.4886 | CTC: 0.6213 | CE: 0.1788 | Time: 10.19s\n",
      "Epoch 20 | Batch 350/737 | Loss: 0.4459 | CTC: 0.5766 | CE: 0.1407 | Time: 10.24s\n",
      "Epoch 20 | Batch 360/737 | Loss: 0.4283 | CTC: 0.5353 | CE: 0.1785 | Time: 10.26s\n",
      "Epoch 20 | Batch 370/737 | Loss: 0.4549 | CTC: 0.5926 | CE: 0.1337 | Time: 10.37s\n",
      "Epoch 20 | Batch 380/737 | Loss: 0.4831 | CTC: 0.6220 | CE: 0.1591 | Time: 10.11s\n",
      "Epoch 20 | Batch 390/737 | Loss: 0.4769 | CTC: 0.6063 | CE: 0.1747 | Time: 10.31s\n",
      "Epoch 20 | Batch 400/737 | Loss: 0.4834 | CTC: 0.6194 | CE: 0.1661 | Time: 9.80s\n",
      "Epoch 20 | Batch 410/737 | Loss: 0.4509 | CTC: 0.5738 | CE: 0.1642 | Time: 10.31s\n",
      "Epoch 20 | Batch 420/737 | Loss: 0.4642 | CTC: 0.5940 | CE: 0.1612 | Time: 10.33s\n",
      "Epoch 20 | Batch 430/737 | Loss: 0.4572 | CTC: 0.5826 | CE: 0.1645 | Time: 10.08s\n",
      "Epoch 20 | Batch 440/737 | Loss: 0.5167 | CTC: 0.6590 | CE: 0.1847 | Time: 9.75s\n",
      "Epoch 20 | Batch 450/737 | Loss: 0.4974 | CTC: 0.6311 | CE: 0.1854 | Time: 10.10s\n",
      "Epoch 20 | Batch 460/737 | Loss: 0.4688 | CTC: 0.5959 | CE: 0.1722 | Time: 10.11s\n",
      "Epoch 20 | Batch 470/737 | Loss: 0.3795 | CTC: 0.4811 | CE: 0.1425 | Time: 10.24s\n",
      "Epoch 20 | Batch 480/737 | Loss: 0.4506 | CTC: 0.5714 | CE: 0.1689 | Time: 10.22s\n",
      "Epoch 20 | Batch 490/737 | Loss: 0.4117 | CTC: 0.5342 | CE: 0.1260 | Time: 10.20s\n",
      "Epoch 20 | Batch 500/737 | Loss: 0.5089 | CTC: 0.6565 | CE: 0.1643 | Time: 10.43s\n",
      "Epoch 20 | Batch 510/737 | Loss: 0.4683 | CTC: 0.5951 | CE: 0.1723 | Time: 10.16s\n",
      "Epoch 20 | Batch 520/737 | Loss: 0.4355 | CTC: 0.5501 | CE: 0.1682 | Time: 10.14s\n",
      "Epoch 20 | Batch 530/737 | Loss: 0.4636 | CTC: 0.5883 | CE: 0.1727 | Time: 10.06s\n",
      "Epoch 20 | Batch 540/737 | Loss: 0.4191 | CTC: 0.5489 | CE: 0.1161 | Time: 10.47s\n",
      "Epoch 20 | Batch 550/737 | Loss: 0.5033 | CTC: 0.6237 | CE: 0.2225 | Time: 10.30s\n",
      "Epoch 20 | Batch 560/737 | Loss: 0.4965 | CTC: 0.6362 | CE: 0.1704 | Time: 9.87s\n",
      "Epoch 20 | Batch 570/737 | Loss: 0.5255 | CTC: 0.6692 | CE: 0.1903 | Time: 10.19s\n",
      "Epoch 20 | Batch 580/737 | Loss: 0.4628 | CTC: 0.5906 | CE: 0.1644 | Time: 10.20s\n",
      "Epoch 20 | Batch 590/737 | Loss: 0.4774 | CTC: 0.5957 | CE: 0.2012 | Time: 10.26s\n",
      "Epoch 20 | Batch 600/737 | Loss: 0.5047 | CTC: 0.6280 | CE: 0.2169 | Time: 10.39s\n",
      "Epoch 20 | Batch 610/737 | Loss: 0.5131 | CTC: 0.6627 | CE: 0.1641 | Time: 10.04s\n",
      "Epoch 20 | Batch 620/737 | Loss: 0.4676 | CTC: 0.5838 | CE: 0.1967 | Time: 10.02s\n",
      "Epoch 20 | Batch 630/737 | Loss: 0.4764 | CTC: 0.6072 | CE: 0.1712 | Time: 10.25s\n",
      "Epoch 20 | Batch 640/737 | Loss: 0.4668 | CTC: 0.5913 | CE: 0.1763 | Time: 10.09s\n",
      "Epoch 20 | Batch 650/737 | Loss: 0.4719 | CTC: 0.6125 | CE: 0.1438 | Time: 10.29s\n",
      "Epoch 20 | Batch 660/737 | Loss: 0.4208 | CTC: 0.5414 | CE: 0.1396 | Time: 10.08s\n",
      "Epoch 20 | Batch 670/737 | Loss: 0.5095 | CTC: 0.6461 | CE: 0.1907 | Time: 10.28s\n",
      "Epoch 20 | Batch 680/737 | Loss: 0.4601 | CTC: 0.5823 | CE: 0.1749 | Time: 10.13s\n",
      "Epoch 20 | Batch 690/737 | Loss: 0.5048 | CTC: 0.6284 | CE: 0.2163 | Time: 10.03s\n",
      "Epoch 20 | Batch 700/737 | Loss: 0.4805 | CTC: 0.5997 | CE: 0.2024 | Time: 10.24s\n",
      "Epoch 20 | Batch 710/737 | Loss: 0.4876 | CTC: 0.6234 | CE: 0.1707 | Time: 10.36s\n",
      "Epoch 20 | Batch 720/737 | Loss: 0.5344 | CTC: 0.6689 | CE: 0.2204 | Time: 10.20s\n",
      "Epoch 20 | Batch 730/737 | Loss: 0.5276 | CTC: 0.6783 | CE: 0.1760 | Time: 10.34s\n",
      "Train Loss: 0.7395 | CTC: 0.9823 | CE: 0.1727\n",
      "Val Loss: 0.4839 | CTC: 0.6078 | CE: 0.1950\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnting in the nlysens with wich waret presnt coneernd diffors from mosdienotfrom althe artsoncrafrrprisented in the exibition\n",
      "\n",
      "Epoch 21/25\n",
      "Epoch 21 | Batch 0/737 | Loss: 0.4872 | CTC: 0.6218 | CE: 0.1732 | Time: 1.07s\n",
      "Epoch 21 | Batch 10/737 | Loss: 0.4708 | CTC: 0.5966 | CE: 0.1773 | Time: 10.28s\n",
      "Epoch 21 | Batch 20/737 | Loss: 0.4895 | CTC: 0.6319 | CE: 0.1571 | Time: 10.11s\n",
      "Epoch 21 | Batch 30/737 | Loss: 0.4129 | CTC: 0.5342 | CE: 0.1298 | Time: 10.30s\n",
      "Epoch 21 | Batch 40/737 | Loss: 0.4687 | CTC: 0.5981 | CE: 0.1668 | Time: 10.15s\n",
      "Epoch 21 | Batch 50/737 | Loss: 0.4529 | CTC: 0.5698 | CE: 0.1799 | Time: 10.19s\n",
      "Epoch 21 | Batch 60/737 | Loss: 0.4279 | CTC: 0.5235 | CE: 0.2051 | Time: 10.44s\n",
      "Epoch 21 | Batch 70/737 | Loss: 0.4320 | CTC: 0.5618 | CE: 0.1291 | Time: 10.29s\n",
      "Epoch 21 | Batch 80/737 | Loss: 0.4080 | CTC: 0.5253 | CE: 0.1342 | Time: 10.26s\n",
      "Epoch 21 | Batch 90/737 | Loss: 0.3776 | CTC: 0.4887 | CE: 0.1184 | Time: 10.38s\n",
      "Epoch 21 | Batch 100/737 | Loss: 0.4089 | CTC: 0.5255 | CE: 0.1370 | Time: 10.37s\n",
      "Epoch 21 | Batch 110/737 | Loss: 0.5046 | CTC: 0.6306 | CE: 0.2106 | Time: 9.86s\n",
      "Epoch 21 | Batch 120/737 | Loss: 0.4247 | CTC: 0.5467 | CE: 0.1400 | Time: 10.21s\n",
      "Epoch 21 | Batch 130/737 | Loss: 0.4313 | CTC: 0.5589 | CE: 0.1334 | Time: 10.44s\n",
      "Epoch 21 | Batch 140/737 | Loss: 0.4319 | CTC: 0.5444 | CE: 0.1693 | Time: 10.33s\n",
      "Epoch 21 | Batch 150/737 | Loss: 0.4635 | CTC: 0.5806 | CE: 0.1905 | Time: 10.41s\n",
      "Epoch 21 | Batch 160/737 | Loss: 12.4771 | CTC: 17.7244 | CE: 0.2333 | Time: 9.92s\n",
      "Epoch 21 | Batch 170/737 | Loss: 0.4037 | CTC: 0.5142 | CE: 0.1461 | Time: 10.16s\n",
      "Epoch 21 | Batch 180/737 | Loss: 0.4462 | CTC: 0.5613 | CE: 0.1775 | Time: 10.13s\n",
      "Epoch 21 | Batch 190/737 | Loss: 0.4608 | CTC: 0.5905 | CE: 0.1580 | Time: 10.23s\n",
      "Epoch 21 | Batch 200/737 | Loss: 0.4460 | CTC: 0.5735 | CE: 0.1486 | Time: 10.06s\n",
      "Epoch 21 | Batch 210/737 | Loss: 0.4557 | CTC: 0.5902 | CE: 0.1419 | Time: 10.14s\n",
      "Epoch 21 | Batch 220/737 | Loss: 0.4393 | CTC: 0.5649 | CE: 0.1460 | Time: 10.12s\n",
      "Epoch 21 | Batch 230/737 | Loss: 0.4415 | CTC: 0.5609 | CE: 0.1628 | Time: 10.00s\n",
      "Epoch 21 | Batch 240/737 | Loss: 0.3871 | CTC: 0.5072 | CE: 0.1068 | Time: 10.19s\n",
      "Epoch 21 | Batch 250/737 | Loss: 0.3893 | CTC: 0.5057 | CE: 0.1175 | Time: 9.89s\n",
      "Epoch 21 | Batch 260/737 | Loss: 0.4899 | CTC: 0.6178 | CE: 0.1914 | Time: 10.23s\n",
      "Epoch 21 | Batch 270/737 | Loss: 0.4896 | CTC: 0.6321 | CE: 0.1572 | Time: 10.21s\n",
      "Epoch 21 | Batch 280/737 | Loss: 0.4848 | CTC: 0.6059 | CE: 0.2024 | Time: 10.27s\n",
      "Epoch 21 | Batch 290/737 | Loss: 4.4250 | CTC: 6.2463 | CE: 0.1753 | Time: 10.31s\n",
      "Epoch 21 | Batch 300/737 | Loss: 0.4674 | CTC: 0.5927 | CE: 0.1749 | Time: 10.32s\n",
      "Epoch 21 | Batch 310/737 | Loss: 0.4451 | CTC: 0.5682 | CE: 0.1580 | Time: 10.03s\n",
      "Epoch 21 | Batch 320/737 | Loss: 0.4260 | CTC: 0.5273 | CE: 0.1896 | Time: 10.29s\n",
      "Epoch 21 | Batch 330/737 | Loss: 0.5264 | CTC: 0.6729 | CE: 0.1843 | Time: 10.16s\n",
      "Epoch 21 | Batch 340/737 | Loss: 0.4823 | CTC: 0.6082 | CE: 0.1886 | Time: 10.07s\n",
      "Epoch 21 | Batch 350/737 | Loss: 0.4319 | CTC: 0.5500 | CE: 0.1564 | Time: 10.45s\n",
      "Epoch 21 | Batch 360/737 | Loss: 0.4401 | CTC: 0.5616 | CE: 0.1565 | Time: 10.30s\n",
      "Epoch 21 | Batch 370/737 | Loss: 0.4970 | CTC: 0.6199 | CE: 0.2102 | Time: 10.25s\n",
      "Epoch 21 | Batch 380/737 | Loss: 0.5123 | CTC: 0.6512 | CE: 0.1882 | Time: 10.01s\n",
      "Epoch 21 | Batch 390/737 | Loss: 0.4145 | CTC: 0.5278 | CE: 0.1500 | Time: 10.10s\n",
      "Epoch 21 | Batch 400/737 | Loss: 0.4471 | CTC: 0.5671 | CE: 0.1672 | Time: 10.15s\n",
      "Epoch 21 | Batch 410/737 | Loss: 0.4499 | CTC: 0.5656 | CE: 0.1802 | Time: 9.92s\n",
      "Epoch 21 | Batch 420/737 | Loss: 0.4001 | CTC: 0.4893 | CE: 0.1919 | Time: 9.84s\n",
      "Epoch 21 | Batch 430/737 | Loss: 0.4611 | CTC: 0.5910 | CE: 0.1580 | Time: 10.13s\n",
      "Epoch 21 | Batch 440/737 | Loss: 0.4911 | CTC: 0.6246 | CE: 0.1797 | Time: 9.71s\n",
      "Epoch 21 | Batch 450/737 | Loss: 0.4509 | CTC: 0.5792 | CE: 0.1515 | Time: 10.23s\n",
      "Epoch 21 | Batch 460/737 | Loss: 10.6480 | CTC: 15.1375 | CE: 0.1724 | Time: 10.39s\n",
      "Epoch 21 | Batch 470/737 | Loss: 0.4453 | CTC: 0.5716 | CE: 0.1505 | Time: 10.35s\n",
      "Epoch 21 | Batch 480/737 | Loss: 11.0861 | CTC: 15.7701 | CE: 0.1568 | Time: 10.19s\n",
      "Epoch 21 | Batch 490/737 | Loss: 0.4437 | CTC: 0.5620 | CE: 0.1676 | Time: 10.31s\n",
      "Epoch 21 | Batch 500/737 | Loss: 0.4351 | CTC: 0.5552 | CE: 0.1546 | Time: 10.23s\n",
      "Epoch 21 | Batch 510/737 | Loss: 0.4295 | CTC: 0.5438 | CE: 0.1626 | Time: 10.09s\n",
      "Epoch 21 | Batch 520/737 | Loss: 0.4853 | CTC: 0.6038 | CE: 0.2087 | Time: 10.20s\n",
      "Epoch 21 | Batch 530/737 | Loss: 0.5119 | CTC: 0.6455 | CE: 0.2003 | Time: 10.07s\n",
      "Epoch 21 | Batch 540/737 | Loss: 0.4624 | CTC: 0.5857 | CE: 0.1746 | Time: 10.39s\n",
      "Epoch 21 | Batch 550/737 | Loss: 0.4466 | CTC: 0.5828 | CE: 0.1289 | Time: 10.42s\n",
      "Epoch 21 | Batch 560/737 | Loss: 0.3736 | CTC: 0.4828 | CE: 0.1188 | Time: 10.27s\n",
      "Epoch 21 | Batch 570/737 | Loss: 0.4409 | CTC: 0.5581 | CE: 0.1675 | Time: 10.04s\n",
      "Epoch 21 | Batch 580/737 | Loss: 0.4540 | CTC: 0.5846 | CE: 0.1493 | Time: 10.18s\n",
      "Epoch 21 | Batch 590/737 | Loss: 0.4518 | CTC: 0.5769 | CE: 0.1598 | Time: 10.34s\n",
      "Epoch 21 | Batch 600/737 | Loss: 0.4584 | CTC: 0.5870 | CE: 0.1582 | Time: 10.02s\n",
      "Epoch 21 | Batch 610/737 | Loss: 0.3976 | CTC: 0.5141 | CE: 0.1259 | Time: 10.03s\n",
      "Epoch 21 | Batch 620/737 | Loss: 0.3873 | CTC: 0.4875 | CE: 0.1536 | Time: 10.30s\n",
      "Epoch 21 | Batch 630/737 | Loss: 0.4739 | CTC: 0.5918 | CE: 0.1987 | Time: 10.33s\n",
      "Epoch 21 | Batch 640/737 | Loss: 0.4524 | CTC: 0.5859 | CE: 0.1409 | Time: 10.44s\n",
      "Epoch 21 | Batch 650/737 | Loss: 0.4920 | CTC: 0.6307 | CE: 0.1683 | Time: 10.22s\n",
      "Epoch 21 | Batch 660/737 | Loss: 0.4850 | CTC: 0.6269 | CE: 0.1540 | Time: 10.34s\n",
      "Epoch 21 | Batch 670/737 | Loss: 0.5467 | CTC: 0.7191 | CE: 0.1446 | Time: 10.31s\n",
      "Epoch 21 | Batch 680/737 | Loss: 0.4630 | CTC: 0.5881 | CE: 0.1711 | Time: 9.68s\n",
      "Epoch 21 | Batch 690/737 | Loss: 0.4700 | CTC: 0.6007 | CE: 0.1652 | Time: 10.21s\n",
      "Epoch 21 | Batch 700/737 | Loss: 0.4469 | CTC: 0.5718 | CE: 0.1555 | Time: 10.43s\n",
      "Epoch 21 | Batch 710/737 | Loss: 0.4195 | CTC: 0.5386 | CE: 0.1416 | Time: 10.28s\n",
      "Epoch 21 | Batch 720/737 | Loss: 0.4470 | CTC: 0.5729 | CE: 0.1533 | Time: 10.15s\n",
      "Epoch 21 | Batch 730/737 | Loss: 0.5238 | CTC: 0.6610 | CE: 0.2036 | Time: 9.96s\n",
      "Train Loss: 0.6751 | CTC: 0.8977 | CE: 0.1558\n",
      "Val Loss: 0.4687 | CTC: 0.5888 | CE: 0.1885\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnting in the nlysens withwich wareat presn conernd diffors from mosdtienotfrom althey arts ondcrafrrprisente in the exibition\n",
      "\n",
      "Epoch 22/25\n",
      "Epoch 22 | Batch 0/737 | Loss: 0.4147 | CTC: 0.5264 | CE: 0.1541 | Time: 0.99s\n",
      "Epoch 22 | Batch 10/737 | Loss: 0.3864 | CTC: 0.4962 | CE: 0.1303 | Time: 10.05s\n",
      "Epoch 22 | Batch 20/737 | Loss: 0.3821 | CTC: 0.4947 | CE: 0.1194 | Time: 10.30s\n",
      "Epoch 22 | Batch 30/737 | Loss: 0.4437 | CTC: 0.5649 | CE: 0.1609 | Time: 10.32s\n",
      "Epoch 22 | Batch 40/737 | Loss: 0.3789 | CTC: 0.4889 | CE: 0.1223 | Time: 10.39s\n",
      "Epoch 22 | Batch 50/737 | Loss: 0.4056 | CTC: 0.5277 | CE: 0.1206 | Time: 10.20s\n",
      "Epoch 22 | Batch 60/737 | Loss: 0.3804 | CTC: 0.4917 | CE: 0.1209 | Time: 10.28s\n",
      "Epoch 22 | Batch 70/737 | Loss: 0.4368 | CTC: 0.5675 | CE: 0.1318 | Time: 10.34s\n",
      "Epoch 22 | Batch 80/737 | Loss: 0.4240 | CTC: 0.5287 | CE: 0.1798 | Time: 10.21s\n",
      "Epoch 22 | Batch 90/737 | Loss: 0.4443 | CTC: 0.5555 | CE: 0.1848 | Time: 10.24s\n",
      "Epoch 22 | Batch 100/737 | Loss: 0.3857 | CTC: 0.4846 | CE: 0.1550 | Time: 10.35s\n",
      "Epoch 22 | Batch 110/737 | Loss: 0.4015 | CTC: 0.5212 | CE: 0.1221 | Time: 10.31s\n",
      "Epoch 22 | Batch 120/737 | Loss: 0.4513 | CTC: 0.5879 | CE: 0.1325 | Time: 10.37s\n",
      "Epoch 22 | Batch 130/737 | Loss: 0.4095 | CTC: 0.5307 | CE: 0.1265 | Time: 10.08s\n",
      "Epoch 22 | Batch 140/737 | Loss: 0.3846 | CTC: 0.4849 | CE: 0.1506 | Time: 10.28s\n",
      "Epoch 22 | Batch 150/737 | Loss: 0.4101 | CTC: 0.5334 | CE: 0.1224 | Time: 10.39s\n",
      "Epoch 22 | Batch 160/737 | Loss: 0.4781 | CTC: 0.5992 | CE: 0.1955 | Time: 10.31s\n",
      "Epoch 22 | Batch 170/737 | Loss: 0.4214 | CTC: 0.5395 | CE: 0.1457 | Time: 9.95s\n",
      "Epoch 22 | Batch 180/737 | Loss: 0.4197 | CTC: 0.5285 | CE: 0.1658 | Time: 10.14s\n",
      "Epoch 22 | Batch 190/737 | Loss: 0.4306 | CTC: 0.5529 | CE: 0.1451 | Time: 10.13s\n",
      "Epoch 22 | Batch 200/737 | Loss: 0.4158 | CTC: 0.5267 | CE: 0.1571 | Time: 10.11s\n",
      "Epoch 22 | Batch 210/737 | Loss: 0.3996 | CTC: 0.5164 | CE: 0.1271 | Time: 10.30s\n",
      "Epoch 22 | Batch 220/737 | Loss: 0.4351 | CTC: 0.5544 | CE: 0.1568 | Time: 10.25s\n",
      "Epoch 22 | Batch 230/737 | Loss: 0.3903 | CTC: 0.4941 | CE: 0.1480 | Time: 10.03s\n",
      "Epoch 22 | Batch 240/737 | Loss: 0.3492 | CTC: 0.4593 | CE: 0.0921 | Time: 10.01s\n",
      "Epoch 22 | Batch 250/737 | Loss: 0.4462 | CTC: 0.5779 | CE: 0.1387 | Time: 10.32s\n",
      "Epoch 22 | Batch 260/737 | Loss: 0.4016 | CTC: 0.5181 | CE: 0.1299 | Time: 10.00s\n",
      "Epoch 22 | Batch 270/737 | Loss: 0.4003 | CTC: 0.5080 | CE: 0.1490 | Time: 10.18s\n",
      "Epoch 22 | Batch 280/737 | Loss: 0.4232 | CTC: 0.5353 | CE: 0.1617 | Time: 10.16s\n",
      "Epoch 22 | Batch 290/737 | Loss: 0.4313 | CTC: 0.5542 | CE: 0.1447 | Time: 10.06s\n",
      "Epoch 22 | Batch 300/737 | Loss: 0.4460 | CTC: 0.5579 | CE: 0.1849 | Time: 10.25s\n",
      "Epoch 22 | Batch 310/737 | Loss: 0.4906 | CTC: 0.6361 | CE: 0.1510 | Time: 10.30s\n",
      "Epoch 22 | Batch 320/737 | Loss: 0.3873 | CTC: 0.5051 | CE: 0.1125 | Time: 10.14s\n",
      "Epoch 22 | Batch 330/737 | Loss: 0.4622 | CTC: 0.5876 | CE: 0.1696 | Time: 10.39s\n",
      "Epoch 22 | Batch 340/737 | Loss: 14.2052 | CTC: 20.2187 | CE: 0.1738 | Time: 10.54s\n",
      "Epoch 22 | Batch 350/737 | Loss: 0.3968 | CTC: 0.5143 | CE: 0.1226 | Time: 10.09s\n",
      "Epoch 22 | Batch 360/737 | Loss: 0.4518 | CTC: 0.5733 | CE: 0.1683 | Time: 10.25s\n",
      "Epoch 22 | Batch 370/737 | Loss: 0.4944 | CTC: 0.6424 | CE: 0.1492 | Time: 10.20s\n",
      "Epoch 22 | Batch 380/737 | Loss: 0.4255 | CTC: 0.5348 | CE: 0.1705 | Time: 10.39s\n",
      "Epoch 22 | Batch 390/737 | Loss: 0.4013 | CTC: 0.5191 | CE: 0.1265 | Time: 10.37s\n",
      "Epoch 22 | Batch 400/737 | Loss: 0.4133 | CTC: 0.5332 | CE: 0.1336 | Time: 10.12s\n",
      "Epoch 22 | Batch 410/737 | Loss: 0.4669 | CTC: 0.5878 | CE: 0.1848 | Time: 10.17s\n",
      "Epoch 22 | Batch 420/737 | Loss: 0.4140 | CTC: 0.5322 | CE: 0.1381 | Time: 10.02s\n",
      "Epoch 22 | Batch 430/737 | Loss: 4.9386 | CTC: 6.9816 | CE: 0.1716 | Time: 9.75s\n",
      "Epoch 22 | Batch 440/737 | Loss: 0.4121 | CTC: 0.5365 | CE: 0.1217 | Time: 10.19s\n",
      "Epoch 22 | Batch 450/737 | Loss: 0.4160 | CTC: 0.5397 | CE: 0.1273 | Time: 10.38s\n",
      "Epoch 22 | Batch 460/737 | Loss: 0.4246 | CTC: 0.5499 | CE: 0.1321 | Time: 10.33s\n",
      "Epoch 22 | Batch 470/737 | Loss: 8.3199 | CTC: 11.8092 | CE: 0.1781 | Time: 10.25s\n",
      "Epoch 22 | Batch 480/737 | Loss: 9.6683 | CTC: 13.7343 | CE: 0.1808 | Time: 10.23s\n",
      "Epoch 22 | Batch 490/737 | Loss: 0.4134 | CTC: 0.5250 | CE: 0.1531 | Time: 10.12s\n",
      "Epoch 22 | Batch 500/737 | Loss: 0.3806 | CTC: 0.4778 | CE: 0.1537 | Time: 10.25s\n",
      "Epoch 22 | Batch 510/737 | Loss: 0.4326 | CTC: 0.5539 | CE: 0.1496 | Time: 10.06s\n",
      "Epoch 22 | Batch 520/737 | Loss: 0.4287 | CTC: 0.5551 | CE: 0.1339 | Time: 10.03s\n",
      "Epoch 22 | Batch 530/737 | Loss: 0.4685 | CTC: 0.5853 | CE: 0.1958 | Time: 10.38s\n",
      "Epoch 22 | Batch 540/737 | Loss: 0.3724 | CTC: 0.4853 | CE: 0.1089 | Time: 10.26s\n",
      "Epoch 22 | Batch 550/737 | Loss: 0.4236 | CTC: 0.5509 | CE: 0.1268 | Time: 10.33s\n",
      "Epoch 22 | Batch 560/737 | Loss: 0.4518 | CTC: 0.5825 | CE: 0.1468 | Time: 10.20s\n",
      "Epoch 22 | Batch 570/737 | Loss: 0.4842 | CTC: 0.6203 | CE: 0.1666 | Time: 10.12s\n",
      "Epoch 22 | Batch 580/737 | Loss: 0.4121 | CTC: 0.5282 | CE: 0.1410 | Time: 10.15s\n",
      "Epoch 22 | Batch 590/737 | Loss: 0.4067 | CTC: 0.5154 | CE: 0.1531 | Time: 10.29s\n",
      "Epoch 22 | Batch 600/737 | Loss: 0.4073 | CTC: 0.5379 | CE: 0.1025 | Time: 10.34s\n",
      "Epoch 22 | Batch 610/737 | Loss: 0.4197 | CTC: 0.5474 | CE: 0.1217 | Time: 10.28s\n",
      "Epoch 22 | Batch 620/737 | Loss: 0.4129 | CTC: 0.5305 | CE: 0.1386 | Time: 10.36s\n",
      "Epoch 22 | Batch 630/737 | Loss: 0.4341 | CTC: 0.5421 | CE: 0.1820 | Time: 10.52s\n",
      "Epoch 22 | Batch 640/737 | Loss: 0.3953 | CTC: 0.5095 | CE: 0.1286 | Time: 10.19s\n",
      "Epoch 22 | Batch 650/737 | Loss: 0.3862 | CTC: 0.5053 | CE: 0.1083 | Time: 10.33s\n",
      "Epoch 22 | Batch 660/737 | Loss: 0.4687 | CTC: 0.6007 | CE: 0.1608 | Time: 10.30s\n",
      "Epoch 22 | Batch 670/737 | Loss: 0.3353 | CTC: 0.4396 | CE: 0.0920 | Time: 10.32s\n",
      "Epoch 22 | Batch 680/737 | Loss: 0.3971 | CTC: 0.5119 | CE: 0.1291 | Time: 10.35s\n",
      "Epoch 22 | Batch 690/737 | Loss: 0.4030 | CTC: 0.5241 | CE: 0.1203 | Time: 10.28s\n",
      "Epoch 22 | Batch 700/737 | Loss: 0.4027 | CTC: 0.5149 | CE: 0.1409 | Time: 9.97s\n",
      "Epoch 22 | Batch 710/737 | Loss: 0.4893 | CTC: 0.6081 | CE: 0.2122 | Time: 10.29s\n",
      "Epoch 22 | Batch 720/737 | Loss: 0.4569 | CTC: 0.5893 | CE: 0.1479 | Time: 10.08s\n",
      "Epoch 22 | Batch 730/737 | Loss: 0.4802 | CTC: 0.6119 | CE: 0.1728 | Time: 10.12s\n",
      "Train Loss: 0.6463 | CTC: 0.8622 | CE: 0.1423\n",
      "Val Loss: 0.4674 | CTC: 0.5825 | CE: 0.1989\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnting in the nly sence with which weradt presnt conernd divffors from most enotfrom al the artsandcraftrprisenti in the exibition\n",
      "\n",
      "Epoch 23/25\n",
      "Epoch 23 | Batch 0/737 | Loss: 0.3492 | CTC: 0.4537 | CE: 0.1054 | Time: 1.04s\n",
      "Epoch 23 | Batch 10/737 | Loss: 0.3811 | CTC: 0.5045 | CE: 0.0932 | Time: 10.13s\n",
      "Epoch 23 | Batch 20/737 | Loss: 0.3838 | CTC: 0.4938 | CE: 0.1271 | Time: 10.34s\n",
      "Epoch 23 | Batch 30/737 | Loss: 0.4001 | CTC: 0.5347 | CE: 0.0860 | Time: 10.26s\n",
      "Epoch 23 | Batch 40/737 | Loss: 0.3693 | CTC: 0.4779 | CE: 0.1158 | Time: 10.20s\n",
      "Epoch 23 | Batch 50/737 | Loss: 0.3872 | CTC: 0.4971 | CE: 0.1307 | Time: 10.17s\n",
      "Epoch 23 | Batch 60/737 | Loss: 0.4066 | CTC: 0.5258 | CE: 0.1286 | Time: 10.17s\n",
      "Epoch 23 | Batch 70/737 | Loss: 0.3598 | CTC: 0.4636 | CE: 0.1177 | Time: 9.98s\n",
      "Epoch 23 | Batch 80/737 | Loss: 0.4224 | CTC: 0.5483 | CE: 0.1287 | Time: 10.07s\n",
      "Epoch 23 | Batch 90/737 | Loss: 0.3735 | CTC: 0.4868 | CE: 0.1090 | Time: 10.24s\n",
      "Epoch 23 | Batch 100/737 | Loss: 0.4649 | CTC: 0.5982 | CE: 0.1539 | Time: 10.38s\n",
      "Epoch 23 | Batch 110/737 | Loss: 0.3760 | CTC: 0.4883 | CE: 0.1140 | Time: 10.22s\n",
      "Epoch 23 | Batch 120/737 | Loss: 0.3993 | CTC: 0.5193 | CE: 0.1192 | Time: 10.26s\n",
      "Epoch 23 | Batch 130/737 | Loss: 0.3922 | CTC: 0.4873 | CE: 0.1705 | Time: 10.46s\n",
      "Epoch 23 | Batch 140/737 | Loss: 0.4086 | CTC: 0.5325 | CE: 0.1194 | Time: 10.29s\n",
      "Epoch 23 | Batch 150/737 | Loss: 0.4513 | CTC: 0.5827 | CE: 0.1447 | Time: 10.13s\n",
      "Epoch 23 | Batch 160/737 | Loss: 0.3606 | CTC: 0.4689 | CE: 0.1079 | Time: 10.38s\n",
      "Epoch 23 | Batch 170/737 | Loss: 0.3617 | CTC: 0.4749 | CE: 0.0975 | Time: 10.35s\n",
      "Epoch 23 | Batch 180/737 | Loss: 0.3847 | CTC: 0.4955 | CE: 0.1262 | Time: 10.36s\n",
      "Epoch 23 | Batch 190/737 | Loss: 0.3629 | CTC: 0.4726 | CE: 0.1070 | Time: 9.93s\n",
      "Epoch 23 | Batch 200/737 | Loss: 0.4100 | CTC: 0.5235 | CE: 0.1451 | Time: 10.43s\n",
      "Epoch 23 | Batch 210/737 | Loss: 0.4044 | CTC: 0.5241 | CE: 0.1252 | Time: 10.11s\n",
      "Epoch 23 | Batch 220/737 | Loss: 0.3838 | CTC: 0.4887 | CE: 0.1390 | Time: 10.50s\n",
      "Epoch 23 | Batch 230/737 | Loss: 0.3948 | CTC: 0.5051 | CE: 0.1372 | Time: 10.48s\n",
      "Epoch 23 | Batch 240/737 | Loss: 0.4015 | CTC: 0.5191 | CE: 0.1271 | Time: 10.15s\n",
      "Epoch 23 | Batch 250/737 | Loss: 0.4275 | CTC: 0.5511 | CE: 0.1392 | Time: 10.17s\n",
      "Epoch 23 | Batch 260/737 | Loss: 0.3654 | CTC: 0.4776 | CE: 0.1038 | Time: 10.26s\n",
      "Epoch 23 | Batch 270/737 | Loss: 0.4868 | CTC: 0.6152 | CE: 0.1871 | Time: 10.29s\n",
      "Epoch 23 | Batch 280/737 | Loss: 0.3410 | CTC: 0.4470 | CE: 0.0936 | Time: 9.99s\n",
      "Epoch 23 | Batch 290/737 | Loss: 0.4175 | CTC: 0.5388 | CE: 0.1346 | Time: 10.16s\n",
      "Epoch 23 | Batch 300/737 | Loss: 0.4821 | CTC: 0.5974 | CE: 0.2130 | Time: 10.25s\n",
      "Epoch 23 | Batch 310/737 | Loss: 0.4038 | CTC: 0.5232 | CE: 0.1251 | Time: 10.24s\n",
      "Epoch 23 | Batch 320/737 | Loss: 0.4371 | CTC: 0.5565 | CE: 0.1584 | Time: 10.04s\n",
      "Epoch 23 | Batch 330/737 | Loss: 0.3677 | CTC: 0.4704 | CE: 0.1282 | Time: 9.86s\n",
      "Epoch 23 | Batch 340/737 | Loss: 0.3960 | CTC: 0.5083 | CE: 0.1340 | Time: 10.21s\n",
      "Epoch 23 | Batch 350/737 | Loss: 0.3873 | CTC: 0.4892 | CE: 0.1496 | Time: 10.00s\n",
      "Epoch 23 | Batch 360/737 | Loss: 0.3608 | CTC: 0.4751 | CE: 0.0940 | Time: 9.97s\n",
      "Epoch 23 | Batch 370/737 | Loss: 0.4012 | CTC: 0.5245 | CE: 0.1136 | Time: 10.24s\n",
      "Epoch 23 | Batch 380/737 | Loss: 0.4421 | CTC: 0.5697 | CE: 0.1442 | Time: 9.98s\n",
      "Epoch 23 | Batch 390/737 | Loss: 0.4345 | CTC: 0.5568 | CE: 0.1490 | Time: 10.27s\n",
      "Epoch 23 | Batch 400/737 | Loss: 0.3902 | CTC: 0.5019 | CE: 0.1298 | Time: 10.14s\n",
      "Epoch 23 | Batch 410/737 | Loss: 0.3790 | CTC: 0.4976 | CE: 0.1023 | Time: 10.15s\n",
      "Epoch 23 | Batch 420/737 | Loss: 0.4183 | CTC: 0.5284 | CE: 0.1615 | Time: 10.05s\n",
      "Epoch 23 | Batch 430/737 | Loss: 0.4677 | CTC: 0.6025 | CE: 0.1532 | Time: 9.98s\n",
      "Epoch 23 | Batch 440/737 | Loss: 0.3869 | CTC: 0.4861 | CE: 0.1552 | Time: 10.13s\n",
      "Epoch 23 | Batch 450/737 | Loss: 0.4046 | CTC: 0.5248 | CE: 0.1242 | Time: 10.24s\n",
      "Epoch 23 | Batch 460/737 | Loss: 0.4046 | CTC: 0.5162 | CE: 0.1441 | Time: 10.15s\n",
      "Epoch 23 | Batch 470/737 | Loss: 0.4330 | CTC: 0.5582 | CE: 0.1408 | Time: 10.08s\n",
      "Epoch 23 | Batch 480/737 | Loss: 0.3980 | CTC: 0.5154 | CE: 0.1240 | Time: 9.91s\n",
      "Epoch 23 | Batch 490/737 | Loss: 0.4402 | CTC: 0.5533 | CE: 0.1765 | Time: 10.34s\n",
      "Epoch 23 | Batch 500/737 | Loss: 0.4196 | CTC: 0.5400 | CE: 0.1388 | Time: 10.09s\n",
      "Epoch 23 | Batch 510/737 | Loss: 0.3953 | CTC: 0.5172 | CE: 0.1108 | Time: 10.22s\n",
      "Epoch 23 | Batch 520/737 | Loss: 0.3811 | CTC: 0.4965 | CE: 0.1118 | Time: 10.36s\n",
      "Epoch 23 | Batch 530/737 | Loss: 0.4437 | CTC: 0.5616 | CE: 0.1685 | Time: 10.20s\n",
      "Epoch 23 | Batch 540/737 | Loss: 0.3958 | CTC: 0.5156 | CE: 0.1163 | Time: 10.04s\n",
      "Epoch 23 | Batch 550/737 | Loss: 0.3769 | CTC: 0.4785 | CE: 0.1399 | Time: 10.29s\n",
      "Epoch 23 | Batch 560/737 | Loss: 0.3877 | CTC: 0.5124 | CE: 0.0968 | Time: 10.16s\n",
      "Epoch 23 | Batch 570/737 | Loss: 0.4127 | CTC: 0.5263 | CE: 0.1477 | Time: 10.20s\n",
      "Epoch 23 | Batch 580/737 | Loss: 0.4344 | CTC: 0.5499 | CE: 0.1647 | Time: 10.53s\n",
      "Epoch 23 | Batch 590/737 | Loss: 0.4722 | CTC: 0.6074 | CE: 0.1567 | Time: 9.90s\n",
      "Epoch 23 | Batch 600/737 | Loss: 0.4460 | CTC: 0.5713 | CE: 0.1536 | Time: 10.41s\n",
      "Epoch 23 | Batch 610/737 | Loss: 0.3489 | CTC: 0.4456 | CE: 0.1234 | Time: 9.90s\n",
      "Epoch 23 | Batch 620/737 | Loss: 0.3951 | CTC: 0.4990 | CE: 0.1528 | Time: 10.29s\n",
      "Epoch 23 | Batch 630/737 | Loss: 0.3999 | CTC: 0.5088 | CE: 0.1458 | Time: 10.00s\n",
      "Epoch 23 | Batch 640/737 | Loss: 0.4239 | CTC: 0.5513 | CE: 0.1266 | Time: 10.17s\n",
      "Epoch 23 | Batch 650/737 | Loss: 0.3992 | CTC: 0.5155 | CE: 0.1278 | Time: 10.19s\n",
      "Epoch 23 | Batch 660/737 | Loss: 0.3802 | CTC: 0.4935 | CE: 0.1157 | Time: 10.08s\n",
      "Epoch 23 | Batch 670/737 | Loss: 0.4236 | CTC: 0.5444 | CE: 0.1416 | Time: 10.38s\n",
      "Epoch 23 | Batch 680/737 | Loss: 0.3860 | CTC: 0.4948 | CE: 0.1321 | Time: 9.99s\n",
      "Epoch 23 | Batch 690/737 | Loss: 0.3699 | CTC: 0.4739 | CE: 0.1271 | Time: 10.05s\n",
      "Epoch 23 | Batch 700/737 | Loss: 0.3569 | CTC: 0.4532 | CE: 0.1323 | Time: 10.10s\n",
      "Epoch 23 | Batch 710/737 | Loss: 0.4424 | CTC: 0.5649 | CE: 0.1565 | Time: 10.16s\n",
      "Epoch 23 | Batch 720/737 | Loss: 0.4319 | CTC: 0.5584 | CE: 0.1366 | Time: 10.40s\n",
      "Epoch 23 | Batch 730/737 | Loss: 0.4196 | CTC: 0.5429 | CE: 0.1321 | Time: 10.53s\n",
      "Train Loss: 0.6041 | CTC: 0.8070 | CE: 0.1305\n",
      "Val Loss: 0.4517 | CTC: 0.5668 | CE: 0.1832\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnting in the onlysense with which wereat presint concerned diffors frommost if notfrom althey artsond crafsrepresente in the exuibition\n",
      "\n",
      "Epoch 24/25\n",
      "Epoch 24 | Batch 0/737 | Loss: 0.3395 | CTC: 0.4436 | CE: 0.0965 | Time: 0.96s\n",
      "Epoch 24 | Batch 10/737 | Loss: 0.3537 | CTC: 0.4526 | CE: 0.1230 | Time: 10.33s\n",
      "Epoch 24 | Batch 20/737 | Loss: 0.3436 | CTC: 0.4376 | CE: 0.1243 | Time: 9.57s\n",
      "Epoch 24 | Batch 30/737 | Loss: 0.3520 | CTC: 0.4546 | CE: 0.1124 | Time: 10.18s\n",
      "Epoch 24 | Batch 40/737 | Loss: 0.3792 | CTC: 0.4972 | CE: 0.1039 | Time: 10.20s\n",
      "Epoch 24 | Batch 50/737 | Loss: 0.3588 | CTC: 0.4689 | CE: 0.1019 | Time: 10.27s\n",
      "Epoch 24 | Batch 60/737 | Loss: 0.3068 | CTC: 0.3968 | CE: 0.0968 | Time: 10.31s\n",
      "Epoch 24 | Batch 70/737 | Loss: 0.3730 | CTC: 0.4875 | CE: 0.1057 | Time: 10.13s\n",
      "Epoch 24 | Batch 80/737 | Loss: 0.3472 | CTC: 0.4540 | CE: 0.0982 | Time: 10.08s\n",
      "Epoch 24 | Batch 90/737 | Loss: 0.3789 | CTC: 0.4899 | CE: 0.1200 | Time: 10.19s\n",
      "Epoch 24 | Batch 100/737 | Loss: 0.3430 | CTC: 0.4449 | CE: 0.1053 | Time: 10.26s\n",
      "Epoch 24 | Batch 110/737 | Loss: 12.1661 | CTC: 17.3117 | CE: 0.1597 | Time: 10.19s\n",
      "Epoch 24 | Batch 120/737 | Loss: 0.3978 | CTC: 0.5106 | CE: 0.1344 | Time: 10.25s\n",
      "Epoch 24 | Batch 130/737 | Loss: 0.4138 | CTC: 0.5380 | CE: 0.1239 | Time: 10.15s\n",
      "Epoch 24 | Batch 140/737 | Loss: 0.4313 | CTC: 0.5510 | CE: 0.1521 | Time: 10.17s\n",
      "Epoch 24 | Batch 150/737 | Loss: 0.3884 | CTC: 0.5067 | CE: 0.1124 | Time: 10.48s\n",
      "Epoch 24 | Batch 160/737 | Loss: 0.3954 | CTC: 0.5092 | CE: 0.1301 | Time: 10.11s\n",
      "Epoch 24 | Batch 170/737 | Loss: 0.3631 | CTC: 0.4725 | CE: 0.1078 | Time: 10.24s\n",
      "Epoch 24 | Batch 180/737 | Loss: 0.3381 | CTC: 0.4403 | CE: 0.0996 | Time: 10.26s\n",
      "Epoch 24 | Batch 190/737 | Loss: 0.4056 | CTC: 0.5209 | CE: 0.1365 | Time: 9.92s\n",
      "Epoch 24 | Batch 200/737 | Loss: 0.4220 | CTC: 0.5404 | CE: 0.1457 | Time: 10.02s\n",
      "Epoch 24 | Batch 210/737 | Loss: 0.3610 | CTC: 0.4541 | CE: 0.1437 | Time: 10.14s\n",
      "Epoch 24 | Batch 220/737 | Loss: 0.3814 | CTC: 0.5005 | CE: 0.1034 | Time: 10.01s\n",
      "Epoch 24 | Batch 230/737 | Loss: 0.3386 | CTC: 0.4411 | CE: 0.0994 | Time: 10.18s\n",
      "Epoch 24 | Batch 240/737 | Loss: 0.3710 | CTC: 0.4835 | CE: 0.1087 | Time: 10.15s\n",
      "Epoch 24 | Batch 250/737 | Loss: 0.3553 | CTC: 0.4617 | CE: 0.1069 | Time: 10.34s\n",
      "Epoch 24 | Batch 260/737 | Loss: 0.4109 | CTC: 0.5286 | CE: 0.1362 | Time: 10.23s\n",
      "Epoch 24 | Batch 270/737 | Loss: 0.4065 | CTC: 0.5245 | CE: 0.1313 | Time: 10.18s\n",
      "Epoch 24 | Batch 280/737 | Loss: 0.3936 | CTC: 0.5072 | CE: 0.1283 | Time: 10.14s\n",
      "Epoch 24 | Batch 290/737 | Loss: 0.3895 | CTC: 0.5051 | CE: 0.1198 | Time: 10.16s\n",
      "Epoch 24 | Batch 300/737 | Loss: 0.4262 | CTC: 0.5469 | CE: 0.1447 | Time: 10.60s\n",
      "Epoch 24 | Batch 310/737 | Loss: 0.3799 | CTC: 0.4912 | CE: 0.1202 | Time: 9.90s\n",
      "Epoch 24 | Batch 320/737 | Loss: 0.4360 | CTC: 0.5550 | CE: 0.1582 | Time: 10.36s\n",
      "Epoch 24 | Batch 330/737 | Loss: 0.3398 | CTC: 0.4364 | CE: 0.1144 | Time: 10.20s\n",
      "Epoch 24 | Batch 340/737 | Loss: 0.3569 | CTC: 0.4647 | CE: 0.1053 | Time: 10.20s\n",
      "Epoch 24 | Batch 350/737 | Loss: 0.3541 | CTC: 0.4333 | CE: 0.1694 | Time: 10.24s\n",
      "Epoch 24 | Batch 360/737 | Loss: 0.2974 | CTC: 0.3883 | CE: 0.0853 | Time: 10.27s\n",
      "Epoch 24 | Batch 370/737 | Loss: 0.3893 | CTC: 0.4989 | CE: 0.1335 | Time: 10.32s\n",
      "Epoch 24 | Batch 380/737 | Loss: 0.3731 | CTC: 0.4862 | CE: 0.1094 | Time: 10.35s\n",
      "Epoch 24 | Batch 390/737 | Loss: 0.3501 | CTC: 0.4638 | CE: 0.0847 | Time: 10.13s\n",
      "Epoch 24 | Batch 400/737 | Loss: 0.3946 | CTC: 0.5072 | CE: 0.1318 | Time: 10.34s\n",
      "Epoch 24 | Batch 410/737 | Loss: 0.3934 | CTC: 0.5066 | CE: 0.1295 | Time: 10.21s\n",
      "Epoch 24 | Batch 420/737 | Loss: 0.3505 | CTC: 0.4570 | CE: 0.1019 | Time: 9.86s\n",
      "Epoch 24 | Batch 430/737 | Loss: 0.4638 | CTC: 0.5918 | CE: 0.1652 | Time: 10.32s\n",
      "Epoch 24 | Batch 440/737 | Loss: 0.3523 | CTC: 0.4594 | CE: 0.1021 | Time: 10.22s\n",
      "Epoch 24 | Batch 450/737 | Loss: 0.3763 | CTC: 0.4838 | CE: 0.1255 | Time: 10.00s\n",
      "Epoch 24 | Batch 460/737 | Loss: 0.3691 | CTC: 0.4752 | CE: 0.1214 | Time: 10.44s\n",
      "Epoch 24 | Batch 470/737 | Loss: 0.4072 | CTC: 0.5186 | CE: 0.1473 | Time: 10.00s\n",
      "Epoch 24 | Batch 480/737 | Loss: 0.3903 | CTC: 0.5089 | CE: 0.1134 | Time: 9.88s\n",
      "Epoch 24 | Batch 490/737 | Loss: 0.3771 | CTC: 0.4950 | CE: 0.1019 | Time: 10.19s\n",
      "Epoch 24 | Batch 500/737 | Loss: 0.3254 | CTC: 0.4189 | CE: 0.1072 | Time: 10.17s\n",
      "Epoch 24 | Batch 510/737 | Loss: 0.4256 | CTC: 0.5461 | CE: 0.1442 | Time: 10.12s\n",
      "Epoch 24 | Batch 520/737 | Loss: 0.3716 | CTC: 0.4891 | CE: 0.0972 | Time: 10.25s\n",
      "Epoch 24 | Batch 530/737 | Loss: 0.4008 | CTC: 0.5139 | CE: 0.1369 | Time: 10.13s\n",
      "Epoch 24 | Batch 540/737 | Loss: 0.4541 | CTC: 0.5896 | CE: 0.1378 | Time: 10.11s\n",
      "Epoch 24 | Batch 550/737 | Loss: 0.4075 | CTC: 0.5228 | CE: 0.1383 | Time: 10.11s\n",
      "Epoch 24 | Batch 560/737 | Loss: 0.4072 | CTC: 0.5245 | CE: 0.1334 | Time: 10.16s\n",
      "Epoch 24 | Batch 570/737 | Loss: 0.3338 | CTC: 0.4425 | CE: 0.0800 | Time: 10.12s\n",
      "Epoch 24 | Batch 580/737 | Loss: 0.4120 | CTC: 0.5179 | CE: 0.1651 | Time: 10.28s\n",
      "Epoch 24 | Batch 590/737 | Loss: 0.3647 | CTC: 0.4760 | CE: 0.1052 | Time: 10.23s\n",
      "Epoch 24 | Batch 600/737 | Loss: 0.3912 | CTC: 0.5083 | CE: 0.1179 | Time: 10.21s\n",
      "Epoch 24 | Batch 610/737 | Loss: 0.3687 | CTC: 0.4747 | CE: 0.1214 | Time: 9.84s\n",
      "Epoch 24 | Batch 620/737 | Loss: 0.3931 | CTC: 0.5087 | CE: 0.1233 | Time: 9.83s\n",
      "Epoch 24 | Batch 630/737 | Loss: 0.3165 | CTC: 0.4084 | CE: 0.1019 | Time: 10.17s\n",
      "Epoch 24 | Batch 640/737 | Loss: 0.4477 | CTC: 0.5789 | CE: 0.1417 | Time: 10.43s\n",
      "Epoch 24 | Batch 650/737 | Loss: 0.3804 | CTC: 0.4586 | CE: 0.1981 | Time: 10.11s\n",
      "Epoch 24 | Batch 660/737 | Loss: 0.3632 | CTC: 0.4603 | CE: 0.1367 | Time: 10.28s\n",
      "Epoch 24 | Batch 670/737 | Loss: 0.3303 | CTC: 0.4185 | CE: 0.1245 | Time: 10.44s\n",
      "Epoch 24 | Batch 680/737 | Loss: 0.3970 | CTC: 0.5207 | CE: 0.1085 | Time: 10.03s\n",
      "Epoch 24 | Batch 690/737 | Loss: 0.4339 | CTC: 0.5609 | CE: 0.1376 | Time: 9.97s\n",
      "Epoch 24 | Batch 700/737 | Loss: 0.4238 | CTC: 0.5449 | CE: 0.1415 | Time: 9.80s\n",
      "Epoch 24 | Batch 710/737 | Loss: 0.4289 | CTC: 0.5485 | CE: 0.1497 | Time: 10.28s\n",
      "Epoch 24 | Batch 720/737 | Loss: 0.3599 | CTC: 0.4614 | CE: 0.1230 | Time: 10.43s\n",
      "Epoch 24 | Batch 730/737 | Loss: 0.3871 | CTC: 0.4962 | CE: 0.1324 | Time: 10.35s\n",
      "Train Loss: 0.5952 | CTC: 0.7989 | CE: 0.1200\n",
      "Val Loss: 0.4377 | CTC: 0.5496 | CE: 0.1768\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: prnting in the onlysense withwich waret present conernnd diffors from mosedt enotfrom althe arts ondcrafreprisented in the exibition\n",
      "\n",
      "Epoch 25/25\n",
      "Epoch 25 | Batch 0/737 | Loss: 0.3149 | CTC: 0.4042 | CE: 0.1063 | Time: 0.84s\n",
      "Epoch 25 | Batch 10/737 | Loss: 0.3456 | CTC: 0.4429 | CE: 0.1185 | Time: 10.34s\n",
      "Epoch 25 | Batch 20/737 | Loss: 0.3216 | CTC: 0.4193 | CE: 0.0934 | Time: 10.03s\n",
      "Epoch 25 | Batch 30/737 | Loss: 0.2999 | CTC: 0.3840 | CE: 0.1035 | Time: 9.76s\n",
      "Epoch 25 | Batch 40/737 | Loss: 0.2963 | CTC: 0.3829 | CE: 0.0942 | Time: 10.03s\n",
      "Epoch 25 | Batch 50/737 | Loss: 0.3239 | CTC: 0.4294 | CE: 0.0778 | Time: 10.06s\n",
      "Epoch 25 | Batch 60/737 | Loss: 0.3680 | CTC: 0.4781 | CE: 0.1110 | Time: 9.97s\n",
      "Epoch 25 | Batch 70/737 | Loss: 0.3391 | CTC: 0.4416 | CE: 0.0997 | Time: 10.07s\n",
      "Epoch 25 | Batch 80/737 | Loss: 0.3573 | CTC: 0.4609 | CE: 0.1154 | Time: 10.19s\n",
      "Epoch 25 | Batch 90/737 | Loss: 0.3322 | CTC: 0.4279 | CE: 0.1091 | Time: 10.22s\n",
      "Epoch 25 | Batch 100/737 | Loss: 0.3668 | CTC: 0.4809 | CE: 0.1005 | Time: 9.97s\n",
      "Epoch 25 | Batch 110/737 | Loss: 0.2671 | CTC: 0.3503 | CE: 0.0732 | Time: 10.32s\n",
      "Epoch 25 | Batch 120/737 | Loss: 0.3388 | CTC: 0.4483 | CE: 0.0835 | Time: 10.13s\n",
      "Epoch 25 | Batch 130/737 | Loss: 0.3765 | CTC: 0.4916 | CE: 0.1079 | Time: 10.38s\n",
      "Epoch 25 | Batch 140/737 | Loss: 0.3391 | CTC: 0.4463 | CE: 0.0891 | Time: 10.23s\n",
      "Epoch 25 | Batch 150/737 | Loss: 0.4048 | CTC: 0.5337 | CE: 0.1039 | Time: 10.07s\n",
      "Epoch 25 | Batch 160/737 | Loss: 0.3634 | CTC: 0.4685 | CE: 0.1181 | Time: 10.17s\n",
      "Epoch 25 | Batch 170/737 | Loss: 0.3288 | CTC: 0.4167 | CE: 0.1237 | Time: 10.35s\n",
      "Epoch 25 | Batch 180/737 | Loss: 0.3829 | CTC: 0.4907 | CE: 0.1314 | Time: 10.32s\n",
      "Epoch 25 | Batch 190/737 | Loss: 0.3706 | CTC: 0.4841 | CE: 0.1056 | Time: 10.31s\n",
      "Epoch 25 | Batch 200/737 | Loss: 0.3316 | CTC: 0.4184 | CE: 0.1290 | Time: 10.34s\n",
      "Epoch 25 | Batch 210/737 | Loss: 0.3919 | CTC: 0.5093 | CE: 0.1180 | Time: 10.41s\n",
      "Epoch 25 | Batch 220/737 | Loss: 0.3709 | CTC: 0.4755 | CE: 0.1268 | Time: 10.16s\n",
      "Epoch 25 | Batch 230/737 | Loss: 0.4160 | CTC: 0.5283 | CE: 0.1540 | Time: 10.28s\n",
      "Epoch 25 | Batch 240/737 | Loss: 0.3556 | CTC: 0.4734 | CE: 0.0807 | Time: 10.18s\n",
      "Epoch 25 | Batch 250/737 | Loss: 0.3608 | CTC: 0.4761 | CE: 0.0919 | Time: 10.19s\n",
      "Epoch 25 | Batch 260/737 | Loss: 0.3023 | CTC: 0.3980 | CE: 0.0790 | Time: 10.18s\n",
      "Epoch 25 | Batch 270/737 | Loss: 0.3709 | CTC: 0.4852 | CE: 0.1040 | Time: 10.32s\n",
      "Epoch 25 | Batch 280/737 | Loss: 0.3582 | CTC: 0.4707 | CE: 0.0958 | Time: 9.99s\n",
      "Epoch 25 | Batch 290/737 | Loss: 0.3905 | CTC: 0.5088 | CE: 0.1143 | Time: 10.32s\n",
      "Epoch 25 | Batch 300/737 | Loss: 0.3714 | CTC: 0.4822 | CE: 0.1128 | Time: 10.35s\n",
      "Epoch 25 | Batch 310/737 | Loss: 0.3294 | CTC: 0.4272 | CE: 0.1010 | Time: 10.02s\n",
      "Epoch 25 | Batch 320/737 | Loss: 0.3799 | CTC: 0.4870 | CE: 0.1300 | Time: 9.96s\n",
      "Epoch 25 | Batch 330/737 | Loss: 0.3585 | CTC: 0.4661 | CE: 0.1075 | Time: 10.26s\n",
      "Epoch 25 | Batch 340/737 | Loss: 0.3014 | CTC: 0.3956 | CE: 0.0817 | Time: 10.22s\n",
      "Epoch 25 | Batch 350/737 | Loss: 0.3831 | CTC: 0.4978 | CE: 0.1155 | Time: 10.24s\n",
      "Epoch 25 | Batch 360/737 | Loss: 0.3627 | CTC: 0.4695 | CE: 0.1136 | Time: 10.37s\n",
      "Epoch 25 | Batch 370/737 | Loss: 0.3575 | CTC: 0.4640 | CE: 0.1090 | Time: 10.26s\n",
      "Epoch 25 | Batch 380/737 | Loss: 0.3590 | CTC: 0.4564 | CE: 0.1318 | Time: 10.04s\n",
      "Epoch 25 | Batch 390/737 | Loss: 0.3817 | CTC: 0.4963 | CE: 0.1143 | Time: 10.23s\n",
      "Epoch 25 | Batch 400/737 | Loss: 0.3660 | CTC: 0.4583 | CE: 0.1507 | Time: 10.17s\n",
      "Epoch 25 | Batch 410/737 | Loss: 6.1320 | CTC: 8.6824 | CE: 0.1811 | Time: 10.16s\n",
      "Epoch 25 | Batch 420/737 | Loss: 0.3852 | CTC: 0.4940 | CE: 0.1311 | Time: 10.15s\n",
      "Epoch 25 | Batch 430/737 | Loss: 0.3354 | CTC: 0.4335 | CE: 0.1066 | Time: 9.87s\n",
      "Epoch 25 | Batch 440/737 | Loss: 0.3793 | CTC: 0.4902 | CE: 0.1205 | Time: 10.32s\n",
      "Epoch 25 | Batch 450/737 | Loss: 0.3404 | CTC: 0.4526 | CE: 0.0787 | Time: 9.95s\n",
      "Epoch 25 | Batch 460/737 | Loss: 0.3430 | CTC: 0.4330 | CE: 0.1331 | Time: 10.40s\n",
      "Epoch 25 | Batch 470/737 | Loss: 0.3748 | CTC: 0.4780 | CE: 0.1341 | Time: 10.19s\n",
      "Epoch 25 | Batch 480/737 | Loss: 0.3702 | CTC: 0.4704 | CE: 0.1363 | Time: 10.24s\n",
      "Epoch 25 | Batch 490/737 | Loss: 0.3772 | CTC: 0.4914 | CE: 0.1108 | Time: 10.12s\n",
      "Epoch 25 | Batch 500/737 | Loss: 0.3718 | CTC: 0.4856 | CE: 0.1062 | Time: 10.17s\n",
      "Epoch 25 | Batch 510/737 | Loss: 0.3040 | CTC: 0.3931 | CE: 0.0962 | Time: 9.87s\n",
      "Epoch 25 | Batch 520/737 | Loss: 0.3318 | CTC: 0.4336 | CE: 0.0941 | Time: 10.16s\n",
      "Epoch 25 | Batch 530/737 | Loss: 0.2955 | CTC: 0.3814 | CE: 0.0951 | Time: 9.90s\n",
      "Epoch 25 | Batch 540/737 | Loss: 0.3712 | CTC: 0.4882 | CE: 0.0980 | Time: 10.32s\n",
      "Epoch 25 | Batch 550/737 | Loss: 0.3335 | CTC: 0.4266 | CE: 0.1164 | Time: 10.10s\n",
      "Epoch 25 | Batch 560/737 | Loss: 8.1916 | CTC: 11.6467 | CE: 0.1298 | Time: 10.29s\n",
      "Epoch 25 | Batch 570/737 | Loss: 0.3506 | CTC: 0.4482 | CE: 0.1228 | Time: 10.13s\n",
      "Epoch 25 | Batch 580/737 | Loss: 0.3804 | CTC: 0.4846 | CE: 0.1371 | Time: 9.75s\n",
      "Epoch 25 | Batch 590/737 | Loss: 0.3834 | CTC: 0.4990 | CE: 0.1137 | Time: 10.31s\n",
      "Epoch 25 | Batch 600/737 | Loss: 0.3773 | CTC: 0.4878 | CE: 0.1193 | Time: 10.56s\n",
      "Epoch 25 | Batch 610/737 | Loss: 0.3691 | CTC: 0.4782 | CE: 0.1147 | Time: 10.07s\n",
      "Epoch 25 | Batch 620/737 | Loss: 0.3386 | CTC: 0.4418 | CE: 0.0979 | Time: 10.28s\n",
      "Epoch 25 | Batch 630/737 | Loss: 0.4138 | CTC: 0.5250 | CE: 0.1544 | Time: 10.05s\n",
      "Epoch 25 | Batch 640/737 | Loss: 0.3689 | CTC: 0.4727 | CE: 0.1267 | Time: 10.14s\n",
      "Epoch 25 | Batch 650/737 | Loss: 0.3748 | CTC: 0.4882 | CE: 0.1102 | Time: 10.06s\n",
      "Epoch 25 | Batch 660/737 | Loss: 0.3246 | CTC: 0.4135 | CE: 0.1172 | Time: 10.16s\n",
      "Epoch 25 | Batch 670/737 | Loss: 0.3556 | CTC: 0.4587 | CE: 0.1150 | Time: 10.34s\n",
      "Epoch 25 | Batch 680/737 | Loss: 0.2996 | CTC: 0.3929 | CE: 0.0819 | Time: 10.48s\n",
      "Epoch 25 | Batch 690/737 | Loss: 0.3572 | CTC: 0.4700 | CE: 0.0940 | Time: 10.15s\n",
      "Epoch 25 | Batch 700/737 | Loss: 0.3898 | CTC: 0.5035 | CE: 0.1246 | Time: 10.29s\n",
      "Epoch 25 | Batch 710/737 | Loss: 0.3406 | CTC: 0.4441 | CE: 0.0990 | Time: 10.39s\n",
      "Epoch 25 | Batch 720/737 | Loss: 0.3755 | CTC: 0.4779 | CE: 0.1367 | Time: 10.25s\n",
      "Epoch 25 | Batch 730/737 | Loss: 0.3117 | CTC: 0.4007 | CE: 0.1039 | Time: 9.94s\n",
      "Train Loss: 0.5563 | CTC: 0.7474 | CE: 0.1104\n",
      "Val Loss: 0.4423 | CTC: 0.5385 | CE: 0.2179\n",
      "Sample inference:\n",
      "Ground truth: printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition\n",
      "Prediction: printing in the onlysens with wich weret presen concernd difor s from mosti notfrom athe artsond crafs represente in the exuibition\n",
      "\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training function\n",
    "def train(model, dataloader, loss_fn, optimizer, epoch, device, log_interval=10):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_ctc_loss = 0\n",
    "    total_ce_loss = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        # Move data to device\n",
    "        feature_batch = batch['feature_batch'].to(device)\n",
    "        feature_lengths = batch['feature_lengths'].to(device)\n",
    "        text_batch = batch['text_batch'].to(device)\n",
    "        text_lengths = batch['text_lengths'].to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        ctc_logits, decoder_logits = model(\n",
    "            feature_batch, \n",
    "            feature_lengths, \n",
    "            text_batch, \n",
    "            text_lengths\n",
    "        )\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss, ctc_loss, ce_loss = loss_fn(\n",
    "            ctc_logits, \n",
    "            decoder_logits, \n",
    "            text_batch, \n",
    "            feature_lengths, \n",
    "            text_lengths\n",
    "        )\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "        total_ctc_loss += ctc_loss.item()\n",
    "        total_ce_loss += ce_loss.item()\n",
    "        \n",
    "        # Log progress\n",
    "        if batch_idx % log_interval == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f'Epoch {epoch} | Batch {batch_idx}/{len(dataloader)} | '\n",
    "                  f'Loss: {loss.item():.4f} | CTC: {ctc_loss.item():.4f} | CE: {ce_loss.item():.4f} | '\n",
    "                  f'Time: {elapsed:.2f}s')\n",
    "            start_time = time.time()\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_ctc_loss = total_ctc_loss / len(dataloader)\n",
    "    avg_ce_loss = total_ce_loss / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_ctc_loss, avg_ce_loss\n",
    "\n",
    "# Validation function\n",
    "def validate(model, dataloader, loss_fn, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_ctc_loss = 0\n",
    "    total_ce_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Move data to device\n",
    "            feature_batch = batch['feature_batch'].to(device)\n",
    "            feature_lengths = batch['feature_lengths'].to(device)\n",
    "            text_batch = batch['text_batch'].to(device)\n",
    "            text_lengths = batch['text_lengths'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            ctc_logits, decoder_logits = model(\n",
    "                feature_batch, \n",
    "                feature_lengths, \n",
    "                text_batch, \n",
    "                text_lengths\n",
    "            )\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss, ctc_loss, ce_loss = loss_fn(\n",
    "                ctc_logits, \n",
    "                decoder_logits, \n",
    "                text_batch, \n",
    "                feature_lengths, \n",
    "                text_lengths\n",
    "            )\n",
    "            \n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "            total_ctc_loss += ctc_loss.item()\n",
    "            total_ce_loss += ce_loss.item()\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_ctc_loss = total_ctc_loss / len(dataloader)\n",
    "    avg_ce_loss = total_ce_loss / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_ctc_loss, avg_ce_loss\n",
    "\n",
    "# Greedy CTC decode function\n",
    "def greedy_ctc_decode(logits, idx_to_char, blank_idx=3):\n",
    "    \"\"\"\n",
    "    Greedy CTC decoding algorithm\n",
    "    \n",
    "    Args:\n",
    "        logits: (time, vocab_size) tensor\n",
    "        idx_to_char: index to character mapping\n",
    "        blank_idx: index of blank token\n",
    "        \n",
    "    Returns:\n",
    "        decoded_text: decoded text without duplicates or blanks\n",
    "    \"\"\"\n",
    "    # Get most probable character at each timestep\n",
    "    indices = torch.argmax(logits, dim=1).tolist()\n",
    "    \n",
    "    # Remove duplicates and blanks\n",
    "    prev = -1\n",
    "    decoded_indices = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        if idx != blank_idx and idx != prev:\n",
    "            decoded_indices.append(idx)\n",
    "        prev = idx\n",
    "    \n",
    "    # Convert indices to text\n",
    "    decoded_text = ''.join([idx_to_char[idx] for idx in decoded_indices if idx in idx_to_char])\n",
    "    \n",
    "    return decoded_text\n",
    "\n",
    "# Infer function to test transcription\n",
    "# Modified infer function to fix device mismatch issue\n",
    "def infer(model, feature_extractor, processor, audio_path, config, device):\n",
    "    \"\"\"Infer text from audio\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract features\n",
    "    features = feature_extractor.extract_features(audio_path)\n",
    "    \n",
    "    # Add batch dimension\n",
    "    features = features.unsqueeze(0)\n",
    "    \n",
    "    # Move features to the same device as the model\n",
    "    features = features.to(device)\n",
    "    \n",
    "    # Create feature lengths tensor and move to the same device\n",
    "    feature_lengths = torch.tensor([features.size(1)], device=device)\n",
    "    \n",
    "    # Forward pass (CTC only)\n",
    "    with torch.no_grad():\n",
    "        ctc_logits, _ = model(features, feature_lengths)\n",
    "    \n",
    "    # Get CTC logits for first item in batch\n",
    "    ctc_logits = ctc_logits[0]\n",
    "    \n",
    "    # Decode\n",
    "    decoded_text = greedy_ctc_decode(ctc_logits, processor.idx_to_char)\n",
    "    \n",
    "    return decoded_text\n",
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, loss_fn, config, device, \n",
    "               feature_extractor, processor, checkpoint_dir=\"./checkpoints\"):\n",
    "    \"\"\"Main training loop\"\"\"\n",
    "    # Create checkpoint directory\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    # Initialize scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-6, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Initialize best validation loss\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_ctc_loss': [],\n",
    "        'train_ce_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_ctc_loss': [],\n",
    "        'val_ce_loss': [],\n",
    "    }\n",
    "    \n",
    "    # Sample audio for inference testing\n",
    "    sample_audio_path = os.path.join(config.WAVS_DIR, f\"{train_loader.dataset.file_ids[0]}.wav\")\n",
    "    \n",
    "    # Main training loop\n",
    "    for epoch in range(1, config.max_epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{config.max_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_ctc_loss, train_ce_loss = train(\n",
    "            model, train_loader, loss_fn, optimizer, epoch, device\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_ctc_loss, val_ce_loss = validate(\n",
    "            model, val_loader, loss_fn, device\n",
    "        )\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_ctc_loss'].append(train_ctc_loss)\n",
    "        history['train_ce_loss'].append(train_ce_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_ctc_loss'].append(val_ctc_loss)\n",
    "        history['val_ce_loss'].append(val_ce_loss)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"Train Loss: {train_loss:.4f} | CTC: {train_ctc_loss:.4f} | CE: {train_ce_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | CTC: {val_ctc_loss:.4f} | CE: {val_ce_loss:.4f}\")\n",
    "        \n",
    "        # Test inference\n",
    "        decoded_text = infer(model, feature_extractor, processor, sample_audio_path, config, device)\n",
    "        ground_truth = train_loader.dataset.processed_texts[0]\n",
    "        print(f\"Sample inference:\")\n",
    "        print(f\"Ground truth: {ground_truth}\")\n",
    "        print(f\"Prediction: {decoded_text}\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title('Total Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_ctc_loss'], label='Train CTC Loss')\n",
    "    plt.plot(history['train_ce_loss'], label='Train CE Loss')\n",
    "    plt.plot(history['val_ctc_loss'], label='Val CTC Loss')\n",
    "    plt.plot(history['val_ce_loss'], label='Val CE Loss')\n",
    "    plt.title('Component Losses')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Modified main function with training\n",
    "def main_with_training():\n",
    "    import time\n",
    "    print(\"Initializing LJSpeech Transformer with CTC and Decoder Heads...\")\n",
    "    \n",
    "    # Configuration\n",
    "    config = Config()\n",
    "    \n",
    "    # Initialize processor\n",
    "    processor = LJSpeechProcessor(config)\n",
    "    \n",
    "    # Download and extract dataset\n",
    "    processor.download_and_extract()\n",
    "    \n",
    "    # Load metadata\n",
    "    print(\"Loading metadata...\")\n",
    "    metadata_df = processor.load_metadata()\n",
    "    print(f\"Found {len(metadata_df)} samples\")\n",
    "    \n",
    "    # Preprocess text\n",
    "    print(\"\\nPreprocessing text and building vocabulary...\")\n",
    "    processed_texts = processor.preprocess_text(metadata_df)\n",
    "    \n",
    "    # Initialize feature extractor\n",
    "    print(\"\\nInitializing audio feature extractor...\")\n",
    "    feature_extractor = AudioFeatureExtractor(config)\n",
    "    \n",
    "    # Create full dataset\n",
    "    print(\"\\nCreating dataset...\")\n",
    "    # Use a subset for faster training\n",
    "    train_size = len(metadata_df)\n",
    "    # Split into train and validation sets (90% train, 10% val)\n",
    "    train_size = int(0.9 * train_size)\n",
    "    val_size = int(0.1 * train_size)\n",
    "    \n",
    "    train_metadata_df = metadata_df.iloc[:train_size]\n",
    "    train_processed_texts = processed_texts[:train_size]\n",
    "    \n",
    "    val_metadata_df = metadata_df.iloc[train_size:train_size+val_size]\n",
    "    val_processed_texts = processed_texts[train_size:train_size+val_size]\n",
    "    \n",
    "    train_dataset = LJSpeechDataset(\n",
    "        train_metadata_df, \n",
    "        train_processed_texts, \n",
    "        config, \n",
    "        processor, \n",
    "        feature_extractor\n",
    "    )\n",
    "    \n",
    "    val_dataset = LJSpeechDataset(\n",
    "        val_metadata_df, \n",
    "        val_processed_texts, \n",
    "        config, \n",
    "        processor, \n",
    "        feature_extractor\n",
    "    )\n",
    "    \n",
    "    print(f\"Created train dataset with {len(train_dataset)} samples\")\n",
    "    print(f\"Created validation dataset with {len(val_dataset)} samples\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    print(\"\\nCreating dataloaders...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"\\nInitializing model...\")\n",
    "    model = DualHeadTransformer(config).to(device)\n",
    "    print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "    \n",
    "    # Initialize loss function\n",
    "    print(\"\\nInitializing loss function...\")\n",
    "    loss_fn = DualHeadLoss().to(device)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nStarting training...\")\n",
    "    history = train_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        loss_fn, \n",
    "        config, \n",
    "        device,\n",
    "        feature_extractor,\n",
    "        processor\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining complete!\")\n",
    "    return model, history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    main_with_training()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19648.983942,
   "end_time": "2025-05-07T14:45:28.216963",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-07T09:17:59.233021",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
